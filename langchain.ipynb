{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai, os\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://aoai.openai.azure.com/\"\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from typing import List\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "class CognitiveSearchRetriever(BaseRetriever):\n",
    "    def __init__(self, endpoint: str, index_name: str, searchkey: str, top: int = 3):\n",
    "        self.endpoint = endpoint\n",
    "        self.index_name = index_name\n",
    "        self.searchkey = searchkey\n",
    "        self.top = top\n",
    "        self.client = SearchClient(endpoint=endpoint, index_name=index_name, credential=AzureKeyCredential(searchkey))\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = []\n",
    "        for i in self.client.search(query, top=self.top):\n",
    "            docs.append(Document(page_content=i['content'], metadata={\"sourcefile\": i['sourcefile']}))\n",
    "        return docs\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_search = CognitiveSearchRetriever(endpoint=\"https://gptkb-73g2mkes5kahm.search.windows.net/\", index_name=\"amldocs\", searchkey=os.environ[\"COG_SEARCH_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='   > You can publish multiple pipelines to a single endpoint. Each pipeline in a given endpoint is given a version number, which you can specify when you call the pipeline endpoint.\\n\\n1. Select **Publish**.\\n\\n## Retrain your model\\n\\nNow that you have a published training pipeline, you can use it to retrain your model on new data. You can submit jobs from a pipeline endpoint from the studio workspace or programmatically.\\n\\n### Submit jobs by using the studio portal\\n\\nUse the following steps to submit a parameterized pipeline endpoint job from the studio portal:\\n\\n1. Go to the **Endpoints** page in your studio workspace.\\n1. Select the **Pipeline endpoints** tab. Then, select your pipeline endpoint.\\n1. Select the **Published pipelines** tab. Then, select the pipeline version that you want to run.\\n1. Select **Submit**.\\n1. In the setup dialog box, you can specify the parameters values for the job. For this example, update the data path to train your model using a non-US dataset.\\n\\n![Screenshot that shows how to set up a parameterized pipeline job in the designer](./media/how-to-retrain-designer/published-pipeline-run.png)\\n\\n### Submit jobs by using code\\n\\nYou can find the REST endpoint of a published pipeline in the overview panel. By calling the endpoint, you can retrain the published pipeline.\\n\\nTo make a REST call, you need an OAuth 2.0 bearer-type authentication header. For information about setting up authentication to your workspace and making a parameterized REST call, see [Build an Azure Machine Learning pipeline for batch scoring](tutorial-pipeline-batch-scoring-classification.md#publish-and-run-from-a-rest-endpoint).\\n\\n## Next steps\\n\\nIn this article, you learned how to create a parameterized training pipeline endpoint using the designer.\\n\\nFor a complete walkthrough of how you can deploy a model to make predictions, see the [designer tutorial](tutorial-designer-automobile-price-train-score.md) to train and deploy a regression model.\\n\\nFor how to publish and submit a job to pipeline endpoint using the SDK v1, see [this article](v1/how-to-deploy-pipelines.md).\\n', metadata={'sourcefile': 'UI/2023-04-06_191207_UTC/simple-4000-100/how-to-retrain-designer-74.md'}),\n",
       " Document(page_content='\\n# Create and run machine learning pipelines using components with the Azure Machine Learning studio\\n\\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\\n\\nIn this article, you\\'ll learn how to create and run [machine learning pipelines](concept-ml-pipelines.md) by using the Azure Machine Learning studio and [Components](concept-component.md). You can create pipelines without using components, but components offer better amount of flexibility and reuse. Azure ML Pipelines may be defined in YAML and [run from the CLI](how-to-create-component-pipelines-cli.md), [authored in Python](how-to-create-component-pipeline-python.md), or composed in Azure ML Studio Designer with a drag-and-drop UI. This document focuses on the AzureML studio designer UI.\\n\\n## Prerequisites\\n\\n* If you don\\'t have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\\n\\n* An Azure Machine Learning workspace[Create workspace resources](quickstart-create-resources.md).\\n\\n* [Install and set up the Azure CLI extension for Machine Learning](how-to-configure-cli.md).\\n\\n* Clone the examples repository:\\n\\n    ```azurecli-interactive\\n    git clone https://github.com/Azure/azureml-examples --depth 1\\n    cd azureml-examples/cli/jobs/pipelines-with-components/\\n    ```\\n\\n## Register component in your workspace\\n\\n>[!Note]\\n> Designer supports two type of components, classic prebuilt components and custom components. These two types of components are not compatible.  \\n>\\n>Classic prebuilt components provides prebuilt components majorly for data processing and traditional machine learning tasks like regression and classification. This type of component continues to be supported but will not have any new components added.\\n>\\n>\\n>Custom components allow you to provide your own code as a component. It supports sharing across workspaces and seamless authoring across Studio, CLI, and SDK interfaces.\\n>\\n>This article applies to custom components. \\n\\nTo build pipeline using components in UI, you need to register components to your workspace first. You can use CLI or SDK to register components to your workspace, so that you can share and reuse the component within the workspace. Registered components support automatic versioning so you can update the component but assure that pipelines that require an older version will continue to work.  \\n\\nIn the example below take using CLI for example. If you want to learn more about how to build a component, see [Create and run pipelines using components with  CLI](how-to-create-component-pipelines-cli.md).\\n\\n1. From the `cli/jobs/pipelines-with-components/basics` directory of the [`azureml-examples` repository](https://github.com/Azure/azureml-examples), navigate to the `1b_e2e_registered_components` subdirectory.\\n\\n1. Register the components to AzureML workspace using following commands. Learn more about [ML components](concept-component.md).\\n\\n    ```CLI\\n    az ml component create --file train.yml\\n    az ml component create --file score.yml\\n    az ml component create --file eval.yml\\n    ```\\n\\n1. After register component successfully, you can see your component in the studio UI.\\n\\n:::image type=\"content\" source=\"./media/how-to-create-component-pipelines-ui/component-page.png\" alt-text=\"Screenshot showing registered component in component page.\" lightbox =\"./media/how-to-create-component-pipelines-ui/component-page.png\":::\\n\\n## Create pipeline using registered component\\n\\n1. Create a new pipeline in the designer.\\n\\n    :::image type=\"content\" source=\"./media/how-to-create-component-pipelines-ui/new-pipeline.png\" alt-text=\"Screenshot showing creating new pipeline in designer homepage.\" lightbox =\"./media/how-to-create-component-pipelines-ui/new-pipeline.png\":::\\n\\n1. Set the default compute target of the pipeline. \\n\\n    Select the **Gear icon** ![Screenshot of the gear icon that is in the UI.](./media/tutorial-designer-automobile-price-train-score/gear-icon.png) at the top right of the canvas to open the **Settings** pane. Select the default compute target for your pipeline.\\n', metadata={'sourcefile': 'UI/2023-04-06_191207_UTC/simple-4000-100/how-to-create-component-pipelines-ui-0.md'}),\n",
       " Document(page_content='\\n# Use GitHub Actions with Azure Machine Learning\\n[!INCLUDE [v2](../../includes/machine-learning-dev-v2.md)]\\nGet started with [GitHub Actions](https://docs.github.com/en/actions) to train a model on Azure Machine Learning. \\n\\nThis article will teach you how to create a GitHub Actions workflow that builds and deploys a machine learning model to [Azure Machine Learning](./overview-what-is-azure-machine-learning.md). You\\'ll train a [scikit-learn](https://scikit-learn.org/) linear regression model on the NYC Taxi dataset. \\n\\nGitHub Actions uses a workflow YAML (.yml) file in the `/.github/workflows/` path in your repository. This definition contains the various steps and parameters that make up the workflow.\\n\\n\\n## Prerequisites\\n\\n[!INCLUDE [sdk](../../includes/machine-learning-sdk-v2-prereqs.md)]\\n\\n* A GitHub account. If you don\\'t have one, sign up for [free](https://github.com/join).  \\n\\n## Step 1. Get the code\\n\\nFork the following repo at GitHub:\\n\\n```\\nhttps://github.com/azure/azureml-examples\\n```\\n\\n## Step 2. Authenticate with Azure\\n\\nYou\\'ll need to first define how to authenticate with Azure. You can use a [service principal](../active-directory/develop/app-objects-and-service-principals.md#service-principal-object) or [OpenID Connect](https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect). \\n\\n### Generate deployment credentials\\n\\n[!INCLUDE [include](~/articles/reusable-content/github-actions/generate-deployment-credentials.md)]\\n\\n### Create secrets\\n\\n[!INCLUDE [include](~/articles/reusable-content/github-actions/create-secrets-with-openid.md)]\\n\\n## Step 3. Update `setup.sh` to connect to your Azure Machine Learning workspace\\n\\nYou\\'ll need to update the CLI setup file variables to match your workspace. \\n\\n1. In your cloned repository, go to `azureml-examples/cli/`. \\n1. Edit `setup.sh` and update these variables in the file. \\n   \\n    |Variable  | Description  |\\n    |---------|---------|\\n    |GROUP     |      Name of resource group    |\\n    |LOCATION     |    Location of your workspace (example: `eastus2`)    |\\n    |WORKSPACE     |     Name of Azure ML workspace     | \\n\\n## Step 4. Update `pipeline.yml` with your compute cluster name\\n\\nYou\\'ll use a `pipeline.yml` file to deploy your Azure ML pipeline. This is a machine learning pipeline and not a DevOps pipeline. You only need to make this update if you\\'re using a name other than `cpu-cluster` for your computer cluster name. \\n\\n1. In your cloned repository, go to `azureml-examples/cli/jobs/pipelines/nyc-taxi/pipeline.yml`. \\n1. Each time you see `compute: azureml:cpu-cluster`, update the value of `cpu-cluster` with your compute cluster name. For example, if your cluster is named `my-cluster`, your new value would be `azureml:my-cluster`. There are five updates.\\n\\n## Step 5: Run your GitHub Actions workflow\\n\\nYour workflow authenticates with Azure, sets up the Azure Machine Learning CLI, and uses the CLI to train a model in Azure Machine Learning. \\n\\n# [Service principal](#tab/userlevel)\\n\\n\\nYour workflow file is made up of a trigger section and jobs:\\n- A trigger starts the workflow in the `on` section. The workflow runs by default on a cron schedule and when a pull request is made from matching branches and paths. Learn more about [events that trigger workflows](https://docs.github.com/actions/using-workflows/events-that-trigger-workflows). \\n- In the jobs section of the workflow, you checkout code and log into Azure with your service principal secret.\\n- The jobs section also includes a setup action that installs and sets up the [Machine Learning CLI (v2)](how-to-configure-cli.md). Once the CLI is installed, the run job action runs your Azure Machine Learning `pipeline.yml` file to train a model with NYC taxi data.\\n\\n\\n### Enable your workflow\\n\\n1. In your cloned repository, open `.github/workflows/cli-jobs-pipelines-nyc-taxi-pipeline.yml` and verify that your workflow looks like this. \\n\\n    ```yaml\\n    name: cli-jobs-pipelines-nyc-taxi-pipeline\\n    on:\\n      workflow_dispatch:\\n      schedule:\\n        - cron: \"0 0/4 * * *\"\\n      pull_request:\\n        branches:\\n          - main\\n          - sdk-preview\\n        paths:\\n          - cli/jobs/pipelines/nyc-taxi/**\\n          - .github/workflows/cli-jobs-pipelines-nyc-taxi-pipeline.yml\\n          - cli/run-pipeline-jobs.sh\\n          - cli/setup.sh\\n    jobs:\\n      build:\\n        runs-on: ubuntu-latest\\n        steps:\\n        - name: check out repo\\n          uses: actions/checkout@v2\\n        - name: azure login\\n          uses: azure/login@v1\\n          with:\\n            creds: ${{secrets.AZ_CREDS}}\\n        - name: setup\\n          run: bash setup.sh\\n          working-directory: cli\\n          continue-on-error: true\\n        - name: run job\\n          run: bash -x ../../../run-job.sh pipeline.yml\\n          working-directory: cli/jobs/pipelines/nyc-taxi\\n    ```\\n', metadata={'sourcefile': 'UI/2023-04-06_191207_UTC/simple-4000-100/how-to-github-actions-machine-learning-0.md'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cog_search.get_relevant_documents(\"pipelines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    temperature=0,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    chain_type=\"stuff\",\n",
    "                                    retriever=cog_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is a pipeline?',\n",
       " 'result': 'In the context of Azure Machine Learning, a pipeline is a collection of steps used in machine learning workflows for orchestrating, managing, and automating machine learning projects. A machine learning pipeline in Azure Machine Learning can contain steps from data preparation, to feature extraction, to hyperparameter tuning, to model evaluation. Azure Machine Learning pipelines are particularly powerful in creating reproducible and reusable machine learning workflows with consistent and reliable outcomes.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(\"What is a pipeline?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
