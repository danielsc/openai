2021-10-23T15:01:01Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24781 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING
2021-10-23T15:01:02Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore
2021-10-23T15:01:02Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:01:02Z Starting output-watcher...
2021-10-23T15:01:02Z IsDedicatedCompute == True, won't poll for Low Pri Preemption
2021-10-23T15:01:04Z Executing 'Copy ACR Details file' on 10.0.0.4
2021-10-23T15:01:04Z Copy ACR Details file succeeded on 10.0.0.4. Output: 
>>>   
>>>   
Login Succeeded
Using default tag: latest
latest: Pulling from azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4
92473f7ef455: Pulling fs layer
fb52bde70123: Pulling fs layer
64788f86be3f: Pulling fs layer
33f6d5f2e001: Pulling fs layer
eeb715f1b6ae: Pulling fs layer
fe519cf36537: Pulling fs layer
58ff99196c15: Pulling fs layer
9b13f06a8eff: Pulling fs layer
2d4e93adbf58: Pulling fs layer
6ee7c3767844: Pulling fs layer
62cfc3ccb8ab: Pulling fs layer
4a7af9d757ee: Pulling fs layer
55ee3a8427d1: Pulling fs layer
276b3b4ab7fb: Pulling fs layer
409473831e40: Pulling fs layer
1d385b5297a8: Pulling fs layer
cdc39f9539df: Pulling fs layer
f07fc542af21: Pulling fs layer
08d3c92ca6ca: Pulling fs layer
9b13f06a8eff: Waiting
2d4e93adbf58: Waiting
6ee7c3767844: Waiting
62cfc3ccb8ab: Waiting
4a7af9d757ee: Waiting
55ee3a8427d1: Waiting
276b3b4ab7fb: Waiting
eeb715f1b6ae: Waiting
fe519cf36537: Waiting
58ff99196c15: Waiting
409473831e40: Waiting
1d385b5297a8: Waiting
cdc39f9539df: Waiting
33f6d5f2e001: Waiting
f07fc542af21: Waiting
08d3c92ca6ca: Waiting
fb52bde70123: Verifying Checksum
fb52bde70123: Download complete
64788f86be3f: Download complete
33f6d5f2e001: Verifying Checksum
fe519cf36537: Verifying Checksum
fe519cf36537: Download complete
92473f7ef455: Verifying Checksum
92473f7ef455: Download complete
58ff99196c15: Verifying Checksum
58ff99196c15: Download complete
eeb715f1b6ae: Verifying Checksum
eeb715f1b6ae: Download complete
9b13f06a8eff: Verifying Checksum
9b13f06a8eff: Download complete
62cfc3ccb8ab: Verifying Checksum
62cfc3ccb8ab: Download complete
6ee7c3767844: Verifying Checksum
6ee7c3767844: Download complete
4a7af9d757ee: Verifying Checksum
4a7af9d757ee: Download complete
55ee3a8427d1: Verifying Checksum
55ee3a8427d1: Download complete
409473831e40: Verifying Checksum
409473831e40: Download complete
1d385b5297a8: Verifying Checksum
1d385b5297a8: Download complete
2d4e93adbf58: Verifying Checksum
2d4e93adbf58: Download complete
cdc39f9539df: Verifying Checksum
cdc39f9539df: Download complete
f07fc542af21: Verifying Checksum
f07fc542af21: Download complete
08d3c92ca6ca: Verifying Checksum
08d3c92ca6ca: Download complete
92473f7ef455: Pull complete
fb52bde70123: Pull complete
64788f86be3f: Pull complete
33f6d5f2e001: Pull complete
276b3b4ab7fb: Verifying Checksum
276b3b4ab7fb: Download complete
eeb715f1b6ae: Pull complete
fe519cf36537: Pull complete
58ff99196c15: Pull complete
9b13f06a8eff: Pull complete
2d4e93adbf58: Pull complete
6ee7c3767844: Pull complete
62cfc3ccb8ab: Pull complete
4a7af9d757ee: Pull complete
55ee3a8427d1: Pull complete
276b3b4ab7fb: Pull complete
409473831e40: Pull complete
1d385b5297a8: Pull complete
cdc39f9539df: Pull complete
f07fc542af21: Pull complete
08d3c92ca6ca: Pull complete
Digest: sha256:2dd62cdffcf3989c82023b0938c78c6c0d0c0050ef236d24f3f67911568b7bd5
Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4:latest
viennaglobal.azurecr.io/azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4:latest
2021-10-23T15:01:22Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:01:22Z Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar already exist exited with 0, 

5012a8ecdbd36b823616e247d9131a6772116f9ac197f11fe1db67a84ea4d69f
2021-10-23T15:01:24Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
2021-10-23T15:01:24Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-704e678173c4fe59-01 -sshRequired=false] 
2021/10/23 15:01:24 Got JobInfoJson from env
2021/10/23 15:01:24 Starting App Insight Logger for task:  containerSetup
2021/10/23 15:01:24 Version: 3.0.01751.0001 Branch: 2021-10-18 Commit: 281a55e
2021/10/23 15:01:24 Entered ContainerSetupTask - Preparing infiniband
2021/10/23 15:01:24 Starting infiniband setup
2021/10/23 15:01:24 Python Version found is Python 3.7.9

2021/10/23 15:01:24 Returning Python Version as 3.7
2021-10-23T15:01:24Z VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04
2021/10/23 15:01:24 VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04
2021/10/23 15:01:24 VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04
2021/10/23 15:01:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
2021-10-23T15:01:24Z Not setting up Infiniband in Container
2021/10/23 15:01:24 Not setting up Infiniband in Container
2021/10/23 15:01:24 Not setting up Infiniband in Container
2021/10/23 15:01:24 Python Version found is Python 3.7.9

2021/10/23 15:01:24 Returning Python Version as 3.7
2021/10/23 15:01:24 sshd inside container not required for job, skipping setup.
2021/10/23 15:01:25 All App Insights Logs was sent successfully or the close timeout of 10 was reached
2021/10/23 15:01:25 App Insight Client has already been closed
2021/10/23 15:01:25 Not exporting to RunHistory as the exporter is either stopped or there is no data.
Stopped: false
OriginalData: 1
FilteredData: 0.
2021-10-23T15:01:25Z Starting docker container succeeded.
2021-10-23T15:01:25Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:01:42Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:01:42Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:01:42Z Executing 'Copy ACR Details file' on 10.0.0.4
2021-10-23T15:01:42Z Copy ACR Details file succeeded on 10.0.0.4. Output: 
>>>   
>>>   
Login Succeeded
Using default tag: latest
latest: Pulling from azureml/azureml_a5653c74995b808262a585f93fd754e5
284055322776: Pulling fs layer
eac21e864395: Pulling fs layer
9e64dc49a10f: Pulling fs layer
a5bc810e87ec: Pulling fs layer
0fab68c59895: Pulling fs layer
cfd11bf92fb1: Pulling fs layer
b8892d2ab1db: Pulling fs layer
1ee35456d60a: Pulling fs layer
ea64f68eca4c: Pulling fs layer
afa07a40910f: Pulling fs layer
a3d855a622e2: Pulling fs layer
ef0b5b222257: Pulling fs layer
0262dad25f70: Pulling fs layer
a6570bca6017: Pulling fs layer
b122e22b3611: Pulling fs layer
fa348c46acaf: Pulling fs layer
a88ae2457e87: Pulling fs layer
ae801dc90367: Pulling fs layer
a5bc810e87ec: Waiting
a3d855a622e2: Waiting
0fab68c59895: Waiting
cfd11bf92fb1: Waiting
b8892d2ab1db: Waiting
ea64f68eca4c: Waiting
1ee35456d60a: Waiting
afa07a40910f: Waiting
ef0b5b222257: Waiting
a6570bca6017: Waiting
0262dad25f70: Waiting
b122e22b3611: Waiting
fa348c46acaf: Waiting
a88ae2457e87: Waiting
ae801dc90367: Waiting
9e64dc49a10f: Verifying Checksum
9e64dc49a10f: Download complete
284055322776: Verifying Checksum
284055322776: Download complete
a5bc810e87ec: Verifying Checksum
a5bc810e87ec: Download complete
cfd11bf92fb1: Verifying Checksum
cfd11bf92fb1: Download complete
eac21e864395: Verifying Checksum
eac21e864395: Download complete
0fab68c59895: Verifying Checksum
0fab68c59895: Download complete
284055322776: Pull complete
b8892d2ab1db: Verifying Checksum
b8892d2ab1db: Download complete
1ee35456d60a: Verifying Checksum
1ee35456d60a: Download complete
afa07a40910f: Verifying Checksum
afa07a40910f: Download complete
ea64f68eca4c: Verifying Checksum
ea64f68eca4c: Download complete
a3d855a622e2: Verifying Checksum
a3d855a622e2: Download complete
ef0b5b222257: Verifying Checksum
ef0b5b222257: Download complete
0262dad25f70: Verifying Checksum
0262dad25f70: Download complete
b122e22b3611: Verifying Checksum
b122e22b3611: Download complete
fa348c46acaf: Verifying Checksum
fa348c46acaf: Download complete
ae801dc90367: Verifying Checksum
ae801dc90367: Download complete
a88ae2457e87: Verifying Checksum
a88ae2457e87: Download complete
a6570bca6017: Verifying Checksum
a6570bca6017: Download complete
eac21e864395: Pull complete
9e64dc49a10f: Pull complete
a5bc810e87ec: Pull complete
0fab68c59895: Pull complete
cfd11bf92fb1: Pull complete
b8892d2ab1db: Pull complete
1ee35456d60a: Pull complete
ea64f68eca4c: Pull complete
afa07a40910f: Pull complete
a3d855a622e2: Pull complete
ef0b5b222257: Pull complete
0262dad25f70: Pull complete
a6570bca6017: Pull complete
b122e22b3611: Pull complete
fa348c46acaf: Pull complete
a88ae2457e87: Pull complete
ae801dc90367: Pull complete
Digest: sha256:e3db0e121d64d1dddde0b23e95850fad6af54c9901cc9939a8c1fb732a540197
Status: Downloaded newer image for ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5:latest
ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5:latest
2021-10-23T15:02:01Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:02:01Z Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exist exited with 0, 5012a8ecdbd3


2021-10-23T15:02:01Z The container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exists, stop and remove it before starting it.
2021-10-23T15:02:01Z Stopping container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error response from daemon: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c


2021-10-23T15:02:01Z Removing container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c


468db4cff7aaa6b0715c85a7d7e4c91c58776b492ee09479a2e16793e9766c7d
2021-10-23T15:02:04Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
2021-10-23T15:02:04Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-763004f20b583da2-01 -sshRequired=false] 
2021/10/23 15:02:04 Got JobInfoJson from env
2021/10/23 15:02:04 Starting App Insight Logger for task:  containerSetup
2021/10/23 15:02:04 Version: 3.0.01751.0001 Branch: 2021-10-18 Commit: 281a55e
2021/10/23 15:02:04 Entered ContainerSetupTask - Preparing infiniband
2021/10/23 15:02:04 Starting infiniband setup
2021/10/23 15:02:04 Python Version found is Python 3.8.12

2021/10/23 15:02:04 Returning Python Version as 3.8
2021-10-23T15:02:04Z VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021/10/23 15:02:04 VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021/10/23 15:02:04 VMSize: standard_ds3_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021/10/23 15:02:04 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
2021-10-23T15:02:04Z Not setting up Infiniband in Container
2021/10/23 15:02:04 Not setting up Infiniband in Container
2021/10/23 15:02:04 Not setting up Infiniband in Container
2021/10/23 15:02:04 Python Version found is Python 3.8.12

2021/10/23 15:02:04 Returning Python Version as 3.8
2021/10/23 15:02:04 sshd inside container not required for job, skipping setup.
2021/10/23 15:02:05 All App Insights Logs was sent successfully or the close timeout of 10 was reached
2021/10/23 15:02:05 App Insight Client has already been closed
2021/10/23 15:02:05 Not exporting to RunHistory as the exporter is either stopped or there is no data.
Stopped: false
OriginalData: 1
FilteredData: 0.
2021-10-23T15:02:05Z Starting docker container succeeded.
2021-10-23T15:02:05Z Job environment preparation succeeded on 10.0.0.4. Output: 
>>>   2021/10/23 15:01:01 Got JobInfoJson from env
>>>   2021/10/23 15:01:01 Starting App Insight Logger for task:  prepareJobEnvironment
>>>   2021/10/23 15:01:01 Version: 3.0.01751.0001 Branch: 2021-10-18 Commit: 281a55e
>>>   2021/10/23 15:01:01 Got JobInfoJson from env
>>>   2021/10/23 15:01:01 runtime.GOOS linux
>>>   2021/10/23 15:01:01 Checking if '/tmp' exists
>>>   2021/10/23 15:01:01 Reading dyanamic configs
>>>   2021/10/23 15:01:01 Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=0zSJlZiBvTfbGrZHmFBZqzDes0PMmYkeROmANx9hhuo%3D
>>>   2021/10/23 15:01:01 Starting Azsecpack installation on machine: d7fd8b27cce44e968a47d4c9f6da0572000000#72f988bf-86f1-41af-91ab-2d7cd011db47#15ae9cb6-95c1-483d-a0e3-b1a1a3b06324#ray#ray#cpu-cluster#tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d
>>>   2021/10/23 15:01:01 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory
>>>   2021/10/23 15:01:01 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: true,
>>>   2021/10/23 15:01:01 Is Azsecpack enabled: true, GetDisableVsatlsscan: true
>>>   2021/10/23 15:01:01 Start preparing environment for azsecpack installation. MachineName is d7fd8b27cce44e968a47d4c9f6da0572000000 
>>>   
>>>   2021/10/23 15:01:01 
>>>   2021/10/23 15:01:01 
>>>   2021/10/23 15:01:01 bypass systemd resolved
>>>   2021/10/23 15:01:01 Cluster Subscription Id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324
>>>   2021/10/23 15:01:01 Cluster Workspace Name: ray
>>>   2021/10/23 15:01:01 Cluster Name: cpu-cluster
>>>   2021/10/23 15:01:01 VMsize: standard_ds3_v2
>>>   2021/10/23 15:01:01 GPU Count: 0
>>>   2021/10/23 15:01:01 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber
>>>   2021/10/23 15:01:01 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:01 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:01 Get GPU count failed with err: The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., 
>>>   2021/10/23 15:01:01 AMLComputeXDSEndpoint:  https://eastus2.cert.api.azureml.ms/xdsbatchai
>>>   2021/10/23 15:01:01 AMLComputeXDSApiVersion:  2018-02-01
>>>   2021/10/23 15:01:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config
>>>   2021/10/23 15:01:01 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.
>>>   2021/10/23 15:01:01 Starting identity responder.
>>>   2021/10/23 15:01:01 Starting identity responder.
>>>   2021/10/23 15:01:01 Logfile used for identity responder: /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/IdentityResponderLog-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:01 Logfile used for identity responder: /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/IdentityResponderLog-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:01 Started Identity Responder for job.
>>>   2021/10/23 15:01:01 Started Identity Responder for job.
>>>   2021/10/23 15:01:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd
>>>   2021/10/23 15:01:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/shared
>>>   2021/10/23 15:01:01 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:01 From the policy service, the filtering patterns is: , data store is 
>>>   2021/10/23 15:01:01 Mounting job level file systems
>>>   2021/10/23 15:01:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts
>>>   2021/10/23 15:01:01 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.amlcompute.datastorecredentials
>>>   2021/10/23 15:01:01 Datastore credentials file not found, skipping.
>>>   2021/10/23 15:01:01 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.master.runtimesastokens
>>>   2021/10/23 15:01:01 Runtime sas tokens file not found, skipping.
>>>   2021/10/23 15:01:01 NFS mount is not enabled
>>>   2021/10/23 15:01:01 No Azure File Shares configured
>>>   2021/10/23 15:01:01 Mounting blob file systems
>>>   2021/10/23 15:01:01 Blobfuse runtime version 1.3.6
>>>   2021/10/23 15:01:01 Mounting azureml-blobstore-599c8ff0-b43f-4048-ba22-2073107846af container from ray7080601732 account at /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore
>>>   2021/10/23 15:01:01 Using Compute Identity to authenticate Blobfuse: false.
>>>   2021/10/23 15:01:01 Using Compute Identity to authenticate Blobfuse: false.
>>>   2021/10/23 15:01:01 Blobfuse cache size set to 24781 MB.
>>>   2021/10/23 15:01:01 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24781 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING
>>>   2021/10/23 15:01:02 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore
>>>   2021/10/23 15:01:02 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore
>>>   2021/10/23 15:01:02 Successfully mounted azureml-blobstore-599c8ff0-b43f-4048-ba22-2073107846af container from ray7080601732 account at /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore
>>>   2021/10/23 15:01:02 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c: read-only file system
>>>   2021/10/23 15:01:02 No unmanaged file systems configured
>>>   2021/10/23 15:01:02 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:02 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:02 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 From the policy service, the filtering patterns is: , data store is 
>>>   2021/10/23 15:01:02 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:02 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d
>>>   2021/10/23 15:01:02 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d/55_azureml-execution-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:02 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:02 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:02 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:02 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d
>>>   2021/10/23 15:01:02 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d/55_azureml-execution-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:02 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs
>>>   2021/10/23 15:01:02 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/outputs
>>>   2021/10/23 15:01:02 Starting output-watcher...
>>>   2021/10/23 15:01:02 Single file input dataset is enabled.
>>>   2021/10/23 15:01:02 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/10/23 15:01:02 SidecarEnabled:: AmlDatasetContextManagerConfig exists: true
>>>   2021/10/23 15:01:02 SidecarEnabled:: enabling sidecar due to dataset being present and sidecar is enabled
>>>   2021/10/23 15:01:02 Begin Sidecar setup
>>>   2021/10/23 15:01:02 SingleDataDirectory enabled, Passing to Sidecar.
>>>   2021/10/23 15:01:02 Pulling Sidecar docker image: azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4
>>>   2021/10/23 15:01:02 Start pull docker image: azureml
>>>   2021/10/23 15:01:02 Getting credentials for image azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4 with url 
>>>   2021/10/23 15:01:02 Container registry is not ACR.
>>>   2021/10/23 15:01:02 Skip getting ACR Credentials from Identity and will be getting it from EMS
>>>   2021/10/23 15:01:02 Getting ACR Credentials from EMS for environment AzureML-Sidecar:22
>>>   2021/10/23 15:01:02 Requesting XDS for registry details.
>>>   2021/10/23 15:01:02 Attempt 1 of http call to https://eastus2.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/workspaces/ray/clusters/cpu-cluster/nodes/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d?api-version=2018-02-01
>>>   2021/10/23 15:01:04 Got container registry details from credentials service for registry address: viennaglobal.azurecr.io.
>>>   2021/10/23 15:01:04 Writing ACR Details to file...
>>>   2021/10/23 15:01:04 Copying ACR Details file to worker nodes...
>>>   2021/10/23 15:01:04 Executing 'Copy ACR Details file' on 10.0.0.4
>>>   2021/10/23 15:01:04 Begin executing 'Copy ACR Details file' task on Node
>>>   2021/10/23 15:01:04 'Copy ACR Details file' task Node result: succeeded
>>>   2021/10/23 15:01:04 Copy ACR Details file succeeded on 10.0.0.4. Output: 
>>>   >>>   
>>>   >>>   
>>>   2021/10/23 15:01:04 Successfully retrieved ACR Credentials from EMS.
>>>   2021/10/23 15:01:04 EMS returned viennaglobal.azurecr.io for environment AzureML-Sidecar
>>>   2021/10/23 15:01:04 Updating image url from blank to viennaglobal.azurecr.io
>>>   2021/10/23 15:01:04 Save docker credentials for image viennaglobal.azurecr.io/azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4 in /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/docker_login_71B7687F946ACC1E
>>>   2021/10/23 15:01:04 Start login to the docker registry
>>>   2021/10/23 15:01:04 Successfully logged into the docker registry.
>>>   2021/10/23 15:01:04 Start run pull docker image command
>>>   2021/10/23 15:01:06 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 19
>>>   FilteredData: 0.
>>>   2021/10/23 15:01:22 Pull docker image succeeded.
>>>   2021/10/23 15:01:22 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/docker_login_71B7687F946ACC1E
>>>   2021/10/23 15:01:22 Pull docker image time: 19.738427873s
>>>   
>>>   2021/10/23 15:01:22 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:01:22 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:22 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:22 Setting the memory limit for docker container to be 13674 MB
>>>   2021/10/23 15:01:22 The env variable file size is 44531 bytes
>>>   2021/10/23 15:01:22 Creating parent cgroup '6dd8c2d3-a72b-44a1-a4e8-93d9d616642c' for Containers used in Job
>>>   2021/10/23 15:01:22 Add parent cgroup '6dd8c2d3-a72b-44a1-a4e8-93d9d616642c' to container '6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar'
>>>   2021/10/23 15:01:22 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
>>>   2021/10/23 15:01:22 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/,--shm-size,2g,-v,/:/mnt/hostfs:rshared,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,--env,RSLEX_DIRECT_VOLUME_MOUNT=true,--env,DATASET_RSLEX_UPLOAD=true
>>>   2021/10/23 15:01:22 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared 
>>>   2021/10/23 15:01:22 the binding /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c 
>>>   2021/10/23 15:01:22 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/,--shm-size,2g,--env,SIDECAR_HOSTFS=/mnt/hostfs,--env,SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,--env,AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--env,AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true,--env,RSLEX_DIRECT_VOLUME_MOUNT=true,--env,DATASET_RSLEX_UPLOAD=true,-v,/:/mnt/hostfs:rshared,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs
>>>   2021/10/23 15:01:22 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist --cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/ --shm-size 2g --env SIDECAR_HOSTFS=/mnt/hostfs --env SIDECAR_WORKING_DIR=/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c --env AZ_BATCHAI_ENVLIST_PATH=/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist --env AZUREML_SIDECAR_SINGLE_DATA_DIRECTORY=true --env RSLEX_DIRECT_VOLUME_MOUNT=true --env DATASET_RSLEX_UPLOAD=true -v /:/mnt/hostfs:rshared -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c -v /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd -v /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs -d -it --privileged --net=host viennaglobal.azurecr.io/azureml/azureml_8ceb6b8f58eaa8cee47c9719bba2cae4
>>>   2021/10/23 15:01:22 Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar already exist exited with 0, 
>>>   
>>>   2021/10/23 15:01:22 Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar already exist exited with 0, 
>>>   
>>>   2021/10/23 15:01:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/10/23 15:01:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/10/23 15:01:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-704e678173c4fe59-01 -sshRequired=false] 
>>>   2021/10/23 15:01:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-704e678173c4fe59-01 -sshRequired=false] 
>>>   2021/10/23 15:01:25 Container ssh is not required for job type.
>>>   2021/10/23 15:01:25 Starting docker container succeeded.
>>>   2021/10/23 15:01:25 Starting docker container succeeded.
>>>   2021/10/23 15:01:25 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:01:25 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:25 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:25 Waiting for sidecar container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar to start running.
>>>   2021/10/23 15:01:25 Running command /usr/bin/docker inspect -f {{.State.Running}} 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   2021/10/23 15:01:25 Waiting for sidecar container to be ready.
>>>   2021/10/23 15:01:25 Running command /usr/bin/docker exec 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar sh -c python -c 'from azureml.sidecar.ipc import IPC_FILE;import os;print("IsSidecarReady:{}".format(os.path.exists(IPC_FILE)))'
>>>   2021/10/23 15:01:26 Sidecar container is running and TaskServer is ready.
>>>   2021/10/23 15:01:26 Run job preparation command in Sidecar container
>>>   2021/10/23 15:01:26 runSpecialJobTask: checking control script content under dir: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c-setup
>>>   2021/10/23 15:01:26 Attempt 1 of http call to https://eastus2.api.azureml.ms/history/v1.0/private/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/runs/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/spans
>>>   2021/10/23 15:01:27 runSpecialJobTask: control script dir content: [_tracer.py: size=2022 md5=4c1dd974ef27d1cbec1434a93802ac73; _tracing.py: size=26407 md5=64b473943a5d2905628a9b2097f18081; _vendor_jwt_decode.py: size=2277 md5=d4b49e48ed904f03a4d6ad2f64f17368; azureml_globals.py: size=12242 md5=3700b728b132e633c956f368d13818e4; context_managers.py: size=48073 md5=1d499aa329dc1debda235d60098e98dd; job_prep.py: size=11214 md5=13bb64f32d440c1fbaff3644045668fc; log_history_status.py: size=4428 md5=778bbe2bb6cb72340d4344366f752a63; request_utilities.py: size=1185 md5=e053daf561ffebe1c54811d9dc11beaa; run_token_provider.py: size=4228 md5=b167c8697df9c999e3676723caa93cb3; utility_context_managers.py: size=5015 md5=824d969dee21cf92733986c744d17142]
>>>   2021/10/23 15:01:27 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:01:27 runSpecialJobTask: Raw cmd for preparation is passed is: python /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c-setup/job_prep.py --snapshots '[{"Id":"7942ae2c-ad59-44a7-8fcc-801e371fcae9","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/10/23 15:01:27 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/65_job_prep-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:27 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/65_job_prep-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:01:27 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c;python /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c-setup/job_prep.py --snapshots '[{"Id":"7942ae2c-ad59-44a7-8fcc-801e371fcae9","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/10/23 15:01:27 runSpecialJobTask: commons.GetOsPlatform(): ubuntu
>>>   2021/10/23 15:01:27 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-89b54b6d745e40ed3815aee6cc981bdb-ddd0426145b6e4fb-01 -t 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c;python /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/mounts/workspaceblobstore/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c-setup/job_prep.py --snapshots '[{"Id":"7942ae2c-ad59-44a7-8fcc-801e371fcae9","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/10/23 15:01:42 containerName:6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   2021/10/23 15:01:42 sidecar containerName:6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   2021/10/23 15:01:42 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:01:42 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:42 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:42 sidecar dockerLauncher:docker
>>>   2021/10/23 15:01:42 sidecarContainerId:5012a8ecdbd36b823616e247d9131a6772116f9ac197f11fe1db67a84ea4d69f
>>>   2021/10/23 15:01:42 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:01:42 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:42 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:01:42 Docker logs for 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   [2021-10-23T15:01:25.831203] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   [2021-10-23T15:01:25.835326] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 48347
>>>   [2021-10-23T15:01:29.194812] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers
>>>   [2021-10-23T15:01:29.378] Initialize DatasetContextManager.
>>>   [2021-10-23T15:01:29.381480] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers
>>>   [2021-10-23T15:01:29.382870] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset
>>>   fuse: warning: library too old, some operations may not not work
>>>   fuse: warning: library too old, some operations may not not work
>>>   [2021-10-23T15:01:41.857486] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers
>>>   
>>>   2021/10/23 15:01:42 runSpecialJobTask: job preparation exited with code 0 and err <nil>
>>>   
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:27.736580] Entering job preparation.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.371824] Starting job preparation.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.371860] Extracting the control code.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.372227] Starting extract_project.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.372275] Starting to extract zip file.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.446748] Finished extracting zip file.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.450712] Using urllib.request Python 3.0 or later
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.450778] Start fetching snapshots.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.450862] Start fetching snapshot.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.450880] Retrieving project from snapshot: 7942ae2c-ad59-44a7-8fcc-801e371fcae9
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: Starting the daemon thread to refresh tokens in background for process with pid = 51
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.711437] Finished fetching snapshot.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.711480] Finished fetching snapshots.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.711488] Finished extract_project.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.711589] Finished fetching and extracting the control code.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.720999] Start run_history_prep.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.728645] Job preparation is complete.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.728803] Entering Data Context Managers in Sidecar
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:28.729827] Running Sidecar prep cmd...
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:29.182531] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:29.183540] INFO azureml.sidecar.sidecar: Invoking "enter_contexts" task with Context Managers: {"context_managers": ["Dataset:context_managers.Datasets"]}
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:29.385] Enter __enter__ of DatasetContextManager
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:29.386] SDK version: azureml-core==1.35.0 azureml-dataprep==2.23.2. Session id: 0f8183e5-7bb7-440f-bde1-a784e7997db3. Run id: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [[[Context Manager output has been redacted.]]]
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:42.253564] Ran Sidecar prep cmd.
>>>   2021/10/23 15:01:42 runSpecialJobTask->SideCar + : preparation: [2021-10-23T15:01:42.253711] Running Context Managers in Sidecar complete.
>>>   2021/10/23 15:01:42 DockerSideCarContainerLogs:
>>>   [2021-10-23T15:01:25.831203] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   [2021-10-23T15:01:25.835326] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 48347
>>>   [2021-10-23T15:01:29.194812] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers
>>>   [2021-10-23T15:01:29.378] Initialize DatasetContextManager.
>>>   [2021-10-23T15:01:29.381480] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers
>>>   [2021-10-23T15:01:29.382870] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset
>>>   fuse: warning: library too old, some operations may not not work
>>>   fuse: warning: library too old, some operations may not not work
>>>   [2021-10-23T15:01:41.857486] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers
>>>   
>>>   2021/10/23 15:01:42 DockerSideCarContainerLogs End
>>>   2021/10/23 15:01:42 Job preparation command in Sidecar container completed
>>>   2021/10/23 15:01:42 Sidecar setup completed
>>>   2021/10/23 15:01:42 Start to pulling docker image: ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5
>>>   2021/10/23 15:01:42 Start pull docker image: ray4711.azurecr.io
>>>   2021/10/23 15:01:42 Getting credentials for image ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5 with url ray4711.azurecr.io
>>>   2021/10/23 15:01:42 Container registry is ACR.
>>>   2021/10/23 15:01:42 Skip getting ACR Credentials from Identity and will be getting it from EMS
>>>   2021/10/23 15:01:42 Getting ACR Credentials from EMS for environment b88e5408-884f-4873-9e7c-5ee3d87cd5e8:1
>>>   2021/10/23 15:01:42 Requesting XDS for registry details.
>>>   2021/10/23 15:01:42 Attempt 1 of http call to https://eastus2.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/workspaces/ray/clusters/cpu-cluster/nodes/tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d?api-version=2018-02-01
>>>   2021/10/23 15:01:42 Got container registry details from credentials service for registry address: ray4711.azurecr.io.
>>>   2021/10/23 15:01:42 Writing ACR Details to file...
>>>   2021/10/23 15:01:42 Copying ACR Details file to worker nodes...
>>>   2021/10/23 15:01:42 Executing 'Copy ACR Details file' on 10.0.0.4
>>>   2021/10/23 15:01:42 Begin executing 'Copy ACR Details file' task on Node
>>>   2021/10/23 15:01:42 'Copy ACR Details file' task Node result: succeeded
>>>   2021/10/23 15:01:42 Copy ACR Details file succeeded on 10.0.0.4. Output: 
>>>   >>>   
>>>   >>>   
>>>   2021/10/23 15:01:42 Successfully retrieved ACR Credentials from EMS.
>>>   2021/10/23 15:01:42 EMS returned ray4711.azurecr.io for environment b88e5408-884f-4873-9e7c-5ee3d87cd5e8
>>>   2021/10/23 15:01:42 Save docker credentials for image ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5 in /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/docker_login_ADB2933F28BCB5A2
>>>   2021/10/23 15:01:42 Start login to the docker registry
>>>   2021/10/23 15:01:43 Successfully logged into the docker registry.
>>>   2021/10/23 15:01:43 Start run pull docker image command
>>>   2021/10/23 15:01:46 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 5
>>>   FilteredData: 0.
>>>   2021/10/23 15:02:01 Pull docker image succeeded.
>>>   2021/10/23 15:02:01 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/docker_login_ADB2933F28BCB5A2
>>>   2021/10/23 15:02:01 Pull docker image time: 18.400292774s
>>>   
>>>   2021/10/23 15:02:01 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:02:01 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:02:01 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:02:01 Setting the memory limit for docker container to be 13674 MB
>>>   2021/10/23 15:02:01 The env variable file size is 46011 bytes
>>>   2021/10/23 15:02:01 Add parent cgroup '6dd8c2d3-a72b-44a1-a4e8-93d9d616642c' to container '6dd8c2d3-a72b-44a1-a4e8-93d9d616642c'
>>>   2021/10/23 15:02:01 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
>>>   2021/10/23 15:02:01 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/,--shm-size,2g,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:rslave
>>>   2021/10/23 15:02:01 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared 
>>>   2021/10/23 15:02:01 the binding /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c 
>>>   2021/10/23 15:02:01 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist,--cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:rslave,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd,-v,/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:rslave,-v,/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:rslave
>>>   2021/10/23 15:02:01 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/config/.batchai.envlist --cgroup-parent=/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c -v /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/fine_tune_metadata_workspaceblobstore:rslave -v /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd -v /mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs:/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/certs -v /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/training_data_0cd3ea36-cbea-4788-a22d-90345b44397b:rslave -v /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/validation_data_872b6967-2d17-4f76-b84a-2159f08a7c12:rslave -d -it --privileged --net=host ray4711.azurecr.io/azureml/azureml_a5653c74995b808262a585f93fd754e5
>>>   2021/10/23 15:02:01 Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exist exited with 0, 5012a8ecdbd3
>>>   
>>>   
>>>   2021/10/23 15:02:01 Check if container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exist exited with 0, 5012a8ecdbd3
>>>   
>>>   
>>>   2021/10/23 15:02:01 The container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exists, stop and remove it before starting it.
>>>   2021/10/23 15:02:01 The container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c already exists, stop and remove it before starting it.
>>>   2021/10/23 15:02:01 Stopping container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error response from daemon: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   
>>>   
>>>   2021/10/23 15:02:01 Stopping container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error response from daemon: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   
>>>   
>>>   2021/10/23 15:02:01 Removing container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   
>>>   
>>>   2021/10/23 15:02:01 Removing container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 1, Error: No such container: 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   
>>>   
>>>   2021/10/23 15:02:01 Attempt 1 of http call to https://eastus2.api.azureml.ms/history/v1.0/private/subscriptions/15ae9cb6-95c1-483d-a0e3-b1a1a3b06324/resourceGroups/ray/providers/Microsoft.MachineLearningServices/workspaces/ray/runs/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/spans
>>>   2021/10/23 15:02:04 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/10/23 15:02:04 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/10/23 15:02:04 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-763004f20b583da2-01 -sshRequired=false] 
>>>   2021/10/23 15:02:04 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-89b54b6d745e40ed3815aee6cc981bdb-763004f20b583da2-01 -sshRequired=false] 
>>>   2021/10/23 15:02:05 Container ssh is not required for job type.
>>>   2021/10/23 15:02:05 Starting docker container succeeded.
>>>   2021/10/23 15:02:05 Starting docker container succeeded.
>>>   2021/10/23 15:02:05 Disk space after starting docker container: 23119MB
>>>   2021/10/23 15:02:05 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/10/23 15:02:05 SidecarEnabled:: AmlDatasetContextManagerConfig exists: true
>>>   2021/10/23 15:02:05 SidecarEnabled:: enabling sidecar due to dataset being present and sidecar is enabled
>>>   2021/10/23 15:02:05 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 2
>>>   FilteredData: 0.
>>>   2021/10/23 15:02:05 Process Exiting with Code:  0
>>>   2021/10/23 15:02:05 All App Insights Logs was sent successfully or the close timeout of 10 was reached
>>>   
2021-10-23T15:02:05Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:02:05Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:02:05Z 127.0.0.1 slots=4 max-slots=4
2021-10-23T15:02:06Z launching Custom job
2021-10-23T15:06:05Z The vmsize standard_ds3_v2 is not a GPU VM, skipping running nvidia-smi command.
2021-10-23T15:06:30Z job exited with code 0
2021-10-23T15:06:30Z Executing 'JobRelease task' on 10.0.0.4
2021-10-23T15:06:32Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:06:32Z The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-10-23T15:06:32Z JobRelease task succeeded on 10.0.0.4. Output: 
>>>   2021/10/23 15:06:30 Got JobInfoJson from env
>>>   2021/10/23 15:06:30 Starting App Insight Logger for task:  jobRelease
>>>   2021/10/23 15:06:30 Version: 3.0.01751.0001 Branch: 2021-10-18 Commit: 281a55e
>>>   2021/10/23 15:06:30 Got JobInfoJson from env
>>>   2021/10/23 15:06:30 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/10/23 15:06:30 SidecarEnabled:: AmlDatasetContextManagerConfig exists: true
>>>   2021/10/23 15:06:30 SidecarEnabled:: enabling sidecar due to dataset being present and sidecar is enabled
>>>   2021/10/23 15:06:30 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs
>>>   2021/10/23 15:06:30 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml-setup/job_release.py
>>>   2021/10/23 15:06:30 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/75_job_post-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:06:30 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml_compute_logs/75_job_post-tvmps_e25a17b61ba345db15470fd7bced36b4bf10a216391232941083f4ad91b4e6cd_d.txt
>>>   2021/10/23 15:06:30 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml-setup/job_release.py
>>>   2021/10/23 15:06:30 runSpecialJobTask: commons.GetOsPlatform(): ubuntu
>>>   2021/10/23 15:06:30 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-89b54b6d745e40ed3815aee6cc981bdb-b3960274b271c40e-01 -t 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8ed52900-3785-4aec-a582-8a1f3a4b06dd/job-1/6dd8c2d3-a72b-44a1-a_1254364d-1884-4a3b-8501-7e4cd3c264ea/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/azureml-setup/job_release.py
>>>   2021/10/23 15:06:32 containerName:6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   2021/10/23 15:06:32 sidecar containerName:6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   2021/10/23 15:06:32 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:06:32 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:06:32 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:06:32 sidecar dockerLauncher:docker
>>>   2021/10/23 15:06:32 sidecarContainerId:5012a8ecdbd36b823616e247d9131a6772116f9ac197f11fe1db67a84ea4d69f
>>>   2021/10/23 15:06:32 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/10/23 15:06:32 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:06:32 The vmsize standard_ds3_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/10/23 15:06:32 Docker logs for 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar
>>>   [2021-10-23T15:01:25.831203] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   [2021-10-23T15:01:25.835326] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 48347
>>>   [2021-10-23T15:01:29.194812] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers
>>>   [2021-10-23T15:01:29.378] Initialize DatasetContextManager.
>>>   [2021-10-23T15:01:29.381480] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers
>>>   [2021-10-23T15:01:29.382870] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset
>>>   fuse: warning: library too old, some operations may not not work
>>>   fuse: warning: library too old, some operations may not not work
>>>   [2021-10-23T15:01:41.857486] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers
>>>   [2021-10-23T15:06:31.719678] INFO azureml.sidecar.task.exit_contexts: Exiting Context Managers
>>>   [2021-10-23T15:06:31.721477] INFO azureml.sidecar.context_manager_wrapper: Exiting context: Dataset
>>>   Exception in thread Thread-44:
>>>   Traceback (most recent call last):
>>>     File "/opt/miniconda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
>>>       self.run()
>>>     File "/opt/miniconda/lib/python3.7/threading.py", line 870, in run
>>>       self._target(*self._args, **self._kwargs)
>>>     File "/opt/miniconda/lib/python3.7/site-packages/azureml/dataprep/fuse/daemon.py", line 209, in stream_stdout
>>>       self._trace('Received {} bytes from child process (pid: {}) stdout'.format(len(line), self._process.pid))
>>>   AttributeError: 'NoneType' object has no attribute 'pid'
>>>   
>>>   [2021-10-23T15:06:31.772589] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers
>>>   
>>>   2021/10/23 15:06:32 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>
>>>   
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:30.312730] Entering job release
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.304543] Starting job release
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.305690] Logging experiment finalizing status in history service.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.305981] job release stage : upload_datastore starting...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: Starting the daemon thread to refresh tokens in background for process with pid = 476
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.312360] job release stage : start importing azureml.history._tracking in run_history_release.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.312469] job release stage : execute_job_release starting...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.312861] Entering context manager injector.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.313531] job release stage : copy_batchai_cached_logs starting...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.324708] job release stage : copy_batchai_cached_logs completed...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.329215] job release stage : upload_datastore completed...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.387435] job release stage : send_run_telemetry starting...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.409987] get vm size and vm region successfully.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.420524] get compute meta data successfully.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.544176] job release stage : execute_job_release completed...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.621590] post artifact meta request successfully.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.694304] upload compute record artifact successfully.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.694506] job release stage : send_run_telemetry completed...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.695504] Running in AzureML-Sidecar, starting to exit user context managers...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.695607] Running Sidecar release cmd...
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.708791] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:31.730] Enter __exit__ of DatasetContextManager
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [[[Context Manager output has been redacted.]]]
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:32.157986] Ran Sidecar release cmd.
>>>   2021/10/23 15:06:32 runSpecialJobTask->SideCar + : postprocessing: [2021-10-23T15:06:32.158225] Job release is complete
>>>   2021/10/23 15:06:32 DockerSideCarContainerLogs:
>>>   [2021-10-23T15:01:25.831203] INFO azureml.sidecar.sidecar: Received task: start. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ray/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c/wd/azureml/6dd8c2d3-a72b-44a1-a4e8-93d9d616642c
>>>   [2021-10-23T15:01:25.835326] INFO azureml.sidecar.sidecar: Started TaskServer. Address: 127.0.0.1, Port: 48347
>>>   [2021-10-23T15:01:29.194812] INFO azureml.sidecar.task.enter_contexts: Constructing Context Managers
>>>   [2021-10-23T15:01:29.378] Initialize DatasetContextManager.
>>>   [2021-10-23T15:01:29.381480] INFO azureml.sidecar.task.enter_contexts: Entering Context Managers
>>>   [2021-10-23T15:01:29.382870] INFO azureml.sidecar.context_manager_wrapper: Entering context: Dataset
>>>   fuse: warning: library too old, some operations may not not work
>>>   fuse: warning: library too old, some operations may not not work
>>>   [2021-10-23T15:01:41.857486] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers
>>>   [2021-10-23T15:06:31.719678] INFO azureml.sidecar.task.exit_contexts: Exiting Context Managers
>>>   [2021-10-23T15:06:31.721477] INFO azureml.sidecar.context_manager_wrapper: Exiting context: Dataset
>>>   Exception in thread Thread-44:
>>>   Traceback (most recent call last):
>>>     File "/opt/miniconda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
>>>       self.run()
>>>     File "/opt/miniconda/lib/python3.7/threading.py", line 870, in run
>>>       self._target(*self._args, **self._kwargs)
>>>     File "/opt/miniconda/lib/python3.7/site-packages/azureml/dataprep/fuse/daemon.py", line 209, in stream_stdout
>>>       self._trace('Received {} bytes from child process (pid: {}) stdout'.format(len(line), self._process.pid))
>>>   AttributeError: 'NoneType' object has no attribute 'pid'
>>>   
>>>   [2021-10-23T15:06:31.772589] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers
>>>   
>>>   2021/10/23 15:06:32 DockerSideCarContainerLogs End
>>>   2021/10/23 15:06:32 All App Insights Logs was sent successfully or the close timeout of 10 was reached
>>>   2021/10/23 15:06:32 App Insight Client has already been closed
>>>   2021/10/23 15:06:32 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 3
>>>   FilteredData: 0.
>>>   
2021-10-23T15:06:32Z Executing 'Job environment clean-up' on 10.0.0.4
2021-10-23T15:06:33Z Removing container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c exited with 0, 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c


2021-10-23T15:06:33Z Removing container 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar exited with 0, 6dd8c2d3-a72b-44a1-a4e8-93d9d616642c_DataSidecar


