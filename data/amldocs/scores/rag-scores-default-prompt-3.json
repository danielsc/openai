[
    {
        "query": "How to update an existing azureml environment using AzureML SDK V2?",
        "result": "To update an existing AzureML environment using AzureML SDK V2, you can use the `Environment.update()` method. Here's an example:\n\n```python\nfrom azureml.core import Environment, Workspace\n\n# Load the workspace\nws = Workspace.from_config()\n\n# Get the environment by name\nenv = Environment.get(workspace=ws, name=\"my-environment\")\n\n# Update the environment\nenv.python.conda_dependencies.add_pip_package(\"tensorflow==2.4.0\")\n\n# Save the updated environment\nenv.update(workspace=ws)\n```\n\nIn this example, we first load the workspace using `Workspace.from_config()`. Then we get the environment we want to update using `Environment.get()`. We update the environment by adding a new pip package to the conda dependencies using `env.python.conda_dependencies.add_pip_package()`. Finally, we save the updated environment using `env.update()`.",
        "context": [
            {
                "page_content": "\n*Applies to: all scenarios*\n\nIf you're using a YAML for your conda specification, specify a version for pip\n\n```yaml\nname: project_environment\ndependencies:\n  - python=3.8\n  - pip=22.3.1\n  - pip:\n      - numpy=1.24.1\nchannels:\n  - anaconda\n  - conda-forge\n```\n\n**Resources**\n* See [conda package pinning](https://aka.ms/azureml/environment/how-to-pin-conda-packages)\n\n## *Miscellaneous environment issues*\n### R section is deprecated\n<!--issueDescription-->\n**Potential causes:**\n* You specified an R section in your environment definition\n\n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n\nThe AzureML SDK for R was deprecated at the end of 2021 to make way for an improved R training and deployment experience using the Azure CLI v2\n\n*Applies to: Python SDK v1*\n\nRemove the R section from your environment definition\n\n```python\nenv.r = None\n```\n\n*Applies to: all scenarios*\n\nSee the [samples repository](https://aka.ms/azureml/environment/train-r-models-cli-v2) to get started training R models using the Azure CLI v2\n\n### No definition exists for environment\n<!--issueDescription-->\n**Potential causes:**\n* You specified an environment that doesn't exist or hasn't been registered\n* There was a misspelling or syntactical error in the way you specified your environment name or environment version\n\n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n\nEnsure that you are specifying your environment name correctly, along with the correct version\n* `path-to-resource:version-number`\n\nThe 'latest' version of your environment is specified in a slightly different way\n* `path-to-resource@latest`\n\n## **Image build problems**\n\n## *ACR issues*\n### ACR unreachable\n<!--issueDescription-->\nThis issue can happen by failing to access a workspace's associated Azure Container Registry (ACR) resource.\n\n**Potential causes:**\n* Workspace's ACR is behind a virtual network (VNet) (private endpoint or service endpoint), and no compute cluster is used to build images.\n* Workspace's ACR is behind a virtual network (private endpoint or service endpoint), and the compute cluster used for building images have no access to the workspace's ACR.\n\n**Affected areas (symptoms):**\n* Failure in building environments from UI, SDK, and CLI.\n* Failure in running jobs because it will implicitly build the environment in the first step.\n* Pipeline job failures.\n* Model deployment failures.\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n\n*Applies to: Python SDK v1*\n\nUpdate the workspace image build compute property using SDK:\n\n```python\nfrom azureml.core import Workspace\nws = Workspace.from_config()\nws.update(image_build_compute = 'mycomputecluster')\n```\n\n*Applies to: Azure CLI extensions v1 & v2*\n\nUpdate the workspace image build compute property using Azure CLI:\n\n```\naz ml workspace update --name myworkspace --resource-group myresourcegroup --image-build-compute mycomputecluster\n```\n\n> [!NOTE]\n> * Only Azure Machine Learning compute clusters are supported. Compute, Azure Kubernetes Service (AKS), or other instance types are not supported for image build compute.\n> * Make sure the compute cluster's VNet that's used for the image build compute has access to the workspace's ACR.\n> * Make sure the compute cluster is CPU based.\n\n**Resources**\n* [Enable Azure Container Registry (ACR)](https://aka.ms/azureml/environment/acr-private-endpoint)\n* [How To Use Environments](https://aka.ms/azureml/environment/how-to-use-environments)\n\n## *Docker pull issues*\n### Failed to pull Docker image\n<!--issueDescription-->\nThis issue can happen when a Docker image pull fails during an image build.\n\n**Potential causes:**\n* The path name to the container registry is incorrect\n* A container registry behind a virtual network is using a private endpoint in an [unsupported region](https://aka.ms/azureml/environment/private-link-availability)\n* The image you're trying to reference doesn't exist in the container registry you specified \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-environments-1072.md"
                }
            },
            {
                "page_content": "\n\n# Troubleshoot \"cannot import name 'SerializationError'\"\n\nWhen using Azure Machine Learning, you may receive one of the following errors:\n\n* `cannot import name 'SerializationError'`\n* `cannot import name 'SerializationError' from 'azure.core.exceptions'`\n\nThis error may occur when using an Azure Machine Learning environment. For example, when submitting a training job or using AutoML.\n\n## Cause\n\nThis problem is caused by a bug in the Azure Machine Learning SDK version 1.42.0.\n\n## Resolution\n\nUpdate the affected environment to use SDK version 1.42.0.post1 or greater. For a local development environment or compute instance, use the following command:\n\n```bash\npip install azureml-sdk[automl,explain,notebooks]>=1.42.0\n```\n\nFor more information on updating an Azure Machine Learning environment (for training or deployment), see the following articles:\n\n* [Manage environments in studio](how-to-manage-environments-in-studio.md#rebuild-an-environment)\n* [Create & use software environments (SDK v1)](how-to-use-environments.md#update-an-existing-environment)\n* [Create & manage environments (CLI v2)](how-to-manage-environments-v2.md#update)\n\nTo verify the version of your installed SDK, use the following command:\n\n```bash\npip show azureml-core\n```\n\n## Next steps\n\nFor more information on updating an Azure Machine Learning environment (for training or deployment), see the following articles:\n\n* [Manage environments in studio](how-to-manage-environments-in-studio.md#rebuild-an-environment)\n* [Create & use software environments (SDK v1)](how-to-use-environments.md#update-an-existing-environment)\n* [Create & manage environments (CLI v2)](how-to-manage-environments-v2.md#update)",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-serialization-error-0.md"
                }
            },
            {
                "page_content": "\n# Troubleshoot `descriptors cannot not be created directly` error\n\nWhen using Azure Machine Learning, you may receive the following error:\n\n```\nTypeError: Descriptors cannot not be created directly. If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\u201d It is followed by the proposition to install the appropriate version of protobuf library.\n\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n```\n\nYou may notice this error specifically when using AutoML.\n\n## Cause\n\nThis problem is caused by breaking changes introduced in protobuf 4.0.0. For more information, see [https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates](https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates).\n\n## Resolution\n\nFor a local development environment or compute instance, install the Azure Machine Learning SDK version 1.42.0.post1 or greater.\n\n```bash\npip install azureml-sdk[automl,explain,notebooks]>=1.42.0\n```\n\nFor more information on updating an Azure Machine Learning environment (for training or deployment), see the following articles:\n\n* [Manage environments in studio](how-to-manage-environments-in-studio.md#rebuild-an-environment)\n* [Create & use software environments (SDK v1)](how-to-use-environments.md#update-an-existing-environment)\n* [Create & manage environments (CLI v2)](how-to-manage-environments-v2.md#update)\n\nTo verify the version of your installed SDK, use the following command:\n\n```bash\npip show azureml-core\n```\n\nThis command should return information similar to `Version: 1.42.0.post1`.\n\n> [!TIP]\n> If you can't upgrade your Azure Machine Learning SDK installation, you can pin the protobuf version in your environment to `3.20.1`. The following example is a `conda.yml` file that demonstrates how to pin the version:\n>\n> ```yml\n> name: model-env\n> channels:\n>   - conda-forge\n> dependencies:\n>   - python=3.8\n>   - numpy=1.21.2\n>   - pip=21.2.4\n>   - scikit-learn=0.24.2\n>   - scipy=1.7.1\n>   - pandas>=1.1,<1.2\n>   - pip:\n>     - inference-schema[numpy-support]==1.3.0\n>     - xlrd==2.0.1\n>     - mlflow== 1.26.0\n>     - azureml-mlflow==1.41.0\n>     - protobuf==3.20.1\n> ```\n\n## Next steps\n\nFor more information on the breaking changes in protobuf 4.0.0, see [https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates](https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates). \n\nFor more information on updating an Azure Machine Learning environment (for training or deployment), see the following articles:\n\n* [Manage environments in studio](how-to-manage-environments-in-studio.md#rebuild-an-environment)\n* [Create & use software environments (SDK v1)](how-to-use-environments.md#update-an-existing-environment)\n* [Create & manage environments (CLI v2)](how-to-manage-environments-v2.md#update)",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-protobuf-descriptor-error-0.md"
                }
            }
        ]
    },
    {
        "query": "Generate a Python Code Sample to create an environment from conda specification using AzureML SDK V2?",
        "result": "Here's a Python code sample that creates an environment from a conda specification using AzureML SDK V2:\n\n```python\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\n# Create a new environment\nmyenv = Environment(name=\"myenv\")\n\n# Create a new CondaDependencies object\nconda_dep = CondaDependencies()\n\n# Add the necessary packages to the CondaDependencies object\nconda_dep.add_conda_package(\"scikit-learn\")\nconda_dep.add_conda_package(\"pandas\")\n\n# Add the CondaDependencies object to the environment\nmyenv.python.conda_dependencies = conda_dep\n\n# Register the environment in the workspace\nmyenv.register(workspace=ws)\n```\n\nIn this example, we create a new environment called \"myenv\" and add the necessary packages to the CondaDependencies object. We then add the CondaDependencies object to the environment and register the environment in the workspace.",
        "context": [
            {
                "page_content": "To create a new environment, you must use one of the following approaches (see [DockerSection](https://aka.ms/azureml/environment/environment-docker-section)):\n* Base image\n    * Provide base image name, repository from which to pull it, and credentials if needed\n    * Provide a conda specification\n* Base Dockerfile \n    * Provide a Dockerfile\n    * Provide a conda specification\n* Docker build context\n    * Provide the location of the build context (URL)\n    * The build context must contain at least a Dockerfile, but may contain other files as well\n\n*Applies to: Azure CLI & Python SDK v2*\n\nTo create a new environment, you must use one of the following approaches:\n* Docker image\n    * Provide the image URI of the image hosted in a registry such as Docker Hub or Azure Container Registry\n    * [Sample here](https://aka.ms/azureml/environment/create-env-docker-image-v2)\n* Docker build context\n    * Specify the directory that will serve as the build context\n    * The directory should contain a Dockerfile and any other files needed to build the image\n    * [Sample here](https://aka.ms/azureml/environment/create-env-build-context-v2)\n* Conda specification \n    * You must specify a base Docker image for the environment; the conda environment will be built on top of the Docker image provided\n    * Provide the relative path to the conda file\n    * [Sample here](https://aka.ms/azureml/environment/create-env-conda-spec-v2)\n\n### Missing Docker definition\n*Applies to: Python SDK v1*\n<!--issueDescription-->\nThis issue can happen when your environment definition is missing a `DockerSection.` This section configures settings related to the final Docker image built from your environment specification.\n \n**Potential causes:**\n* The `DockerSection` of your environment definition isn't defined (null)\n \n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n \n**Troubleshooting steps**\n\n Add a `DockerSection` to your environment definition, specifying either a base image, base dockerfile, or docker build context.\n\n```python\nfrom azureml.core import Environment\nmyenv = Environment(name=\"myenv\")\n# Specify docker steps as a string.\ndockerfile = r'''\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\nRUN echo \"Hello from custom container!\"\n'''\n\nmyenv.docker.base_dockerfile = dockerfile\n```\n \n**Resources**\n* [DockerSection](https://aka.ms/azureml/environment/environment-docker-section)\n\n### Too many Docker options\n<!--issueDescription-->\n \n**Potential causes:**\n\n*Applies to: Python SDK v1*\n\nYou have more than one of these Docker options specified in your environment definition\n* `base_image`\n* `base_dockerfile`\n* `build_context`\n* See [DockerSection](https://aka.ms/azureml/environment/docker-section-class)\n\n*Applies to: Azure CLI & Python SDK v2*\n\nYou have more than one of these Docker options specified in your environment definition\n* `image`\n* `build`\n* See [azure.ai.ml.entities.Environment](https://aka.ms/azureml/environment/environment-class-v2)\n \n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n \n**Troubleshooting steps**\n\nChoose which Docker option you'd like to use to build your environment. Then set all other specified options to None.\n\n*Applies to: Python SDK v1*\n\n```python\nfrom azureml.core import Environment\nmyenv = Environment(name=\"myEnv\")\ndockerfile = r'''\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\nRUN echo \"Hello from custom container!\"\n'''\nmyenv.docker.base_dockerfile = dockerfile\nmyenv.docker.base_image = \"pytorch/pytorch:latest\"\n\n# Having both base dockerfile and base image set will cause failure. Delete the one you won't use.\nmyenv.docker.base_image = None\n```\n\n### Missing Docker option\n<!--issueDescription-->\n \n**Potential causes:**\n\n*Applies to: Python SDK v1*\n\nYou didn't specify one of the following options in your environment definition\n* `base_image`\n* `base_dockerfile`\n* `build_context`\n* See [DockerSection](https://aka.ms/azureml/environment/docker-section-class)\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-environments-128.md"
                }
            },
            {
                "page_content": "* See [how to create a conda file manually](https://aka.ms/azureml/environment/how-to-create-conda-file)\n* See [CondaDependencies class](https://aka.ms/azureml/environment/conda-dependencies-class)\n* See [how to set a conda specification on the environment definition](https://aka.ms/azureml/environment/set-conda-spec-on-environment-definition)\n\n### Invalid conda dependencies\n<!--issueDescription-->\n**Potential causes:**\n* The conda dependencies specified in your environment definition aren't formatted correctly\n\n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n\n*Applies to: Python SDK v1*\n\nEnsure that `conda_dependencies` is a JSONified version of the conda dependencies YAML structure\n\n```json\n\"condaDependencies\": {\n    \"channels\": [\n\t\"anaconda\",\n        \"conda-forge\"\n    ],\n    \"dependencies\": [\n        \"python=3.8\",\n        {\n            \"pip\": [\n                \"azureml-defaults\"\n            ]\n        }\n    ],\n    \"name\": \"project_environment\"\n}\n```\n\nConda dependencies can also be specified using the `add_conda_package` method\n\n```python\nfrom azureml.core.environment import CondaDependencies\n\nenv = Environment(name=\"env\")\nconda_dep = CondaDependencies()\nconda_dep.add_conda_package(\"python==3.8\")\nenv.python.conda_dependencies = conda_dep\n```\n\n*Applies to: Azure CLI & Python SDK v2*\n\nYou must specify a base Docker image for the environment, and the conda environment will be built on top of that image\n* Provide the relative path to the conda file\n* See how to [create an environment from a conda specification](https://aka.ms/azureml/environment/create-env-conda-spec-v2)\n\n**Resources**\n* See [more extensive examples](https://github.com/Azure/MachineLearningNotebooks/blob/9b1e130d18d3c61d41dc225488a4575904897c85/how-to-use-azureml/training/using-environments/using-environments.ipynb)\n* See [how to create a conda file manually](https://aka.ms/azureml/environment/how-to-create-conda-file)\n* See [CondaDependencies class](https://aka.ms/azureml/environment/conda-dependencies-class)\n* See [how to set a conda specification on the environment definition](https://aka.ms/azureml/environment/set-conda-spec-on-environment-definition)\n\n### Missing conda channels\n<!--issueDescription-->\n**Potential causes:**\n* You haven't specified conda channels in your environment definition\n\n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n\nFor reproducibility of your environment, specify channels from which to pull dependencies. If no conda channel is specified, conda will use defaults that might change.\n\n*Applies to: Python SDK v1*\n\nAdd a conda channel using the Python SDK\n\n```python\nfrom azureml.core.environment import CondaDependencies\n\nenv = Environment(name=\"env\")\nconda_dep = CondaDependencies()\nconda_dep.add_channel(\"conda-forge\")\nenv.python.conda_dependencies = conda_dep\n```\n\n*Applies to: all scenarios*\n\nIf you're using a YAML for your conda specification, include the conda channel(s) you'd like to use\n\n```yaml\nname: project_environment\ndependencies:\n  - python=3.8\n  - pip:\n      - azureml-defaults\nchannels:\n  - anaconda\n  - conda-forge\n```\n\n**Resources**\n* See [how to set a conda specification on the environment definition v1](https://aka.ms/azureml/environment/set-conda-spec-on-environment-definition)\n* See [CondaDependencies class](https://aka.ms/azureml/environment/conda-dependencies-class)\n* See how to [create an environment from a conda specification v2](https://aka.ms/azureml/environment/create-env-conda-spec-v2)\n* See [how to create a conda file manually](https://aka.ms/azureml/environment/how-to-create-conda-file)\n\n### Base conda environment not recommended\n<!--issueDescription-->\n**Potential causes:**\n* You specified a base conda environment in your environment definition\n\n**Affected areas (symptoms):**\n* Failure in registering your environment\n<!--/issueDescription-->\n\n**Troubleshooting steps**\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-environments-827.md"
                }
            },
            {
                "page_content": "\n# What are Azure Machine Learning environments?\n\nAzure Machine Learning environments are an encapsulation of the environment where your machine learning training happens. They specify the Python packages, environment variables, and software settings around your training and scoring scripts. They also specify runtimes (Python, Spark, or Docker). The environments are managed and versioned entities within your Machine Learning workspace that enable reproducible, auditable, and portable machine learning workflows across a variety of compute targets.\n\nYou can use an `Environment` object on your local compute to:\n* Develop your training script.\n* Reuse the same environment on Azure Machine Learning Compute for model training at scale.\n* Deploy your model with that same environment.\n* Revisit the environment in which an existing model was trained.\n\nThe following diagram illustrates how you can use a single `Environment` object in both your job configuration (for training) and your inference and deployment configuration (for web service deployments).\n\n![Diagram of an environment in machine learning workflow](./media/concept-environments/ml-environment.png)\n\nThe environment, compute target and training script together form the job configuration: the full specification of a training job.\n\n## Types of environments\n\nEnvironments can broadly be divided into three categories: *curated*, *user-managed*, and *system-managed*.\n\nCurated environments are provided by Azure Machine Learning and are available in your workspace by default. Intended to be used as is, they contain collections of Python packages and settings to help you get started with various machine learning frameworks. These pre-created environments also allow for faster deployment time. For a full list, see the [curated environments article](resource-curated-environments.md).\n\nIn user-managed environments, you're responsible for setting up your environment and installing every package that your training script needs on the compute target. Also be sure to include any dependencies needed for model deployment.\n\nYou use system-managed environments when you want [conda](https://conda.io/docs/) to manage the Python environment for you. A new conda environment is materialized from your conda specification on top of a base docker image.\n\n## Create and manage environments\n\nYou can create environments from clients like the AzureML Python SDK, Azure Machine Learning CLI, Environments page in Azure Machine Learning studio, and [VS Code extension](how-to-manage-resources-vscode.md#create-environment). Every client allows you to customize the base image, Dockerfile, and Python layer if needed.\n\nFor specific code samples, see the \"Create an environment\" section of [How to use environments](how-to-manage-environments-v2.md#create-an-environment). \n\nEnvironments are also easily managed through your workspace, which allows you to:\n\n* Register environments.\n* Fetch environments from your workspace to use for training or deployment.\n* Create a new instance of an environment by editing an existing one.\n* View changes to your environments over time, which ensures reproducibility.\n* Build Docker images automatically from your environments.\n\n\"Anonymous\" environments are automatically registered in your workspace when you submit an experiment. They will not be listed but may be retrieved by version.\n\nFor code samples, see the \"Manage environments\" section of [How to use environments](how-to-manage-environments-v2.md#manage-environments).\n\n## Environment building, caching, and reuse\n\nAzure Machine Learning builds environment definitions into Docker images and conda environments. It also caches the environments so they can be reused in subsequent training jobs and service endpoint deployments. Running a training script remotely requires the creation of a Docker image, but a local job can use a conda environment directly. \n\n### Submitting a job using an environment\n\nWhen you first submit a remote job using an environment, the Azure Machine Learning service invokes an [ACR Build Task](../container-registry/container-registry-tasks-overview.md) on the Azure Container Registry (ACR) associated with the Workspace. The built Docker image is then cached on the Workspace ACR. Curated environments are backed by Docker images that are cached in Global ACR. At the start of the job execution, the image is retrieved by the compute target from the relevant ACR.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-environments-0.md"
                }
            }
        ]
    },
    {
        "query": "How to use Tensorboard to see job output using AzureML SDK V2?",
        "result": "To use Tensorboard to see job output using AzureML SDK V2, you can follow these steps:\n\n1. Define the interactive services you want to use for your job. Make sure to replace `your compute name` with your own value. If you want to use your own custom environment, follow the examples in [this tutorial](how-to-manage-environments-v2.md) to create a custom environment. \n\n   Note that you have to import the `JobService` class from the `azure.ai.ml.entities` package to configure interactive services via the SDKv2. \n\n    ```python\n    command_job = command(...\n        code=\"./src\",  # local path where the code is stored\n        command=\"python main.py\", # you can add a command like \"sleep 1h\" to reserve the compute resource is reserved after the script finishes running\n        environment=\"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\",\n        compute=\"<name-of-compute>\",\n        services={\n          \"My_tensorboard\": JobService(\n            job_service_type=\"tensor_board\",\n            nodes=\"all\",\n            properties={\n                \"logDir\": \"output/tblogs\"  # relative path of Tensorboard logs (same as in your training script)\n            }          \n          ),\n        }\n    )\n\n    # submit the command\n    returned_job = ml_client.jobs.create_or_update(command_job)\n    ```\n\n    The `services` section specifies the training applications you want to interact with. In this case, we are using the `tensor_board` service to enable Tensorboard.\n\n    You can put `sleep <specific time>` at the end of your command to specify the amount of time you want to reserve the compute resource. The format follows: \n    * sleep 1s\n    * sleep 1m\n    * sleep 1h\n    * sleep 1d\n\n    You can also use the `sleep infinity` command that would keep the job alive indefinitely. \n    \n    > [!NOTE]\n    > If you use `sleep infinity`, you will need to manually [cancel the job](./how-to-interactive-jobs.md#end-job) to let go of the compute resource (and stop billing). \n\n2. Submit your training job. For more details on how to train with the Python SDKv2, check out this [article](./how-to-train-model.md).\n\n3. Once the job is running, you can access Tensorboard by clicking on the \"Endpoints\" tab in the job details page. From there, you can click on the \"Open\" button next to the Tensorboard endpoint to launch Tensorboard in a new tab.\n\n   :::image type=\"content\" source=\"./media/interactive-jobs/tensorboard-open.png\" alt-text=\"Screenshot of interactive jobs tensorboard panel when first opened. This information will vary depending upon customer data\":::\n\n4. In Tensorboard, you can navigate to the \"SCALARS\" tab to see the metrics logged by your training script.\n\n   :::image type=\"content\" source=\"./media/interactive-jobs/tensorboard-scalars.png\" alt-text=\"Screenshot of interactive jobs tensorboard scalars panel\":::\n\n   You can also navigate to other tabs to see other types of visualizations, such as histograms and images.\n\n   :::image type=\"content\" source=\"./media/interactive-jobs/tensorboard-histograms.png\" alt-text=\"Screenshot of interactive jobs tensorboard histograms panel\":::\n\n   :::image type=\"content\" source=\"./media/interactive-jobs/tensorboard-images.png\" alt-text=\"Screenshot of interactive jobs tensorboard images panel\":::\n\nIf you don't see the above options, make sure you have enabled the \"Debug & monitor your training jobs\" flight via the [preview panel](./how-to-enable-preview-features.md#how-do-i-enable-preview-features).",
        "context": [
            {
                "page_content": "  > If you use `sleep infinity`, you will need to manually [cancel the job](./how-to-interactive-jobs.md#end-job) to let go of the compute resource (and stop billing). \n\n5. Select the training applications you want to use to interact with the job.\n\n  :::image type=\"content\" source=\"./media/interactive-jobs/select-training-apps.png\" alt-text=\"Screenshot of selecting a training application for the user to use for a job.\":::\n\n6. Review and create the job.\n\nIf you don't see the above options, make sure you have enabled the \"Debug & monitor your training jobs\" flight via the [preview panel](./how-to-enable-preview-features.md#how-do-i-enable-preview-features).\n\n# [Python SDK](#tab/python)\n1. Define the interactive services you want to use for your job. Make sure to replace `your compute name` with your own value. If you want to use your own custom environment, follow the examples in [this tutorial](how-to-manage-environments-v2.md) to create a custom environment. \n\n   Note that you have to import the `JobService` class from the `azure.ai.ml.entities` package to configure interactive services via the SDKv2. \n\n    ```python\n    command_job = command(...\n        code=\"./src\",  # local path where the code is stored\n        command=\"python main.py\", # you can add a command like \"sleep 1h\" to reserve the compute resource is reserved after the script finishes running\n        environment=\"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\",\n        compute=\"<name-of-compute>\",\n        services={\n          \"My_jupyterlab\": JobService(\n            job_service_type=\"jupyter_lab\",\n            nodes=\"all\" # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n          ),\n          \"My_vscode\": JobService(\n            job_service_type=\"vs_code\",\n            nodes=\"all\"\n          ),\n          \"My_tensorboard\": JobService(\n            job_service_type=\"tensor_board\",\n            nodes=\"all\",\n            properties={\n                \"logDir\": \"output/tblogs\"  # relative path of Tensorboard logs (same as in your training script)\n            }          \n          ),\n          \"My_ssh\": JobService(\n            job_service_type=\"ssh\",\n            sshPublicKeys=\"<add-public-key>\",\n            nodes=\"all\"\n            properties={\n                \"sshPublicKeys\":\"<add-public-key>\"\n            }    \n          ),\n        }\n    )\n\n    # submit the command\n    returned_job = ml_client.jobs.create_or_update(command_job)\n    ```\n\n    The `services` section specifies the training applications you want to interact with.  \n\n    You can put `sleep <specific time>` at the end of your command to specify the amount of time you want to reserve the compute resource. The format follows: \n    * sleep 1s\n    * sleep 1m\n    * sleep 1h\n    * sleep 1d\n\n    You can also use the `sleep infinity` command that would keep the job alive indefinitely. \n    \n    > [!NOTE]\n    > If you use `sleep infinity`, you will need to manually [cancel the job](./how-to-interactive-jobs.md#end-job) to let go of the compute resource (and stop billing). \n\n2. Submit your training job. For more details on how to train with the Python SDKv2, check out this [article](./how-to-train-model.md).\n\n# [Azure CLI](#tab/azurecli)\n\n1. Create a job yaml `job.yaml` with below sample content. Make sure to replace `your compute name` with your own value. If you want to use custom environment, follow the examples in [this tutorial](how-to-manage-environments-v2.md) to create a custom environment. \n    ```dotnetcli\n    code: src \n    command: \n      python train.py \n      # you can add a command like \"sleep 1h\" to reserve the compute resource is reserved after the script finishes running.\n    environment: azureml:AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu:41\n    compute: azureml:<your compute name>\n    services:\n        my_vs_code:\n          job_service_type: vs_code\n          nodes: all # For distributed jobs, use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node. Values are \"all\", or compute node index (for ex. \"0\", \"1\" etc.)\n        my_tensor_board:\n          job_service_type: tensor_board\n          properties:\n            logDir: \"output/tblogs\" # relative path of Tensorboard logs (same as in your training script)\n          nodes: all\n        my_jupyter_lab:\n          job_service_type: jupyter_lab\n          nodes: all\n        my_ssh:\n         job_service_type: ssh\n         properties:\n           sshPublicKeys: <paste the entire pub key content>\n         nodes: all\n    ```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-interactive-jobs-50.md"
                }
            },
            {
                "page_content": "- [AzureML registered environment asset](https://github.com/Azure/azureml-examples/tree/sdk-preview/cli/jobs/pipelines-with-components/basics/5b_env_registered). It's referenced in component following `azureml:<environment-name>:<environment-version>` syntax.\n- [public docker image](https://github.com/Azure/azureml-examples/tree/sdk-preview/cli/jobs/pipelines-with-components/basics/5a_env_public_docker_image)\n- [conda file](https://github.com/Azure/azureml-examples/tree/sdk-preview/cli/jobs/pipelines-with-components/basics/5c_env_conda_file) Conda file needs to be used together with a base image.\n\n## Register component for reuse and sharing\n\nWhile some components will be specific to a particular pipeline, the real benefit of components comes from reuse and sharing. Register a component in your Machine Learning workspace to make it available for reuse. Registered components support automatic versioning so you can update the component but assure that pipelines that require an older version will continue to work.  \n\nIn the azureml-examples repository, navigate to the `cli/jobs/pipelines-with-components/basics/1b_e2e_registered_components` directory. \n\nTo register a component, use the `az ml component create` command:\n\n```azurecli\naz ml component create --file train.yml\naz ml component create --file score.yml\naz ml component create --file eval.yml\n```\n\nAfter these commands run to completion, you can see the components in Studio, under Asset -> Components:\n\n:::image type=\"content\" source=\"./media/how-to-create-component-pipelines-cli/registered-components.png\" alt-text=\"Screenshot of Studio showing the components that were just registered.\" lightbox =\"./media/how-to-create-component-pipelines-cli/registered-components.png\":::\n\nSelect a component. You'll see detailed information for each version of the component.\n\nUnder **Details** tab, you'll see basic information of the component like name, created by, version etc. You'll see editable fields for Tags and Description. The tags can be used for adding rapidly searched keywords. The description field supports Markdown formatting and should be used to describe your component's functionality and basic use.\n\nUnder **Jobs** tab, you'll see the history of all jobs that use this component.\n\n:::image type=\"content\" source=\"./media/how-to-create-component-pipelines-cli/registered-components.png\" alt-text=\"Screenshot of the component tab showing 3 components.\" lightbox =\"./media/how-to-create-component-pipelines-cli/registered-components.png\":::\n\n### Use registered components in a pipeline job YAML file\n\nLet's use `1b_e2e_registered_components` to demo how to use registered component in pipeline YAML. Navigate to `1b_e2e_registered_components` directory, open the `pipeline.yml` file. The keys and values in the `inputs` and `outputs` fields are similar to those already discussed. The only significant difference is the value of the `component` field in the `jobs.<JOB_NAME>.component` entries. The `component` value is of the form `azureml:<COMPONENT_NAME>:<COMPONENT_VERSION>`. The `train-job` definition, for instance, specifies the latest version of the registered component `my_train` should be used:\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\ntype: pipeline\ndisplay_name: 1b_e2e_registered_components\ndescription: E2E dummy train-score-eval pipeline with registered components\n\ninputs:\n  pipeline_job_training_max_epocs: 20\n  pipeline_job_training_learning_rate: 1.8\n  pipeline_job_learning_rate_schedule: 'time-based'\n\noutputs: \n  pipeline_job_trained_model:\n    mode: upload\n  pipeline_job_scored_data:\n    mode: upload\n  pipeline_job_evaluation_report:\n    mode: upload\n\nsettings:\n default_compute: azureml:cpu-cluster\n\njobs:\n  train_job:\n    type: command\n    component: azureml:my_train@latest\n    inputs:\n      training_data: \n        type: uri_folder \n        path: ./data      \n      max_epocs: ${{parent.inputs.pipeline_job_training_max_epocs}}\n      learning_rate: ${{parent.inputs.pipeline_job_training_learning_rate}}\n      learning_rate_schedule: ${{parent.inputs.pipeline_job_learning_rate_schedule}}\n    outputs:\n      model_output: ${{parent.outputs.pipeline_job_trained_model}}\n    services: \n      my_vscode: \n        job_service_type: vs_code\n      my_jupyter_lab: \n        job_service_type: jupyter_lab\n      my_tensorboard:\n        job_service_type: tensor_board\n        properties:\n          logDir: \"outputs/tblogs\"\n    #  my_ssh:\n    #    job_service_type: tensor_board\n    #    properties:\n    #      sshPublicKeys: <paste the entire pub key content>\n    #    nodes: all # Use the `nodes` property to pick which node you want to enable interactive services on. If `nodes` are not selected, by default, interactive applications are only enabled on the head node.\n  \n  score_job:\n    type: command\n    component: azureml:my_score@latest\n    inputs:\n      model_input: ${{parent.jobs.train_job.outputs.model_output}}\n      test_data: \n        type: uri_folder \n        path: ./data\n    outputs:\n      score_output: ${{parent.outputs.pipeline_job_scored_data}}\n\n  evaluate_job:\n    type: command\n    component: azureml:my_eval@latest\n    inputs:\n      scoring_result: ${{parent.jobs.score_job.outputs.score_output}}\n    outputs:\n      eval_output: ${{parent.outputs.pipeline_job_evaluation_report}}\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-create-component-pipelines-cli-216.md"
                }
            },
            {
                "page_content": "When you click on the endpoints to interact when your job, you're taken to the user container under your working directory, where you can access your code, inputs, outputs, and logs. If you run into any issues while connecting to the applications, the interactive capability and applications logs can be found from **system_logs->interactive_capability** under **Outputs + logs** tab.\n\n:::image type=\"content\" source=\"./media/interactive-jobs/interactive-logs.png\" alt-text=\"Screenshot of interactive jobs interactive logs panel location.\":::\n\n- You can open a terminal from Jupyter Lab and start interacting within the job container. You can also directly iterate on your training script with Jupyter Lab. \n\n  :::image type=\"content\" source=\"./media/interactive-jobs/jupyter-lab.png\" alt-text=\"Screenshot of interactive jobs Jupyter lab content panel.\":::\n\n- You can also interact with the job container within VS Code. To attach a debugger to a job during job submission and pause execution, [navigate here](./how-to-interactive-jobs.md#attach-a-debugger-to-a-job).\n\n  :::image type=\"content\" source=\"./media/interactive-jobs/vs-code-open.png\" alt-text=\"Screenshot of interactive jobs VS Code panel when first opened. This shows the sample python file that was created to print two lines.\":::\n\n- If you have logged tensorflow events for your job, you can use TensorBoard to monitor the metrics when your job is running.\n\n  :::image type=\"content\" source=\"./media/interactive-jobs/tensorboard-open.png\" alt-text=\"Screenshot of interactive jobs tensorboard panel when first opened. This information will vary depending upon customer data\":::\n  \nIf you don't see the above options, make sure you have enabled the \"Debug & monitor your training jobs\" flight via the [preview panel](./how-to-enable-preview-features.md#how-do-i-enable-preview-features).\n\n### End job\nOnce you're done with the interactive training, you can also go to the job details page to cancel the job which will release the compute resource. Alternatively, use `az ml job cancel -n <your job name>` in the CLI or `ml_client.job.cancel(\"<job name>\")` in the SDK. \n\n:::image type=\"content\" source=\"./media/interactive-jobs/cancel-job.png\" alt-text=\"Screenshot of interactive jobs cancel job option and its location for user selection\":::\n\n## Attach a debugger to a job\nTo submit a job with a debugger attached and the execution paused, you can use debugpy and VS Code (`debugpy` must be installed in your job environment). \n\n1. During job submission (either through the UI, the CLIv2 or the SDKv2) use the debugpy command to run your python script. For example, the below screenshot shows a sample command that uses debugpy to attach the debugger for a tensorflow script (`tfevents.py` can be replaced with the name of your training script).\n   \n:::image type=\"content\" source=\"./media/interactive-jobs/use-debugpy.png\" alt-text=\"Screenshot of interactive jobs configuration of debugpy\":::\n\n2. Once the job has been submitted, [connect to the VS Code](./how-to-interactive-jobs.md#connect-to-endpoints), and click on the in-built debugger.\n   \n   :::image type=\"content\" source=\"./media/interactive-jobs/open-debugger.png\" alt-text=\"Screenshot of interactive jobs location of open debugger on the left side panel\":::\n\n3. Use the \"Remote Attach\" debug configuration to attach to the submitted job and pass in the path and port you configured in your job submission command. You can also find this information on the job details page.\n   \n   :::image type=\"content\" source=\"./media/interactive-jobs/debug-path-and-port.png\" alt-text=\"Screenshot of interactive jobs completed jobs\":::\n\n   :::image type=\"content\" source=\"./media/interactive-jobs/remote-attach.png\" alt-text=\"Screenshot of interactive jobs add a remote attach button\":::\n\n4. Set breakpoints and walk through your job execution as you would in your local debugging workflow. \n   \n    :::image type=\"content\" source=\"./media/interactive-jobs/set-breakpoints.png\" alt-text=\"Screenshot of location of an example breakpoint that is set in the Visual Studio Code editor\":::\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-interactive-jobs-194.md"
                }
            }
        ]
    }
]