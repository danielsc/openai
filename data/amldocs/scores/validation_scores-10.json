[
    {
        "query": "can you give me an example of a yaml file to train a model with the CLI v2?",
        "result": "Certainly! Here's an example YAML file that can be used to define an Azure ML pipeline for training a machine learning model:\n\n```yaml\n# pipeline.yml\n\nname: my-pipeline\ndescription: Example pipeline to train a machine learning model\n\n# Define environment(s) for this pipeline (optional)\nenvironments:\n  my-env:\n    docker:\n      enabled: true\n      base_image: mcr.microsoft.com/azureml/base:latest\n    python:\n      packages:\n        - foo\n        - bar==1.0.0\n\n# Define compute target(s) to run this pipeline\ncomputes:\n  my-compute: # The name of the compute resource you want to execute your code/resource on\n    vm_size: standard_d2_v2 # The Azure VM size to use for this compute resource\n    min_nodes: 0 # Optional. Minimum number of nodes for the compute target. If not provided, the minimum is 0\n    max_nodes: 4 # Optional. Max number of nodes for the compute target. If not provided, the maximum is 4\n    idle_seconds_before_scaledown: 300 # Optional. Number of seconds idle before scaling down compute resource. Default is 300 (5 min)\n    remote_login_port_publicaccess: Enabled # Optional. Enable or disable SSH or Remote Desktop access to compute instance.\n\n# Define a single step in the pipeline\nsteps:\n- name: training\n  arguments:\n    script: my_training_script.py\n    inputs:\n      data: /path/to/training/data\n    outputs:\n      model: /path/to/persisted/model\n  run_specs:\n    compute: my-compute\n    environment: my-env\n  is_exit_step: false # Optional. Indicates whether this is the last step in the pipeline. Default is false.\n\n# Define the pipeline\npipeline: \n  endpoint: /subscriptions/{subscription-id}/resourceGroups/{resource-group-name}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/endpoints/{pipeline-end-point-name}\n```\n\nThis YAML file defines a pipeline with a single step for training a machine learning model. The pipeline will execute on a compute target called `my-compute`. The step will execute a Python script called `my_training_script.py` that expects training data to be inputted from `/path/to/training/data`, and will output a trained model to `/path/to/persisted/model`. Finally, the pipeline itself is defined and points to the end point location. \n\nFor more information on creating and running machine learning pipelines using components with the Azure Machine Learning CLI v2, refer to the [official documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-machine-learning-pipelines-cli).",
        "context": [
            {
                "page_content": "\n# Create and run machine learning pipelines using components with the Azure Machine Learning CLI\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n\nIn this article, you learn how to create and run [machine learning pipelines](concept-ml-pipelines.md) by using the Azure CLI and components (for more, see [What is an Azure Machine Learning component?](concept-component.md)). You can create pipelines without using components, but components offer the greatest amount of flexibility and reuse. AzureML Pipelines may be defined in YAML and run from the CLI, authored in Python, or composed in AzureML Studio Designer with a drag-and-drop UI. This document focuses on the CLI.\n\n## Prerequisites\n\n- If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n\n- An Azure Machine Learning workspace. [Create workspace resources](quickstart-create-resources.md).\n\n- [Install and set up the Azure CLI extension for Machine Learning](how-to-configure-cli.md).\n\n- Clone the examples repository:\n\n    ```azurecli-interactive\n    git clone https://github.com/Azure/azureml-examples --depth 1\n    cd azureml-examples/cli/jobs/pipelines-with-components/basics\n    ```\n\n### Suggested pre-reading\n\n- [What is Azure Machine Learning pipeline](./concept-ml-pipelines.md)\n- [What is Azure Machine Learning component](./concept-component.md)\n\n## Create your first pipeline with component\n\nLet's create your first pipeline with component using an example. This section aims to give you an initial impression of what pipeline and component look like in AzureML with a concrete example.\n\nFrom the `cli/jobs/pipelines-with-components/basics` directory of the [`azureml-examples` repository](https://github.com/Azure/azureml-examples), navigate to the `3b_pipeline_with_data` subdirector. There are three types of files in this directory. Those are the files you'll need to create when building your own pipeline.\n\n- **pipeline.yml**: This YAML file defines the machine learning pipeline. This YAML file describes how to break a full machine learning task into a multistep workflow. For example, considering a simple machine learning task of using historical data to train a sales forecasting model, you may want to build a sequential workflow with data processing, model training, and model evaluation steps.  Each step is a component that has well defined interface and can be developed, tested, and optimized independently. The pipeline YAML also defines how the child steps connect to other steps in the pipeline, for example the model training step generate a model file and the model file will pass to a model evaluation step.\n\n- **component.yml**:  This YAML file defines the component. It packages following information:\n  - Metadata: name, display name, version, description, type etc. The metadata helps to describe and manage the component.\n  - Interface: inputs and outputs. For example, a model training component will take training data and number of epochs as input, and generate a trained model file as output. Once the interface is defined, different teams can develop and test the component independently.\n  - Command, code & environment: the command, code and environment to run the component.    Command is the shell command to execute the component. Code usually refers to a source  code directory. Environment could be an AzureML environment(curated or customer created), docker image or conda environment.  \n\n- **component_src**: This is the source code directory for a specific component. It contains the source code that will be executed in the component. You can use your preferred language(Python, R...). The code must be executed by a shell command. The source code can take a few inputs from shell command line to control how this step is going to be executed. For example, a training step may take training data, learning rate, number of epochs to control the training process. The argument of a shell command is used to pass inputs and outputs to the code. \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-create-component-pipelines-cli-0.md"
                }
            },
            {
                "page_content": "\nYou can define a search space with customized settings:\n\n```python \ntext_ner_job.extend_search_space( \n    [ \n        SearchSpace( \n            model_name=Choice([NlpModels.BERT_BASE_CASED, NlpModels.ROBERTA_BASE]) \n        ), \n        SearchSpace( \n            model_name=Choice([NlpModels.DISTILROBERTA_BASE]), \n            learning_rate_scheduler=Choice([NlpLearningRateScheduler.LINEAR,  \n                                            NlpLearningRateScheduler.COSINE]), \n            learning_rate=Uniform(5e-6, 5e-5) \n        ) \n    ] \n) \n ```\n\nYou can configure the sweep procedure via sampling algorithm early termination: \n```python\ntext_ner_job.set_sweep( \n    sampling_algorithm=\"Random\", \n    early_termination=BanditPolicy( \n        evaluation_interval=2, slack_factor=0.05, delay_evaluation=6 \n    ) \n) \n```\n\n\n### Sampling methods for the sweep \n\nWhen sweeping hyperparameters, you need to specify the sampling method to use for sweeping over the defined parameter space. Currently, the following sampling methods are supported with the `sampling_algorithm` parameter:\n\n| Sampling type | AutoML Job syntax |\n|-------|---------|\n|[Random Sampling](how-to-tune-hyperparameters.md#random-sampling)| `random` |\n|[Grid Sampling](how-to-tune-hyperparameters.md#grid-sampling)| `grid` |\n|[Bayesian Sampling](how-to-tune-hyperparameters.md#bayesian-sampling)| `bayesian` |\n\n### Experiment budget \n\nYou can optionally specify the experiment budget for your AutoML NLP training job using the `timeout_minutes` parameter in the `limits` - the amount of time in minutes before the experiment terminates. If none specified, the default experiment timeout is seven days (maximum 60 days).  \n\nAutoML NLP also supports `trial_timeout_minutes`, the maximum amount of time in minutes an individual trial can run before being terminated, and `max_nodes`, the maximum number of nodes from the backing compute cluster to leverage for the job. These parameters also belong to the `limits` section.  \n\n\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\nlimits: \n  timeout_minutes: 60 \n  trial_timeout_minutes: 20 \n  max_nodes: 2 \n```\n\n\n### Early termination policies  \n\nYou can automatically end poorly performing runs with an early termination policy. Early termination improves computational efficiency, saving compute resources that would have been otherwise spent on less promising configurations. AutoML NLP supports early termination policies using the `early_termination` parameter. If no termination policy is specified, all configurations are run to completion. \n\nLearn more about [how to configure the early termination policy for your hyperparameter sweep.](how-to-tune-hyperparameters.md#early-termination) \n\n### Resources for the sweep\n\nYou can control the resources spent on your hyperparameter sweep by specifying the `max_trials` and the `max_concurrent_trials` for the sweep.\n\nParameter | Detail\n-----|----\n`max_trials` |  Parameter for maximum number of configurations to sweep. Must be an integer between 1 and 1000. When exploring just the default hyperparameters for a given model algorithm, set this parameter to 1. The default value is 1.\n`max_concurrent_trials`| Maximum number of runs that can run concurrently. If specified, must be an integer between 1 and 100.  The default value is 1. <br><br> **NOTE:** <li> The number of concurrent runs is gated on the resources available in the specified compute target. Ensure that the compute target has the available resources for the desired concurrency.  <li> `max_concurrent_trials` is capped at `max_trials` internally. For example, if user sets `max_concurrent_trials=4`, `max_trials=2`, values would be internally updated as `max_concurrent_trials=2`, `max_trials=2`.\n\nYou can configure all the sweep related parameters as shown in the example below.\n\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\nsweep:\n  limits:\n    max_trials: 10\n    max_concurrent_trials: 2\n  sampling_algorithm: random\n  early_termination:\n    type: bandit\n    evaluation_interval: 2\n    slack_factor: 0.2\n    delay_evaluation: 6\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-auto-train-nlp-models-416.md"
                }
            },
            {
                "page_content": "\n# What is Azure Machine Learning CLI & Python SDK v2?\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\nAzure Machine Learning CLI v2 and Azure Machine Learning Python SDK v2 introduce a consistency of features and terminology across the interfaces.  In order to create this consistency, the syntax of commands differs, in some cases significantly, from the first versions (v1).\n\n## Azure Machine Learning CLI v2\n\nThe Azure Machine Learning CLI v2 (CLI v2) is the latest extension for the [Azure CLI](/cli/azure/what-is-azure-cli). The CLI v2 provides commands in the format *az ml __\\<noun\\> \\<verb\\> \\<options\\>__* to create and maintain Azure ML assets and workflows. The assets or workflows themselves are defined using a YAML file. The YAML file defines the configuration of the asset or workflow \u2013 what is it, where should it run, and so on.\n\nA few examples of CLI v2 commands:\n\n* `az ml job create --file my_job_definition.yaml`\n* `az ml environment update --name my-env --file my_updated_env_definition.yaml`\n* `az ml model list`\n* `az ml compute show --name my_compute`\n\n### Use cases for CLI v2\n\nThe CLI v2 is useful in the following scenarios:\n\n* On board to Azure ML without the need to learn a specific programming language\n\n    The YAML file defines the configuration of the asset or workflow \u2013 what is it, where should it run, and so on. Any custom logic/IP used, say data preparation, model training, model scoring can remain in script files, which are referred to in the YAML, but not part of the YAML itself. Azure ML supports script files in python, R, Java, Julia or C#. All you need to learn is YAML format and command lines to use Azure ML. You can stick with script files of your choice.\n\n* Ease of deployment and automation\n\n    The use of command-line for execution makes deployment and automation simpler, since workflows can be invoked from any offering/platform, which allows users to call the command line.\n\n* Managed inference deployments\n\n    Azure ML offers [endpoints](concept-endpoints.md) to streamline model deployments for both real-time and batch inference deployments. This functionality is available only via CLI v2 and SDK v2.\n\n* Reusable components in pipelines\n\n    Azure ML introduces [components](concept-component.md) for managing and reusing common logic across pipelines. This functionality is available only via CLI v2 and SDK v2.\n\n\n## Azure Machine Learning Python SDK v2\n\nAzure ML Python SDK v2 is an updated Python SDK package, which allows users to:\n\n* Submit training jobs\n* Manage data, models, environments\n* Perform managed inferencing (real time and batch)\n* Stitch together multiple tasks and production workflows using Azure ML pipelines\n\nThe SDK v2 is on par with CLI v2 functionality and is consistent in how assets (nouns) and actions (verbs) are used between SDK and CLI.  For example, to list an asset, the `list` action can be used in both CLI and SDK. The same `list` action can be used to list a compute, model, environment, and so on.\n\n### Use cases for SDK v2\n\nThe SDK v2 is useful in the following scenarios:\n\n* Use Python functions to build a single step or a complex workflow\n\n    SDK v2 allows you to build a single command or a chain of commands like Python functions - the command has a name, parameters, expects input, and returns output.\n\n* Move from simple to complex concepts incrementally\n\n    SDK v2 allows you to: \n    * Construct a single command.\n    * Add a hyperparameter sweep on top of that command, \n    * Add the command with various others into a pipeline one after the other. \n    \n    This construction is useful, given the iterative nature of machine learning.\n\n* Reusable components in pipelines\n\n    Azure ML introduces [components](concept-component.md) for managing and reusing common logic across pipelines. This functionality is available only via CLI v2 and SDK v2.\n\n* Managed inferencing\n\n    Azure ML offers [endpoints](concept-endpoints.md) to streamline model deployments for both real-time and batch inference deployments. This functionality is available only via CLI v2 and SDK v2.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-v2-0.md"
                }
            }
        ]
    },
    {
        "query": "how can I run a job under the user's identity using CLI v2? Please provide a concrete example of a yaml file.",
        "result": "To run a batch deployment job under the user's identity using CLI v2, you can create a YAML file similar to the following example:\n\n```\n$schema: https://azuremlschemas.azureedge.net/latest/job-1.0.0.yaml\nname: sample-job\ncompute:\n  target: \"local\"\ntype: automl\ntask: image_classification\ntraining_data:\n  source: \n    type: azure_blob_mount\n    container_name: my_container\n    account_name: my_account\n  use_training_data: true\n  target_column_name: ImageFolder\n  ignore_column_identifiers: []\nprimary_metric: accuracy\nallowed_models: []\nfeaturization: {}\nmodel_explainability: false\nmodel_interaction: false\nexit_score_retries: 1\nallowed_exit_scores: []\n```\n\nThen, you can run the job with the following command:\n\n```\naz ml job create --file myjob.yaml\n```\n\nPlease note that the `--file` argument must include the relative or absolute path to your YAML file.",
        "context": [
            {
                "page_content": "\n# Authorization on batch endpoints\n\nBatch endpoints support Azure Active Directory authentication, or `aad_token`. That means that in order to invoke a batch endpoint, the user must present a valid Azure Active Directory authentication token to the batch endpoint URI. Authorization is enforced at the endpoint level. The following article explains how to correctly interact with batch endpoints and the security requirements for it. \n\n## Prerequisites\n\n* This example assumes that you have a model correctly deployed as a batch endpoint. Particularly, we are using the *heart condition classifier* created in the tutorial [Using MLflow models in batch deployments](how-to-mlflow-batch.md).\n\n## How authorization works\n\nTo invoke a batch endpoint, the user must present a valid Azure Active Directory token representing a __security principal__. This principal can be a __user principal__ or a __service principal__. In any case, once an endpoint is invoked, a batch deployment job is created under the identity associated with the token. The identity needs the following permissions in order to successfully create a job:\n\n> [!div class=\"checklist\"]\n> * Read batch endpoints/deployments.\n> * Create jobs in batch inference endpoints/deployment.\n> * Create experiments/runs.\n> * Read and write from/to data stores.\n> * Lists datastore secrets.\n\nYou can either use one of the [built-in security roles](../role-based-access-control/built-in-roles.md) or create a new one. In any case, the identity used to invoke the endpoints requires to be granted the permissions explicitly. See [Steps to assign an Azure role](../role-based-access-control/role-assignments-steps.md) for instructions to assign them.\n\n> [!IMPORTANT]\n> The identity used for invoking a batch endpoint may not be used to read the underlying data depending on how the data store is configured. Please see [Security considerations when reading data](how-to-access-data-batch-endpoints-jobs.md#security-considerations-when-reading-data) for more details.\n\n## How to run jobs using different types of credentials\n\nThe following examples show different ways to start batch deployment jobs using different types of credentials:\n\n> [!IMPORTANT] \n> When working on a private link-enabled workspaces, batch endpoints can't be invoked from the UI in Azure ML studio. Please use the Azure ML CLI v2 instead for job creation.\n\n### Running jobs using user's credentials\n\nIn this case, we want to execute a batch endpoint using the identity of the user currently logged in. Follow these steps:\n\n> [!NOTE]\n> When working on Azure ML studio, batch endpoints/deployments are always executed using the identity of the current user logged in.\n\n# [Azure CLI](#tab/cli)\n\n1. Use the Azure CLI to log in using either interactive or device code authentication:\n\n    ```azurecli\n    az login\n    ```\n\n1. Once authenticated, use the following command to run a batch deployment job:\n\n    ```azurecli\n    az ml batch-endpoint invoke --name $ENDPOINT_NAME --input https://azuremlexampledata.blob.core.windows.net/data/heart-disease-uci\n    ```\n\n# [Python](#tab/sdk)\n\n1. Use the Azure ML SDK for Python to log in using either interactive or device authentication:\n\n    ```python\n    from azure.ai.ml import MLClient\n    from azure.identity import InteractiveAzureCredentials\n\n    subscription_id = \"<subscription>\"\n    resource_group = \"<resource-group>\"\n    workspace = \"<workspace>\"\n\n    ml_client = MLClient(InteractiveAzureCredentials(), subscription_id, resource_group, workspace)\n    ```\n\n1. Once authenticated, use the following command to run a batch deployment job:\n\n    ```python\n    job = ml_client.batch_endpoints.invoke(\n            endpoint_name, \n            input=Input(path=\"https://azuremlexampledata.blob.core.windows.net/data/heart-disease-uci\")\n        )\n    ```\n\n# [REST](#tab/rest)\n\nWhen working with REST APIs, we recommend to using either a [service principal](#running-jobs-using-a-service-principal) or a [managed identity](#running-jobs-using-a-managed-identity) to interact with the API.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-authenticate-batch-endpoint-0.md"
                }
            },
            {
                "page_content": "\n# CLI (v2) compute instance YAML schema\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nThe source JSON schema can be found at https://azuremlschemas.azureedge.net/latest/computeInstance.schema.json.\n\n\n\n[!INCLUDE [schema note](../../includes/machine-learning-preview-old-json-schema-note.md)]\n\n## YAML syntax\n\n| Key | Type | Description | Allowed values | Default value |\n| --- | ---- | ----------- | -------------- | ------- |\n| `$schema` | string | The YAML schema. If you use the Azure Machine Learning VS Code extension to author the YAML file, including `$schema` at the top of your file enables you to invoke schema and resource completions. | | |\n| `type` | string | **Required.** The type of compute. | `computeinstance` | |\n| `name` | string | **Required.** Name of the compute. | | |\n| `description` | string | Description of the compute. | | |\n| `size` | string | The VM size to use for the compute instance. For more information, see [Supported VM series and sizes](concept-compute-target.md#supported-vm-series-and-sizes). Note that not all sizes are available in all regions. | For the list of supported sizes in a given region, please use the `az ml compute list-sizes` command.  | `Standard_DS3_v2` |\n| `create_on_behalf_of` | object | Settings for creating the compute instance on behalf of another user. Please ensure that the assigned user has correct RBAC permissions. |  |  |\n| `create_on_behalf_of.user_tenant_id` | string | The AAD Tenant ID of the assigned user. |  |  |\n| `create_on_behalf_of.user_object_id` | string | The AAD Object ID of the assigned user. |  |  |\n| `ssh_public_access_enabled` | boolean | Whether to enable public SSH access on the compute instance. | | `false` |\n| `ssh_settings` | object | SSH settings for connecting to the compute instance. | | |\n| `ssh_settings.ssh_key_value` | string | The SSH public key of the administrator user account. | | |\n| `network_settings` | object | Network security settings. | | |\n| `network_settings.vnet_name` | string | Name of the virtual network (VNet) when creating a new one or referencing an existing one. | | |\n| `network_settings.subnet` | string | Either the name of the subnet when creating a new VNet or referencing an existing one, or the fully qualified resource ID of a subnet in an existing VNet. Do not specify `network_settings.vnet_name` if the subnet ID is specified. The subnet ID can refer to a VNet/subnet in another resource group. | | |\n| `identity` | object | The managed identity configuration to assign to the compute. AmlCompute clusters support only one system-assigned identity or multiple user-assigned identities, not both concurrently. | | |\n| `identity.type` | string | The type of managed identity to assign to the compute. If the type is `user_assigned`, the `identity.user_assigned_identities` property must also be specified. | `system_assigned`, `user_assigned` | |\n| `identity.user_assigned_identities` | array | List of fully qualified resource IDs of the user-assigned identities. | | |\n\n## Remarks\n\nThe `az ml compute` command can be used for managing Azure Machine Learning compute instances.\n\n## YAML: minimal\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/computeInstance.schema.json\nname: minimal-example-i\ntype: computeinstance\n\n```\n\n## YAML: basic\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/computeInstance.schema.json \nname: basic-example-i\ntype: computeinstance\nsize: STANDARD_DS3_v2\n\n```\n\n## Next steps\n\n- [Install and use the CLI (v2)](how-to-configure-cli.md)\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-yaml-compute-instance-0.md"
                }
            },
            {
                "page_content": "\n# CLI (v2) Automated ML image classification job YAML schema\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nThe source JSON schema can be found at https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLImageClassificationJob.schema.json.\n\n\n\n[!INCLUDE [schema note](../../includes/machine-learning-preview-old-json-schema-note.md)]\n\n## YAML syntax\n\n| Key | Type | Description | Allowed values | Default value |\n| --- | ---- | ----------- | -------------- | ------------- |\n| `$schema` | string | The YAML schema. If the user uses the Azure Machine Learning VS Code extension to author the YAML file, including `$schema` at the top of the file enables the user to invoke schema and resource completions. | | |\n| `type` | const | **Required.** The type of job. | `automl` | `automl` |\n| `task` | const | **Required.** The type of AutoML task. | `image_classification` | `image_classification` |\n| `name` | string | Name of the job. Must be unique across all jobs in the workspace. If omitted, Azure ML will autogenerate a GUID for the name. | | |\n| `display_name` | string | Display name of the job in the studio UI. Can be non-unique within the workspace. If omitted, Azure ML will autogenerate a human-readable adjective-noun identifier for the display name. | | |\n| `experiment_name` | string | Experiment name to organize the job under. Each job's run record will be organized under the corresponding experiment in the studio's \"Experiments\" tab. If omitted, Azure ML will default it to the name of the working directory where the job was created. | | |\n| `description` | string | Description of the job. | | |\n| `tags` | object | Dictionary of tags for the job. | | |\n| `compute` | string | Name of the compute target to execute the job on. This compute can be either a reference to an existing compute in the workspace (using the `azureml:<compute_name>` syntax) or `local` to designate local execution. For more information on compute for AutoML image jobs, see [Compute to run experiment](./how-to-auto-train-image-models.md?tabs=cli#compute-to-run-experiment) section.<br> <br>  *Note:* jobs in pipeline don't support `local` as `compute`. * | | `local` |\n| `log_verbosity` | number | Different levels of log verbosity. |`not_set`, `debug`, `info`, `warning`, `error`, `critical` | `info` |\n| `primary_metric` | string |  The metric that AutoML will optimize for model selection. |`accuracy` | `accuracy` |\n| `target_column_name` | string |  **Required.** The name of the column to target for predictions. It must always be specified. This parameter is applicable to `training_data` and `validation_data`. | |  |\n| `training_data` | object |  **Required.** The data to be used within the job. It should contain both training feature columns and a target column. The parameter training_data must always be provided. For more information on keys and their descriptions, see [Training or validation data](#training-or-validation-data) section. For an example, see [Consume data](./how-to-auto-train-image-models.md?tabs=cli#consume-data) section. | |  |\n| `validation_data` | object |  The validation data to be used within the job. It should contain both training features and label column (optionally a sample weights column). If `validation_data` is specified, then `training_data` and `target_column_name` parameters must be specified. For more information on keys and their descriptions, see [Training or validation data](#training-or-validation-data) section. For an example, see [Consume data](./how-to-auto-train-image-models.md?tabs=cli#consume-data) section| |  |\n| `validation_data_size` | float |  What fraction of the data to hold out for validation when user validation data isn't specified. | A value in range (0.0, 1.0) |  |\n| `limits` | object | Dictionary of limit configurations of the job. The key is name for the limit within the context of the job and the value is limit value. For more information, see [Configure your experiment settings](./how-to-auto-train-image-models.md?tabs=cli#job-limits) section. | | |\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-automl-images-cli-classification-0.md"
                }
            }
        ]
    },
    {
        "query": "how can I use my csv file in a job using the v2 cli?",
        "result": "You can use a YAML file to specify the job that you want to execute. You can pass the CSV file as an input to the job so that you can use it in your script. Here is an example YAML file where we use an `InputDirectory` named `input` to pass a CSV file to the job as input:\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/CommandJob.schema.json\n\ncode: src\ncommand: python my_script.py --input-file ${{inputs.input}}\ninputs:\n  input:\n    type: InputDirectory\n    path: ./data\nenvironment: azureml:AzureML-Minimal@latest\ncompute: local\n```\n\nIn this YAML file, `src` is the code directory, `my_script.py` is the script you want to execute, and `./data` is the directory containing your CSV file. You can execute this job using the following command:\n\n```azurecli\naz ml job create --file job.yml\n```\n\nThis command submits the job to the default environment and compute `(compute=local)`. If you want to submit the job to a remote compute (e.g. a cluster), you can modify the `compute` field in the YAML file accordingly.",
        "context": [
            {
                "page_content": "\n\n### 2. Create a compute resource for training\n\nAn AzureML compute cluster is a fully managed compute resource that can be used to run the training job. In the following examples, a compute cluster named `cpu-compute` is created.\n\n# [Python SDK](#tab/python)\n\n```python\nfrom azure.ai.ml.entities import AmlCompute\n\n# specify aml compute name.\ncpu_compute_target = \"cpu-cluster\"\n\ntry:\n    ml_client.compute.get(cpu_compute_target)\nexcept Exception:\n    print(\"Creating a new cpu compute target...\")\n    compute = AmlCompute(\n        name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4\n    )\n    ml_client.compute.begin_create_or_update(compute).result()\n```\n\n# [Azure CLI](#tab/azurecli)\n\n```azurecli\naz ml compute create -n cpu-cluster --type amlcompute --min-instances 0 --max-instances 4\n```\n\n# [REST API](#tab/restapi)\n\n```bash\ncurl -X PUT \\\n  \"https://management.azure.com/subscriptions/$SUBSCRIPTION_ID/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.MachineLearningServices/workspaces/$WORKSPACE/computes/$COMPUTE_NAME?api-version=$API_VERSION\" \\\n  -H \"Authorization:Bearer $TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"location\": \"'$LOCATION'\",\n    \"properties\": {\n        \"computeType\": \"AmlCompute\",\n        \"properties\": {\n            \"vmSize\": \"Standard_D2_V2\",\n            \"vmPriority\": \"Dedicated\",\n            \"scaleSettings\": {\n                \"maxNodeCount\": 4,\n                \"minNodeCount\": 0,\n                \"nodeIdleTimeBeforeScaleDown\": \"PT30M\"\n            }\n        }\n    }\n}'\n```\n\n> [!TIP]\n> While a response is returned after a few seconds, this only indicates that the creation request has been accepted. It can take several minutes for the cluster creation to finish.\n\n\n### 4. Submit the training job\n\n# [Python SDK](#tab/python)\n\nTo run this script, you'll use a `command`. The command will be run by submitting it as a `job` to Azure ML. \n\n```python\nfrom azure.ai.ml import command, Input\n\n# define the command\ncommand_job = command(\n    code=\"./src\",\n    command=\"python main.py --iris-csv ${{inputs.iris_csv}} --learning-rate ${{inputs.learning_rate}} --boosting ${{inputs.boosting}}\",\n    environment=\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest\",\n    inputs={\n        \"iris_csv\": Input(\n            type=\"uri_file\",\n            path=\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\",\n        ),\n        \"learning_rate\": 0.9,\n        \"boosting\": \"gbdt\",\n    },\n    compute=\"cpu-cluster\",\n)\n```\n\n```python\n# submit the command\nreturned_job = ml_client.jobs.create_or_update(command_job)\n# get a URL for the status of the job\nreturned_job.studio_url\n```\n\nIn the above examples, you configured:\n- `code` - path where the code to run the command is located\n- `command` -  command that needs to be run\n- `environment` - the environment needed to run the training script. In this example, we use a curated or ready-made environment provided by AzureML called `AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu`. We use the latest version of this environment by using the `@latest` directive. You can also use custom environments by specifying a base docker image and specifying a conda yaml on top of it.\n- `inputs` - dictionary of inputs using name value pairs to the command. The key is a name for the input within the context of the job and the value is the input value. Inputs are referenced in the `command` using the `${{inputs.<input_name>}}` expression. To use files or folders as inputs, you can use the `Input` class.\n\nFor more information, see the [reference documentation](/python/api/azure-ai-ml/azure.ai.ml#azure-ai-ml-command).\n\nWhen you submit the job, a URL is returned to the job status in the AzureML studio. Use the studio UI to view the job progress. You can also use `returned_job.status` to check the current status of the job.\n\n# [Azure CLI](#tab/azurecli)\n\nThe `az ml job create` command used in this example requires a YAML job definition file. The contents of the file used in this example are:\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-train-model-660.md"
                }
            },
            {
                "page_content": "If the CLI or SDK code defines an option to use managed identity, Azure Machine Learning Managed (Automatic) Spark compute uses user-assigned managed identity attached to the workspace. You can attach a user-assigned managed identity to an existing Azure Machine Learning workspace using Azure Machine Learning CLI v2, or with `ARMClient`.\n\n### Attach user assigned managed identity using CLI v2\n1. Create a YAML file that defines the user-assigned managed identity that should be attached to the workspace:\n    ```yaml\n    identity:\n      type: system_assigned,user_assigned\n      tenant_id: <TENANT_ID>\n      user_assigned_identities:\n        '/subscriptions/<SUBSCRIPTION_ID/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<AML_USER_MANAGED_ID>':\n          {}\n    ```\n1. With the `--file` parameter, use the YAML file in the `az ml workspace update` command to attach the user assigned managed identity:\n    ```azurecli\n    az ml workspace update --subscription <SUBSCRIPTION_ID> --resource-group <RESOURCE_GROUP> --name <AML_WORKSPACE_NAME> --file <YAML_FILE_NAME>.yaml\n    ```\n\n### Attach user assigned managed identity using `ARMClient`\n1. Install [ARMClient](https://github.com/projectkudu/ARMClient), a simple command line tool that invokes the Azure Resource Manager API.\n1. Create a JSON file that defines the user-assigned managed identity that should be attached to the workspace:\n    ```json\n    {\n        \"properties\":{\n        },\n        \"location\": \"<AZURE_REGION>\",\n        \"identity\":{\n            \"type\":\"SystemAssigned,UserAssigned\",\n            \"userAssignedIdentities\":{\n                \"/subscriptions/<SUBSCRIPTION_ID/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.ManagedIdentity/userAssignedIdentities/<AML_USER_MANAGED_ID>\": { }\n            }\n        }\n    }\n    ```\n1. Execute the following command in the PowerShell prompt or the command prompt, to attach the user-assigned managed identity to the workspace.\n    ```cmd\n    armclient PATCH https://management.azure.com/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.MachineLearningServices/workspaces/<AML_WORKSPACE_NAME>?api-version=2022-05-01 '@<JSON_FILE_NAME>.json'\n    ```\n\n> [!NOTE]\n> - To ensure successful execution of the Spark job, assign the **Contributor** and **Storage Blob Data Contributor** roles, on the Azure storage account used for data input and output, to the identity that the Spark job uses\n> - If an [attached Synapse Spark pool](./how-to-manage-synapse-spark-pool.md) points to a Synapse Spark pool, in an Azure Synapse workspace that has a managed virtual network associated with it, [a managed private endpoint to storage account should be configured](../synapse-analytics/security/connect-to-a-secure-storage-account.md) to ensure data access.\n\n## Submit a standalone Spark job\nA Python script developed by [interactive data wrangling](./interactive-data-wrangling-with-apache-spark-azure-ml.md) can be used to submit a batch job to process a larger volume of data, after making necessary changes for Python script parameterization. A simple data wrangling batch job can be submitted as a standalone Spark job.\n\nA Spark job requires a Python script that takes arguments, which can be developed with modification of the Python code developed from [interactive data wrangling](./interactive-data-wrangling-with-apache-spark-azure-ml.md). A sample Python script is shown here.\n\n```python\n# titanic.py\nimport argparse\nfrom operator import add\nimport pyspark.pandas as pd\nfrom pyspark.ml.feature import Imputer\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--titanic_data\")\nparser.add_argument(\"--wrangled_data\")\n\nargs = parser.parse_args()\nprint(args.wrangled_data)\nprint(args.titanic_data)\n\ndf = pd.read_csv(args.titanic_data, index_col=\"PassengerId\")\nimputer = Imputer(inputCols=[\"Age\"], outputCol=\"Age\").setStrategy(\n    \"mean\"\n)  # Replace missing values in Age column with the mean value\ndf.fillna(\n    value={\"Cabin\": \"None\"}, inplace=True\n)  # Fill Cabin column with value \"None\" if missing\ndf.dropna(inplace=True)  # Drop the rows which still have any missing value\ndf.to_csv(args.wrangled_data, index_col=\"PassengerId\")\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-submit-spark-jobs-51.md"
                }
            },
            {
                "page_content": "\n\n## Write data in a job\n\nIn your job, you can write data to your cloud-based storage with *outputs*. The [Supported modes](#supported-modes) section showed that only job *outputs* can write data, because the mode can be either `rw_mount` or `upload`.\n\n# [Azure CLI](#tab/cli)\n\nCreate a job specification YAML file (`<file-name>.yml`), with the `outputs` section populated with the type and path where you'd like to write your data:\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/CommandJob.schema.json\n\n# Possible Paths for Data:\n# Blob: https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>\n# Datastore: azureml://datastores/paths/<folder>/<file>\n# Data Asset: azureml:<my_data>:<version>\n\ncode: src\ncommand: >-\n  python prep.py \n  --raw_data ${{inputs.raw_data}} \n  --prep_data ${{outputs.prep_data}}\ninputs:\n  raw_data: \n    type: <type> # uri_file, uri_folder, mltable\n    path: <path>\noutputs:\n  prep_data: \n    type: <type> # uri_file, uri_folder, mltable\n    path: <path>\nenvironment: azureml:<environment_name>@latest\ncompute: azureml:cpu-cluster\n```\n\nNext, create a job with the CLI:\n\n```azurecli\naz ml job create --file <file-name>.yml\n```\n\n# [Python SDK](#tab/python)\n\n```python\nfrom azure.ai.ml import command\nfrom azure.ai.ml.entities import Data\nfrom azure.ai.ml import Input, Output\nfrom azure.ai.ml.constants import AssetTypes\n\n# Possible Asset Types for Data:\n# AssetTypes.URI_FILE\n# AssetTypes.URI_FOLDER\n# AssetTypes.MLTABLE\n\n# Possible Paths for Data:\n# Blob: https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>\n# Datastore: azureml://datastores/paths/<folder>/<file>\n# Data Asset: azureml:<my_data>:<version>\n\nmy_job_inputs = {\n    \"raw_data\": Input(type=AssetTypes.URI_FOLDER, path=\"<path>\")\n}\n\nmy_job_outputs = {\n    \"prep_data\": Output(type=AssetTypes.URI_FOLDER, path=\"<path>\")\n}\n\njob = command(\n    code=\"./src\",  # local path where the code is stored\n    command=\"python process_data.py --raw_data ${{inputs.raw_data}} --prep_data ${{outputs.prep_data}}\",\n    inputs=my_job_inputs,\n    outputs=my_job_outputs,\n    environment=\"<environment_name>:<version>\",\n    compute=\"cpu-cluster\",\n)\n\n# submit the command\nreturned_job = ml_client.create_or_update(job)\n# get a URL for the status of the job\nreturned_job.services[\"Studio\"].endpoint\n\n```\n\n\n## Data in pipelines\n\nIf you work with Azure Machine Learning pipelines, you can read data into and move data between pipeline components with the Azure Machine Learning CLI v2 extension, or the Python SDK v2.\n\n### Azure Machine Learning CLI v2\nThis YAML file shows how to use the output data from one component as the input for another component of the pipeline, with the Azure Machine Learning CLI v2 extension:\n\n[!INCLUDE [CLI v2](../../includes/machine-learning-CLI-v2.md)]\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\ntype: pipeline\n\ndisplay_name: 3b_pipeline_with_data\ndescription: Pipeline with 3 component jobs with data dependencies\n\nsettings:\n  default_compute: azureml:cpu-cluster\n\noutputs:\n  final_pipeline_output:\n    mode: rw_mount\n\njobs:\n  component_a:\n    type: command\n    component: ./componentA.yml\n    inputs:\n      component_a_input: \n        type: uri_folder\n        path: ./data\n\n    outputs:\n      component_a_output: \n        mode: rw_mount\n  component_b:\n    type: command\n    component: ./componentB.yml\n    inputs:\n      component_b_input: ${{parent.jobs.component_a.outputs.component_a_output}}\n    outputs:\n      component_b_output: \n        mode: rw_mount\n  component_c:\n    type: command\n    component: ./componentC.yml\n    inputs:\n      component_c_input: ${{parent.jobs.component_b.outputs.component_b_output}}\n    outputs:\n      component_c_output: ${{parent.outputs.final_pipeline_output}}\n      #  mode: upload\n\n\n```\n\n### Python SDK v2\n\nThis example defines a pipeline that contains three nodes, and moves data between each node.\n\n* `prepare_data_node` loads the image and labels from Fashion MNIST data set into `mnist_train.csv` and `mnist_test.csv`.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-read-write-data-v2-259.md"
                }
            }
        ]
    },
    {
        "query": "how can I register a model from a job using the v2 cli?",
        "result": "To register a model from a job using the v2 CLI, you can use the following command: \n```\naz ml model register --experiment-name <your-experiment-name> --run-id <your-run-id> --model-name <your-model-name> --model-path <your-model-path>\n```\nReplace `<your-experiment-name>` with the name of the experiment where the model was trained, `<your-run-id>` with the ID of the job run that produced the model, `<your-model-name>` with the name you want to give the registered model, and `<your-model-path>` with the path to the model file within the job run files (for example, `outputs/model.pkl`).\nNote that the `az ml` CLI command requires authentication through Azure Active Directory (AAD). If you haven't already, you will need to install and configure the [Azure CLI v2.0](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) and then sign in to your Azure account by running `az login`.",
        "context": [
            {
                "page_content": "\n# Work with models in Azure Machine Learning\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\nAzure Machine Learning allows you to work with different types of models. In this article, you learn about using Azure Machine Learning to work with different model types, such as custom, MLflow, and Triton. You also learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.\n\n> [!TIP]\n> If you have model assets created that use the SDK/CLI v1, you can still use those with SDK/CLI v2. Full backward compatibility is provided. All models registered with the V1 SDK are assigned the type `custom`.\n\n## Prerequisites\n\n* An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n* An Azure Machine Learning workspace.\n* The Azure Machine Learning [SDK v2 for Python](https://aka.ms/sdk-v2-install).\n* The Azure Machine Learning [CLI v2](how-to-configure-cli.md).\n\nAdditionally, you will need to:\n\n# [Azure CLI](#tab/cli)\n\n- Install the Azure CLI and the ml extension to the Azure CLI. For more information, see [Install, set up, and use the CLI (v2)](how-to-configure-cli.md).\n\n# [Python SDK](#tab/python)\n\n- Install the Azure Machine Learning SDK for Python\n    \n    ```bash\n    pip install azure-ai-ml\n    ```\n\n## Supported paths\n\nWhen you provide a model you want to register, you'll need to specify a `path` parameter that points to the data or job location. Below is a table that shows the different data locations supported in Azure Machine Learning and examples for the `path` parameter:\n\n\n|Location  | Examples  |\n|---------|---------|\n|A path on your local computer     | `mlflow-model/model.pkl`         |\n|A path on an AzureML Datastore   |   `azureml://datastores/<datastore-name>/paths/<path_on_datastore>`      |\n|A path from an AzureML job   |   `azureml://jobs/<job-name>/outputs/<output-name>/paths/<path-to-model-relative-to-the-named-output-location>`      |\n|A path from an MLflow job   |   `runs:/<run-id>/<path-to-model-relative-to-the-root-of-the-artifact-location>`      |\n|A path from a Model Asset in AzureML Workspace  | `azureml:<model-name>:<version>`|\n|A path from a Model Asset in  AzureML Registry  | `azureml://registries/<registry-name>/models/<model-name>/versions/<version>`|\n\n## Supported modes\n\nWhen you run a job with model inputs/outputs, you can specify the *mode* - for example, whether you would like the model to be read-only mounted or downloaded to the compute target. The table below shows the possible modes for different type/mode/input/output combinations:\n\nType | Input/Output | `upload` | `download` | `ro_mount` | `rw_mount` | `direct` \n------ | ------ | :---: | :---: | :---: | :---: | :---: \n`custom` file  | Input  |   |  |   |  |    \n`custom` folder    | Input |   | \u2713 | \u2713  | |\u2713  \n`mlflow`    | Input |   | \u2713 |  \u2713 |   |   \n`custom` file | Output  | \u2713  |   |    | \u2713  | \u2713   \n`custom` folder    | Output | \u2713  |   |   | \u2713 | \u2713  \n`mlflow`   | Output | \u2713  |   |    | \u2713  | \u2713 \n\n\n### Follow along in Jupyter Notebooks\n\nYou can follow along this sample in a Jupyter Notebook. In the [azureml-examples](https://github.com/azure/azureml-examples) repository, open the notebook: [model.ipynb](https://github.com/Azure/azureml-examples/blob/main/sdk/python/assets/model/model.ipynb).\n\n## Create a model in the model registry\n\n[Model registration](concept-model-management-and-deployment.md) allows you to store and version your models in the Azure cloud, in your workspace. The model registry helps you organize and keep track of your trained models.\n\nThe code snippets in this section cover how to:\n\n* Register your model as an asset in Machine Learning by using the CLI.\n* Register your model as an asset in Machine Learning by using the SDK.\n* Register your model as an asset in Machine Learning by using the UI.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-manage-models-0.md"
                }
            },
            {
                "page_content": "The Bandit early termination policy is also used. This policy terminates poor performing trials; that is, those trials that are not within 20% slack of the best performing trial, which significantly saves compute resources.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\nsweep:\n  sampling_algorithm: random\n  early_termination:\n    type: bandit\n    evaluation_interval: 2\n    slack_factor: 0.2\n    delay_evaluation: 6\n```\n\n```yaml\nsearch_space:\n  - model_name:\n      type: choice\n      values: [yolov5]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.01\n    model_size:\n      type: choice\n      values: [small, medium]\n\n  - model_name:\n      type: choice\n      values: [fasterrcnn_resnet50_fpn]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.001\n    optimizer:\n      type: choice\n      values: [sgd, adam, adamw]\n    min_size:\n      type: choice\n      values: [600, 800]\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=sweep-settings)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=search-space-settings)]\n\n\nOnce the search space and sweep settings are defined, you can then submit the job to train an image model using your training dataset.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nTo submit your AutoML job, you run the following CLI v2 command with the path to your .yml file, workspace name, resource group and subscription ID.\n\n```azurecli\naz ml job create --file ./hello-automl-job-basic.yml --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]\n```\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\nWhen you've configured your AutoML Job to the desired settings, you can submit the job.\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=submit-run)]\n\n\nWhen doing a hyperparameter sweep, it can be useful to visualize the different trials that were tried using the HyperDrive UI. You can navigate to this UI by going to the 'Child jobs' tab in the UI of the main automl_image_job from above, which is the HyperDrive parent job. Then you can go into the 'Child jobs' tab of this one.\n\nAlternatively, here below you can see directly the HyperDrive parent job and navigate to its 'Child jobs' tab:\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n```python\nhd_job = ml_client.jobs.get(returned_job.name + '_HD')\nhd_job\n```\n\n\n## Register and deploy model\n\nOnce the job completes, you can register the model that was created from the best trial (configuration that resulted in the best primary metric). You can either register the model after downloading or by specifying the azureml path with corresponding jobid.  \n\n### Get the best trial\n\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=best_run)] \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/tutorial-auto-train-image-models-387.md"
                }
            },
            {
                "page_content": "\n\n# What is an Azure Machine Learning workspace?\n\nThe workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.  The workspace keeps a history of all training runs, including logs, metrics, output, and a snapshot of your scripts. You use this information to determine which training run produces the best model.  \n\nOnce you have a model you like, you register it with the workspace. You then use the registered model and scoring scripts to deploy to an [online endpoint](concept-endpoints.md) as a REST-based HTTP endpoint.\n\n## Taxonomy \n\n+ A workspace can contain [Azure Machine Learning compute instances](concept-compute-instance.md), cloud resources configured with the Python environment necessary to run Azure Machine Learning.\n\n+ [User roles](how-to-assign-roles.md) enable you to share your workspace with other users, teams, or projects.\n+ [Compute targets](concept-compute-target.md) are used to run your experiments.\n+ When you create the workspace, [associated resources](#associated-resources) are also created for you.\n+ Jobs are training runs you use to build your models.  You can organize your jobs into Experiments.\n+ [Pipelines](concept-ml-pipelines.md) are reusable workflows for training and retraining your model.\n+ [Data assets](concept-data.md) aid in management of the data you use for model training and pipeline creation.\n+ Once you have a model you want to deploy, you create a registered model.\n+ Use the registered model and a scoring script to create an [online endpoint](concept-endpoints.md).\n\n## Tools for workspace interaction\n\nYou can interact with your workspace in the following ways:\n\n+ On the web:\n    + [Azure Machine Learning studio ](https://ml.azure.com) \n    + [Azure Machine Learning designer](concept-designer.md) \n+ In any Python environment with the [Azure Machine Learning SDK for Python](https://aka.ms/sdk-v2-install).\n+ On the command line using the Azure Machine Learning [CLI extension](how-to-configure-cli.md)\n+ [Azure Machine Learning VS Code Extension](how-to-manage-resources-vscode.md#workspaces)\n\n## Machine learning with a workspace\n\nMachine learning tasks read and/or write artifacts to your workspace.\n\n+ Run an experiment to train a model - writes job run results to the workspace.\n+ Use automated ML to train a model - writes training results to the workspace.\n+ Register a model in the workspace.\n+ Deploy a model - uses the registered model to create a deployment.\n+ Create and run reusable workflows.\n+ View machine learning artifacts such as jobs, pipelines, models, deployments.\n+ Track and monitor models.\n\n## Workspace management\n\nYou can also perform the following workspace management tasks:\n\n| Workspace management task           | Portal      | Studio      | Python SDK  | Azure CLI   | VS Code     |\n|-------------------------------------|-------------|-------------|-------------|-------------|-------------|\n| Create a workspace                  | **&check;** | **&check;** | **&check;** | **&check;** | **&check;** |\n| Manage workspace access             | **&check;** |             |             | **&check;** |             |\n| Create and manage compute resources | **&check;** | **&check;** | **&check;** | **&check;** | **&check;** |\n| Create a compute instance           |             | **&check;** | **&check;** | **&check;** | **&check;** |\n\n> [!WARNING]\n> Moving your Azure Machine Learning workspace to a different subscription, or moving the owning subscription to a new tenant, is not supported. Doing so may cause errors.\n\n## Create a workspace\n\nThere are multiple ways to create a workspace:  \n\n* Use [Azure Machine Learning studio](quickstart-create-resources.md) to quickly create a workspace with default settings.\n* Use the [Azure portal](how-to-manage-workspace.md?tabs=azure-portal#create-a-workspace) for a point-and-click interface with more options. \n* Use the [Azure Machine Learning SDK for Python](how-to-manage-workspace.md?tabs=python#create-a-workspace) to create a workspace on the fly from Python scripts or Jupyter notebooks.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-workspace-0.md"
                }
            }
        ]
    },
    {
        "query": "I'm trying to access the files/artifacts located in the code tab under an AzureML job. How can I download the code of a job with the v2 CLI?",
        "result": "You can download the files/artifacts located in the code tab under an AzureML job with the v2 CLI by running the following command:\n\n```azurecli\naz ml job download -n <job-name> --type sdk\n```\n\nReplace `<job-name>` with the name of the job you want to download. The `--type` parameter specifies the type of artifact you want to download, and can be set to `sdk` for Python SDK code, `other` for other generic artifacts, or `all` for all artifacts. The downloaded artifacts will be located in the `outputs` folder of the current working directory.",
        "context": [
            {
                "page_content": "\n# Access data in a job\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\n> [!div class=\"op_single_selector\" title1=\"Select the version of Azure Machine Learning CLI extension you use:\"]\n> * [v1](v1/how-to-train-with-datasets.md)\n> * [v2 (current version)](how-to-read-write-data-v2.md)\n\nLearn how to read and write data for your jobs with the Azure Machine Learning Python SDK v2 and the Azure Machine Learning CLI extension v2.\n\n## Prerequisites\n\n- An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n\n- The [Azure Machine Learning SDK for Python v2](https://aka.ms/sdk-v2-install).\n\n- An Azure Machine Learning workspace\n\n## Supported paths\n\nWhen you provide a data input/output to a Job, you must specify a `path` parameter that points to the data location. This table shows both the different data locations that Azure Machine Learning supports, and examples for the `path` parameter:\n\n\n|Location  | Examples  |\n|---------|---------|\n|A path on your local computer     | `./home/username/data/my_data`         |\n|A path on a public http(s) server    |  `https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv`    |\n|A path on Azure Storage     |   `https://<account_name>.blob.core.windows.net/<container_name>/<path>` <br> `abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>`    |\n|A path on a Datastore   |   `azureml://datastores/<data_store_name>/paths/<path>`      |\n|A path to a Data Asset  |  `azureml:<my_data>:<version>`  |\n\n## Supported modes\n\nWhen you run a job with data inputs/outputs, you can specify the *mode* - for example, whether the data should be read-only mounted, or downloaded to the compute target. This table shows the possible modes for different type/mode/input/output combinations:\n\nType | Input/Output | `upload` | `download` | `ro_mount` | `rw_mount` | `direct` | `eval_download` | `eval_mount` \n------ | ------ | :---: | :---: | :---: | :---: | :---: | :---: | :---:\n`uri_folder` | Input  |   | \u2713  |  \u2713  |   | \u2713  |  | \n`uri_file`   | Input |   | \u2713  |  \u2713  |   | \u2713  |  | \n`mltable`   | Input |   | \u2713  |  \u2713  |   | \u2713  | \u2713 | \u2713\n`uri_folder` | Output  | \u2713  |   |    | \u2713  |   |  | \n`uri_file`   | Output | \u2713  |   |    | \u2713  |   |  | \n`mltable`   | Output | \u2713  |   |    | \u2713  | \u2713  |  | \n\n> [!NOTE]\n> `eval_download` and `eval_mount` are unique to `mltable`. The `ro_mount` is the default mode for MLTable. In some scenarios, however, an MLTable can yield files that are not necessarily co-located with the MLTable file in storage. Alternately, an `mltable` can subset or shuffle the data located in the storage resource. That view becomes visible only if the engine actually evaluates the MLTable file. These modes provide that view of the files.\n\n\n## Read data in a job\n\n# [Azure CLI](#tab/cli)\n\nCreate a job specification YAML file (`<file-name>.yml`). In the `inputs` section of the job, specify:\n\n1. The `type`; whether the data is a specific file (`uri_file`), a folder location (`uri_folder`), or an `mltable`.\n1. The `path` of your data location; any of the paths outlined in the [Supported Paths](#supported-paths) section will work.\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n\n# Possible Paths for Data:\n# Blob: https://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>\n# Datastore: azureml://datastores/paths/<folder>/<file>\n# Data Asset: azureml:<my_data>:<version>\n\ncommand: |\n  ls ${{inputs.my_data}}\ncode: <folder where code is located>\ninputs:\n  my_data:\n    type: <type> # uri_file, uri_folder, mltable\n    path: <path>\nenvironment: azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\ncompute: azureml:cpu-cluster\n```\n\nNext, run in the CLI\n\n```azurecli\naz ml job create -f <file-name>.yml\n```\n\n# [Python SDK](#tab/python)\n\nUse the `Input` class to define:\n\n1. The `type`; whether the data is a specific file (`uri_file`), a folder location (`uri_folder`), or an `mltable`.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-read-write-data-v2-0.md"
                }
            },
            {
                "page_content": "\n# Work with models in Azure Machine Learning\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\nAzure Machine Learning allows you to work with different types of models. In this article, you learn about using Azure Machine Learning to work with different model types, such as custom, MLflow, and Triton. You also learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.\n\n> [!TIP]\n> If you have model assets created that use the SDK/CLI v1, you can still use those with SDK/CLI v2. Full backward compatibility is provided. All models registered with the V1 SDK are assigned the type `custom`.\n\n## Prerequisites\n\n* An Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n* An Azure Machine Learning workspace.\n* The Azure Machine Learning [SDK v2 for Python](https://aka.ms/sdk-v2-install).\n* The Azure Machine Learning [CLI v2](how-to-configure-cli.md).\n\nAdditionally, you will need to:\n\n# [Azure CLI](#tab/cli)\n\n- Install the Azure CLI and the ml extension to the Azure CLI. For more information, see [Install, set up, and use the CLI (v2)](how-to-configure-cli.md).\n\n# [Python SDK](#tab/python)\n\n- Install the Azure Machine Learning SDK for Python\n    \n    ```bash\n    pip install azure-ai-ml\n    ```\n\n## Supported paths\n\nWhen you provide a model you want to register, you'll need to specify a `path` parameter that points to the data or job location. Below is a table that shows the different data locations supported in Azure Machine Learning and examples for the `path` parameter:\n\n\n|Location  | Examples  |\n|---------|---------|\n|A path on your local computer     | `mlflow-model/model.pkl`         |\n|A path on an AzureML Datastore   |   `azureml://datastores/<datastore-name>/paths/<path_on_datastore>`      |\n|A path from an AzureML job   |   `azureml://jobs/<job-name>/outputs/<output-name>/paths/<path-to-model-relative-to-the-named-output-location>`      |\n|A path from an MLflow job   |   `runs:/<run-id>/<path-to-model-relative-to-the-root-of-the-artifact-location>`      |\n|A path from a Model Asset in AzureML Workspace  | `azureml:<model-name>:<version>`|\n|A path from a Model Asset in  AzureML Registry  | `azureml://registries/<registry-name>/models/<model-name>/versions/<version>`|\n\n## Supported modes\n\nWhen you run a job with model inputs/outputs, you can specify the *mode* - for example, whether you would like the model to be read-only mounted or downloaded to the compute target. The table below shows the possible modes for different type/mode/input/output combinations:\n\nType | Input/Output | `upload` | `download` | `ro_mount` | `rw_mount` | `direct` \n------ | ------ | :---: | :---: | :---: | :---: | :---: \n`custom` file  | Input  |   |  |   |  |    \n`custom` folder    | Input |   | \u2713 | \u2713  | |\u2713  \n`mlflow`    | Input |   | \u2713 |  \u2713 |   |   \n`custom` file | Output  | \u2713  |   |    | \u2713  | \u2713   \n`custom` folder    | Output | \u2713  |   |   | \u2713 | \u2713  \n`mlflow`   | Output | \u2713  |   |    | \u2713  | \u2713 \n\n\n### Follow along in Jupyter Notebooks\n\nYou can follow along this sample in a Jupyter Notebook. In the [azureml-examples](https://github.com/azure/azureml-examples) repository, open the notebook: [model.ipynb](https://github.com/Azure/azureml-examples/blob/main/sdk/python/assets/model/model.ipynb).\n\n## Create a model in the model registry\n\n[Model registration](concept-model-management-and-deployment.md) allows you to store and version your models in the Azure cloud, in your workspace. The model registry helps you organize and keep track of your trained models.\n\nThe code snippets in this section cover how to:\n\n* Register your model as an asset in Machine Learning by using the CLI.\n* Register your model as an asset in Machine Learning by using the SDK.\n* Register your model as an asset in Machine Learning by using the UI.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-manage-models-0.md"
                }
            },
            {
                "page_content": "> Any jobs that are running when a service outage occurs will not automatically transition to the secondary workspace. It is also unlikely that the jobs will resume and finish successfully in the primary workspace once the outage is resolved. Instead, these jobs must be resubmitted, either in the secondary workspace or in the primary (once the outage is resolved).\n\n### Moving artifacts between workspaces\n\nDepending on your recovery approach, you may need to copy artifacts such as dataset and model objects between the workspaces to continue your work. Currently, the portability of artifacts between workspaces is limited. We recommend managing artifacts as code where possible so that they can be recreated in the failover instance.\n\nThe following artifacts can be exported and imported between workspaces by using the [Azure CLI extension for machine learning](v1/reference-azure-machine-learning-cli.md):\n\n| Artifact | Export | Import |\n| ----- | ----- | ----- |\n| Models | [az ml model download --model-id {ID} --target-dir {PATH}](/cli/azure/ml/model#az-ml-model-download) | [az ml model register \u2013name {NAME} --path {PATH}](/cli/azure/ml/model) |\n| Environments | [az ml environment download -n {NAME} -d {PATH}](/cli/azure/ml/environment#ml-az-ml-environment-download) | [az ml environment register -d {PATH}](/cli/azure/ml/environment#ml-az-ml-environment-register) |\n| Azure ML pipelines (code-generated) | [az ml pipeline get --path {PATH}](/cli/azure/ml(v1)/pipeline#az-ml(v1)-pipeline-get) | [az ml pipeline create --name {NAME} -y {PATH}](/cli/azure/ml(v1)/pipeline#az-ml(v1)-pipeline-create)\n\n> [!TIP]\n> * __Registered datasets__ cannot be downloaded or moved. This includes datasets generated by Azure ML, such as intermediate pipeline datasets. However datasets that refer to a shared file location that both workspaces can access, or where the underlying data storage is replicated, can be registered on both workspaces. Use the [az ml dataset register](/cli/azure/ml(v1)/dataset#ml-az-ml-dataset-register) to register a dataset.\n> * __Job outputs__ are stored in the default storage account associated with a workspace. While job outputs might become inaccessible from the studio UI in the case of a service outage, you can directly access the data through the storage account. For more information on working with data stored in blobs, see [Create, download, and list blobs with Azure CLI](../storage/blobs/storage-quickstart-blobs-cli.md).\n\n## Recovery options\n\n### Workspace deletion\n\nIf you accidentally deleted your workspace it is currently not possible to recover it. However you are able to retrieve your existing notebooks from the corresponding storage if you follow these steps:\n* In the [Azure portal](https://portal.azure.com) navigate to the storage account that was linked to the deleted Azure Machine Learning workspace.\n* In the Data storage section on the left, click on **File shares**.\n* Your notebooks are located on the file share with the name that contains your workspace ID. \n\n![Reference notebook file share](./media/how-to-high-availability-machine-learning/notebook-file-share.png)\n\n## Next steps\n\nTo learn about repeatable infrastructure deployments with Azure Machine Learning, use an [Azure Resource Manager template](./tutorial-create-secure-workspace-template.md).",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-high-availability-machine-learning-160.md"
                }
            }
        ]
    },
    {
        "query": "how can I cancel a run using the new v2 cli?",
        "result": "To cancel a run using the new v2 CLI, use the command `az ml run cancel` followed by the run ID. For example, to cancel a run with the ID `abc123`, use the command `az ml run cancel --run-id abc123`. You can also cancel multiple runs at once by providing a list of run IDs.",
        "context": [
            {
                "page_content": "    1. A configuration file containing your run configuration settings opens in the editor. If you're satisfied with the settings, select **Submit experiment**. Alternatively, you open the command palette (**View > Command Palette**) from the menu bar and enter the `Azure ML: Submit experiment` command into the text box.\n1. Once your experiment is submitted, a Docker image containing your script and the configurations specified in your run configuration is created.\n\n    When the Docker image build process begins, the contents of the `60_control_log.txt` file stream to the output console in VS Code.\n\n    > [!NOTE]\n    > The first time your Docker image is created can take several minutes.\n\n1. Once your image is built, a prompt appears to start the debugger. Set your breakpoints in your script and select **Start debugger** when you're ready to start debugging. Doing so attaches the VS Code debugger to the container running your experiment. Alternatively, in the Azure Machine Learning extension, hover over the node for your current run and select the play icon to start the debugger.\n\n    > [!IMPORTANT]\n    > You cannot have multiple debug sessions for a single experiment. You can however debug two or more experiments using multiple VS Code instances.\n\nAt this point, you should be able to step-through and debug your code using VS Code.\n\nIf at any point you want to cancel your run, right-click your run node and select **Cancel run**.\n\nSimilar to remote experiment runs, you can expand your run node to inspect the logs and outputs.\n\n> [!TIP]\n> Docker images that use the same dependencies defined in your environment are reused between runs. However, if you run an experiment using a new or different environment, a new image is created. Since these images are saved to your local storage, it's recommended to remove old or unused Docker images. To remove images from your system, use the [Docker CLI](https://docs.docker.com/engine/reference/commandline/rmi/) or the [VS Code Docker extension](https://code.visualstudio.com/docs/containers/overview).\n\n## Debug and troubleshoot machine learning pipelines\n\nIn some cases, you may need to interactively debug the Python code used in your ML pipeline. By using VS Code and debugpy, you can attach to the code as it runs in the training environment.\n\n### Prerequisites\n\n* An __Azure Machine Learning workspace__ that is configured to use an __Azure Virtual Network__.\n* An __Azure Machine Learning pipeline__ that uses Python scripts as part of the pipeline steps. For example, a PythonScriptStep.\n* An Azure Machine Learning Compute cluster, which is __in the virtual network__ and is __used by the pipeline for training__.\n* A __development environment__ that is __in the virtual network__. The development environment might be one of the following:\n\n  * An Azure Virtual Machine in the virtual network\n  * A Compute instance of Notebook VM in the virtual network\n  * A client machine that has private network connectivity to the virtual network, either by VPN or via ExpressRoute.\n\nFor more information on using an Azure Virtual Network with Azure Machine Learning, see [Virtual network isolation and privacy overview](how-to-network-security-overview.md).\n\n> [!TIP]\n> Although you can work with Azure Machine Learning resources that are not behind a virtual network, using a virtual network is recommended.\n\n### How it works\n\nYour ML pipeline steps run Python scripts. These scripts are modified to perform the following actions:\n\n1. Log the IP address of the host that they're running on. You use the IP address to connect the debugger to the script.\n\n2. Start the debugpy debug component, and wait for a debugger to connect.\n\n3. From your development environment, you monitor the logs created by the training process to find the IP address where the script is running.\n\n4. You tell VS Code the IP address to connect the debugger to by using a `launch.json` file.\n\n5. You attach the debugger and interactively step through the script.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-debug-visual-studio-code-52.md"
                }
            },
            {
                "page_content": "\n# Monitor and analyze jobs in studio\n\n\nYou can use [Azure Machine Learning studio](https://ml.azure.com) to monitor, organize, and track your jobs for training and experimentation. Your ML job history is an important part of an explainable and repeatable ML development process.\n\nThis article shows how to do the following tasks:\n\n* Add job display name. \n* Create a custom view. \n* Add a job description. \n* Tag and find jobs.\n* Run search over your job history.\n* Cancel or fail jobs.\n* Monitor the job status by email notification.\n* Monitor your job resources (preview)\n \n\n> [!TIP]\n> * If you're looking for information on using the Azure Machine Learning SDK v1 or CLI v1, see [How to track, monitor, and analyze jobs (v1)](./v1/how-to-track-monitor-analyze-runs.md).\n> * If you're looking for information on monitoring training jobs from the CLI or SDK v2, see [Track experiments with MLflow and CLI v2](how-to-use-mlflow-cli-runs.md).\n> * If you're looking for information on monitoring the Azure Machine Learning service and associated Azure services, see [How to monitor Azure Machine Learning](monitor-azure-machine-learning.md).\n>\n> If you're looking for information on monitoring models deployed to online endpoints, see [Monitor online endpoints](how-to-monitor-online-endpoints.md).\n\n## Prerequisites\n\nYou'll need the following items:\n\n* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n* You must have an Azure Machine Learning workspace. A workspace is created in [Install, set up, and use the CLI (v2)](how-to-configure-cli.md).\n\n## Job display name \n\nThe job display name is an optional and customizable name that you can provide for your job. To edit the job display name:\n\n1. Navigate to the **Jobs** list. \n\n1. Select the job to edit.\n\n    :::image type=\"content\" source=\"media/how-to-track-monitor-analyze-runs/select-job.png\" alt-text=\"Screenshot of Jobs list.\":::\n\n1. Select the **Edit** button to edit the job display name.\n\n    :::image type=\"content\" source=\"media/how-to-track-monitor-analyze-runs/display-name.gif\" alt-text=\"Screenshot of how to edit the display name.\":::\n\n## Custom View \n    \nTo view your jobs in the studio: \n    \n1. Navigate to the **Jobs** tab.\n    \n1. Select either **All experiments** to view all the jobs in an experiment or select **All jobs** to view all the jobs submitted in the Workspace.\n    \nIn the **All jobs'** page, you can filter the jobs list by tags, experiments, compute target and more to better organize and scope your work.  \n    \n1. Make customizations to the page by selecting jobs to compare, adding charts or applying filters. These changes can be saved as a **Custom View** so you can easily return to your work. Users with workspace permissions can edit, or view the custom view. Also, share the custom view with team members for enhanced collaboration by selecting **Share view**.\n\n1. To view the job logs, select a specific job and in the **Outputs + logs** tab, you can find diagnostic and error logs for your job.\n\n    :::image type=\"content\" source=\"media/how-to-track-monitor-analyze-runs/custom-views-2.gif\" alt-text=\"Screenshot of how to create a custom view.\":::   \n\n## Job description \n\nA job description can be added to a job to provide more context and information to the job. You can also search on these descriptions from the jobs list and add the job description as a column in the jobs list. \n\nNavigate to the **Job Details** page for your job and select the edit or pencil icon to add, edit, or delete descriptions for your job. To persist the changes to the jobs list, save the changes to your existing Custom View or a new Custom View. Markdown format is supported for job descriptions, which allows images to be embedded and deep linking as shown below.\n\n:::image type=\"content\" source=\"media/how-to-track-monitor-analyze-runs/run-description-2.gif\" alt-text=\"Screenshot of how to create a job description.\"::: \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-track-monitor-analyze-runs-0.md"
                }
            },
            {
                "page_content": "    > Replace `<domain>` and `<ingress-secret-name>` in the above Ingress Resource with the domain pointing to LoadBalancer of the **Nginx ingress controller/Application Gateway** and name of your secret. Store the above Ingress Resource in a file name `ing-azureml-fe-tls.yaml`.\n\n1. Deploy ing-azureml-fe-tls.yaml by running\n\n    ```bash\n    kubectl apply -f ing-azureml-fe-tls.yaml\n    ```\n\n2. Check the log of the ingress controller for deployment status.\n\n3. Now the `azureml-fe` application will be available on HTTPS. You can check this by visiting the public LoadBalancer address of the Nginx Ingress Controller.\n\n4. [Create an inference job and invoke](../machine-learning/how-to-deploy-online-endpoints.md).\n\n    >[!NOTE]\n    >\n    > Replace the protocol and IP in scoring_uri with https and domain pointing to LoadBalancer of the Nginx Ingress Controller  or the Application Gateway before invoking.\n\n## Use ARM Template to Deploy Extension\nExtension on managed cluster can be deployed with ARM template. A sample template can be found from [deployextension.json](https://github.com/Azure/AML-Kubernetes/blob/master/files/deployextension.json), with a demo parameter file [deployextension.parameters.json](https://github.com/Azure/AML-Kubernetes/blob/master/files/deployextension.parameters.json) \n\nTo leverage the sample deployment template, edit the parameter file with correct value, then run the following command:\n\n```azurecli\naz deployment group create --name <ARM deployment name> --resource-group <resource group name> --template-file deployextension.json --parameters deployextension.parameters.json\n```\nMore information about how to use ARM template can be found from [ARM template doc](../azure-resource-manager/templates/overview.md)\n\n\n## Azureml extension release note\n> [!NOTE]\n >\n > New features are released at a biweekly calendar.\n\n| Date | Version |Version description |\n|---|---|---|\n| Dec 27, 2022 | 1.1.17 | Move the Fluent-bit from DaemonSet to sidecars. Add MDC support. Refine error messages. Support cluster mode (windows, linux) jobs. Bug fixes|\n| Nov 29, 2022 | 1.1.16 |Add instance type validation by new CRD. Support Tolerance. Shorten SVC Name. Workload Core hour. Multiple Bug fixes and improvements. |\n| Sep 13, 2022 | 1.1.10 | Bug fixes.|\n| Aug 29, 2022 | 1.1.9 | Improved health check logic. Bug fixes.|\n| Jun 23, 2022 | 1.1.6 | Bug fixes. |\n| Jun 15, 2022 | 1.1.5 | Updated training to use new common runtime to run jobs. Removed Azure Relay usage for AKS extension. Removed service bus usage from the extension. Updated security context usage. Updated inference azureml-fe to v2. Updated to use Volcano as training job scheduler. Bug fixes. |\n| Oct 14, 2021 | 1.0.37 | PV/PVC volume mount support in AMLArc training job. |\n| Sept 16, 2021 | 1.0.29 | New regions available, WestUS, CentralUS, NorthCentralUS, KoreaCentral. Job queue explainability. See job queue details in AML Workspace Studio. Auto-killing policy. Support max_run_duration_seconds in ScriptRunConfig. The system will attempt to automatically cancel the run if it took longer than the setting value. Performance improvement on cluster auto scaling support. Arc agent and ML extension deployment from on premises container registry.|\n| August 24, 2021 | 1.0.28 | Compute instance type is supported in job YAML. Assign Managed Identity to AMLArc compute.|\n| August 10, 2021 | 1.0.20 |New Kubernetes distribution support, K3S - Lightweight Kubernetes. Deploy AzureML extension to your AKS cluster without connecting via Azure Arc. Automated Machine Learning (AutoML) via Python SDK. Use 2.0 CLI to attach the Kubernetes cluster to AML Workspace. Optimize AzureML extension components CPU/memory resources utilization.|\n| July 2, 2021 | 1.0.13 | New Kubernetes distributions support, OpenShift Kubernetes and GKE (Google Kubernetes Engine). Autoscale support. If the user-managed Kubernetes cluster enables the autoscale, the cluster will be automatically scaled out or scaled in according to the volume of active runs and deployments. Performance improvement on job launcher, which shortens the job execution time to a great deal.|\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-kubernetes-349.md"
                }
            }
        ]
    },
    {
        "query": "can you give me an example of a CLI v2 command to register a model?",
        "result": "Sure! Here's an example Azure CLI (v2) command to register a TensorFlow model:\n\n```azurecli\naz ml model create --model-file 'model.pb' --model-name 'tf-model' --model-framework 'TensorFlow' --model-framework-version '2.3' --model-description 'My first TF model' --marketing-name 'TF Model' --build-id 'build-001'\n```\n\nThis command registers a TensorFlow model named `tf-model` with the file `model.pb`. The model has a description of \"My first TF model\", a marketing name of \"TF Model\", and a build ID of \"build-001\". The `--model-framework` and `--model-framework-version` parameters describe the version of TensorFlow used to build the model. \n\nYou can adjust the parameter values depending on the framework you used to build the model.",
        "context": [
            {
                "page_content": "\n# Image processing with batch deployments\n\n[!INCLUDE [ml v2](../../includes/machine-learning-dev-v2.md)]\n\nBatch Endpoints can be used for processing tabular data, but also any other file type like images. Those deployments are supported in both MLflow and custom models. In this tutorial, we will learn how to deploy a model that classifies images according to the ImageNet taxonomy.\n\n## About this sample\n\nThe model we are going to work with was built using TensorFlow along with the RestNet architecture ([Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)). A sample of this model can be downloaded from `https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip`. The model has the following constrains that are important to keep in mind for deployment:\n\n* It works with images of size 244x244 (tensors of `(224, 224, 3)`).\n* It requires inputs to be scaled to the range `[0,1]`.\n\nThe information in this article is based on code samples contained in the [azureml-examples](https://github.com/azure/azureml-examples) repository. To run the commands locally without having to copy/paste YAML and other files, clone the repo, and then change directories to the `cli/endpoints/batch` if you are using the Azure CLI or `sdk/endpoints/batch` if you are using our SDK for Python.\n\n```azurecli\ngit clone https://github.com/Azure/azureml-examples --depth 1\ncd azureml-examples/cli/endpoints/batch\n```\n\n### Follow along in Jupyter Notebooks\n\nYou can follow along this sample in a Jupyter Notebook. In the cloned repository, open the notebook: [imagenet-classifier-batch.ipynb](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/imagenet-classifier-batch.ipynb).\n\n## Prerequisites\n\n[!INCLUDE [basic cli prereqs](../../includes/machine-learning-cli-prereqs.md)]\n\n* You must have a batch endpoint already created. This example assumes the endpoint is named `imagenet-classifier-batch`. If you don't have one, follow the instructions at [Use batch endpoints for batch scoring](how-to-use-batch-endpoint.md).\n* You must have a compute created where to deploy the deployment. This example assumes the name of the compute is `cpu-cluster`. If you don't, follow the instructions at [Create compute](how-to-use-batch-endpoint.md#create-compute).\n\n## Image classification with batch deployments\n\nIn this example, we are going to learn how to deploy a deep learning model that can classify a given image according to the [taxonomy of ImageNet](https://image-net.org/). \n\n### Registering the model\n\nBatch Endpoint can only deploy registered models so we need to register it. You can skip this step if the model you are trying to deploy is already registered.\n\n1. Downloading a copy of the model:\n\n    # [Azure CLI](#tab/cli)\n    \n    ```azurecli\n    wget https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip\n    mkdir -p imagenet-classifier\n    unzip model.zip -d imagenet-classifier\n    ```\n    \n    # [Python](#tab/sdk)\n\n    ```python\n    import os\n    import urllib.request\n    from zipfile import ZipFile\n    \n    response = urllib.request.urlretrieve('https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip', 'model.zip')\n    \n    os.mkdirs(\"imagenet-classifier\", exits_ok=True)\n    with ZipFile(response[0], 'r') as zip:\n      model_path = zip.extractall(path=\"imagenet-classifier\")\n    ```\n    \n2. Register the model:\n   \n    # [Azure CLI](#tab/cli)\n\n    ```azurecli\n    MODEL_NAME='imagenet-classifier'\n    az ml model create --name $MODEL_NAME --type \"custom_model\" --path \"imagenet-classifier/model\"\n    ```\n\n    # [Python](#tab/sdk)\n\n    ```python\n    model_name = 'imagenet-classifier'\n    model = ml_client.models.create_or_update(\n        Model(name=model_name, path=model_path, type=AssetTypes.CUSTOM_MODEL)\n    )\n    ```\n\n### Creating a scoring script\n\nWe need to create a scoring script that can read the images provided by the batch deployment and return the scores of the model. The following script:\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-image-processing-batch-0.md"
                }
            },
            {
                "page_content": "The Bandit early termination policy is also used. This policy terminates poor performing trials; that is, those trials that are not within 20% slack of the best performing trial, which significantly saves compute resources.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\nsweep:\n  sampling_algorithm: random\n  early_termination:\n    type: bandit\n    evaluation_interval: 2\n    slack_factor: 0.2\n    delay_evaluation: 6\n```\n\n```yaml\nsearch_space:\n  - model_name:\n      type: choice\n      values: [yolov5]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.01\n    model_size:\n      type: choice\n      values: [small, medium]\n\n  - model_name:\n      type: choice\n      values: [fasterrcnn_resnet50_fpn]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.001\n    optimizer:\n      type: choice\n      values: [sgd, adam, adamw]\n    min_size:\n      type: choice\n      values: [600, 800]\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=sweep-settings)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=search-space-settings)]\n\n\nOnce the search space and sweep settings are defined, you can then submit the job to train an image model using your training dataset.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nTo submit your AutoML job, you run the following CLI v2 command with the path to your .yml file, workspace name, resource group and subscription ID.\n\n```azurecli\naz ml job create --file ./hello-automl-job-basic.yml --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]\n```\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\nWhen you've configured your AutoML Job to the desired settings, you can submit the job.\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=submit-run)]\n\n\nWhen doing a hyperparameter sweep, it can be useful to visualize the different trials that were tried using the HyperDrive UI. You can navigate to this UI by going to the 'Child jobs' tab in the UI of the main automl_image_job from above, which is the HyperDrive parent job. Then you can go into the 'Child jobs' tab of this one.\n\nAlternatively, here below you can see directly the HyperDrive parent job and navigate to its 'Child jobs' tab:\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n```python\nhd_job = ml_client.jobs.get(returned_job.name + '_HD')\nhd_job\n```\n\n\n## Register and deploy model\n\nOnce the job completes, you can register the model that was created from the best trial (configuration that resulted in the best primary metric). You can either register the model after downloading or by specifying the azureml path with corresponding jobid.  \n\n### Get the best trial\n\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=best_run)] \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/tutorial-auto-train-image-models-387.md"
                }
            },
            {
                "page_content": "\n# CLI (v2) core YAML syntax\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nEvery Azure Machine Learning entity has a schematized YAML representation. You can create a new entity from a YAML configuration file with a `.yml` or `.yaml` extension.\n\nThis article provides an overview of core syntax concepts you will encounter while configuring these YAML files.\n\n\n\n## Referencing an Azure ML entity\n\nAzure ML provides a reference syntax (consisting of a shorthand and longhand format) for referencing an existing Azure ML entity when configuring a YAML file. For example, you can reference an existing registered environment in your workspace to use as the environment for a job.\n\n### Referencing an Azure ML asset\n\nThere are two options for referencing an Azure ML asset (environments, models, data, and components):\n* Reference an explicit version of an asset:\n  * Shorthand syntax: `azureml:<asset_name>:<asset_version>`\n  * Longhand syntax, which includes the Azure Resource Manager (ARM) resource ID of the asset:\n  ```\n  azureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/environments/<environment-name>/versions/<environment-version>\n  ```\n* Reference the latest version of an asset:\n\n  In some scenarios you may want to reference the latest version of an asset without having to explicitly look up and specify the actual version string itself. The latest    version is defined as the latest (also known as most recently) created version of an asset under a given name. \n\n  You can reference the latest version using the following syntax: `azureml:<asset_name>@latest`. Azure ML will resolve the reference to an explicit asset version in the workspace.\n\n### Reference an Azure ML resource\n\nTo reference an Azure ML resource (such as compute), you can use either of the following syntaxes:\n* Shorthand syntax: `azureml:<resource_name>`\n* Longhand syntax, which includes the ARM resource ID of the resource:\n```\nazureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/computes/<compute-name>\n```\n\n## Azure ML data reference URI\n\nAzure ML offers a convenience data reference URI format to point to data in an Azure storage service. This can be used for scenarios where you need to specify a cloud storage location in your YAML file, such as creating an Azure ML model from file(s) in storage, or pointing to data to pass as input to a job.\n\nTo use this data URI format, the storage service you want to reference must first be registered as a datastore in your workspace. Azure ML will handle the data access using the credentials you provided during datastore creation.\n\nThe format consists of a datastore in the current workspace and the path on the datastore to the file or folder you want to point to:\n\n```\nazureml://datastores/<datastore-name>/paths/<path-on-datastore>/\n```\n\nFor example:\n\n* `azureml://datastores/workspaceblobstore/paths/example-data/`\n* `azureml://datastores/workspaceblobstore/paths/example-data/iris.csv`\n\nIn addition to the Azure ML data reference URI, Azure ML also supports the following direct storage URI protocols: `https`, `wasbs`, `abfss`, and `adl`, as well as public `http` and `https` URIs.\n\n## Expression syntax for configuring Azure ML jobs and components\n\nv2 job and component YAML files allow for the use of expressions to bind to contexts for different scenarios. The essential use case is using an expression for a value that might not be known at the time of authoring the configuration, but must be resolved at runtime.\n\nUse the following syntax to tell Azure ML to evaluate an expression rather than treat it as a string:\n\n`${{ <expression> }}`\n\nThe supported scenarios are covered below.\n\n### Parameterizing the `command` with the `inputs` and `outputs` contexts of a job\n\nYou can specify literal values, URI paths, and registered Azure ML data assets as inputs to a job. The `command` can then be parameterized with references to those input(s) using the `${{inputs.<input_name>}}` syntax. References to literal inputs will get resolved to the literal value at runtime, while references to data inputs will get resolved to the download path or mount path (depending on the `mode` specified).\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-yaml-core-syntax-0.md"
                }
            }
        ]
    },
    {
        "query": "how can I create a datastore using the new CLI v2?",
        "result": "You can create a datastore using the new CLI v2 by running the following command:\n```azurecli\naz ml datastore create -n <datastore_name> -c <datastore_container_or_share> -g <resource_group> -w <workspace_name>\n```\nReplace `<datastore_name>` with the name for your new datastore, `<datastore_container_or_share>` with the name of the Azure Blob Container or the Azure File Share used for the datastore, `<resource_group>` with the name of your Azure resource group, and `<workspace_name>` with the name of your Azure Machine Learning workspace. Once the command is executed, a new datastore with the specified attributes will be created.",
        "context": [
            {
                "page_content": "If you have previously labeled data that you would like to use to train your model, you will first need to upload the images to the default Azure Blob Storage of your Azure ML Workspace and register it as a [data asset](how-to-create-data-assets.md). \n\nThe following script uploads the image data on your local machine at path \"./data/odFridgeObjects\" to datastore in Azure Blob Storage. It then creates a new data asset with the name \"fridge-items-images-object-detection\" in your Azure ML Workspace. \n\nIf there already exists a data asset with the name \"fridge-items-images-object-detection\" in your Azure ML Workspace, it will update the version number of the data asset and point it to the new location where the image data uploaded.\n\n# [Azure CLI](#tab/cli)\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nCreate a .yml file with the following configuration.\n\n```yml\n$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json\nname: fridge-items-images-object-detection\ndescription: Fridge-items images Object detection\npath: ./data/odFridgeObjects\ntype: uri_folder\n```\n\nTo upload the images as a data asset, you run the following CLI v2 command with the path to your .yml file, workspace name, resource group and subscription ID.\n\n```azurecli\naz ml data create -f [PATH_TO_YML_FILE] --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]\n```\n\n# [Python SDK](#tab/python)\n\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=upload-data)]\n\n# [Studio](#tab/Studio)\n\n![Animation showing how to register a dataset from local files](media\\how-to-prepare-datasets-for-automl-images\\ui-dataset-local.gif)\n\n\nIf you already have your data present in an existing datastore and want to create a data asset out of it, you can do so by providing the path to the data in the datastore, instead of providing the path of your local machine. Update the code [above](how-to-prepare-datasets-for-automl-images.md#using-pre-labeled-training-data-from-local-machine) with the following snippet.\n\n# [Azure CLI](#tab/cli)\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nCreate a .yml file with the following configuration.\n\n```yml\n$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json\nname: fridge-items-images-object-detection\ndescription: Fridge-items images Object detection\npath: azureml://subscriptions/<my-subscription-id>/resourcegroups/<my-resource-group>/workspaces/<my-workspace>/datastores/<my-datastore>/paths/<path_to_image_data_folder>\ntype: uri_folder\n```\n\n# [Python SDK](#tab/python)\n\n \n```Python\nmy_data = Data(\n    path=\"azureml://subscriptions/<my-subscription-id>/resourcegroups/<my-resource-group>/workspaces/<my-workspace>/datastores/<my-datastore>/paths/<path_to_image_data_folder>\",\n    type=AssetTypes.URI_FOLDER,\n    description=\"Fridge-items images Object detection\",\n    name=\"fridge-items-images-object-detection\",\n)\n```\n\n# [Studio](#tab/Studio)\n\n![Animation showing how to register a dataset from data already present in datastore](media\\how-to-prepare-datasets-for-automl-images\\ui-dataset-datastore.gif)\n\n\nNext, you will need to get the label annotations in JSONL format. The schema of labeled data depends on the computer vision task at hand. Refer to [schemas for JSONL files for AutoML computer vision experiments](reference-automl-images-schema.md) to learn more about the required JSONL schema for each task type.\n\nIf your training data is in a different format (like, pascal VOC or COCO), [helper scripts](https://github.com/Azure/azureml-examples/blob/main/v1/python-sdk/tutorials/automl-with-azureml/image-object-detection/coco2jsonl.py) to convert the data to JSONL are available in [notebook examples](https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs).\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-prepare-datasets-for-automl-images-70.md"
                }
            },
            {
                "page_content": "\n# Troubleshoot data access errors\n\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\nIn this guide, learn how to identify and resolve known issues with data access with the [Azure Machine Learning SDK](https://aka.ms/sdk-v2-install).\n\n## Error Codes\n\nData access error codes are hierarchical. Error codes are delimited by the full stop character `.` and are more specific the more segments there are.\n\n## ScriptExecution.DatabaseConnection\n\n### ScriptExecution.DatabaseConnection.NotFound\n\nThe database or server defined in the datastore couldn't be found or no longer exists. Check if the database still exists in Azure portal or linked to from the Azure Machine Learning studio datastore details page. If it doesn't exist, recreating it with the same name will enable the existing datastore to be used. If a new server name or database is used, the datastore will have to be deleted, and recreated to use the new name.\n\n### ScriptExecution.DatabaseConnection.Authentication\n\nThe authentication failed while trying to connect to the database. The authentication method is stored inside the datastore and supports SQL authentication, service principal, or no stored credential (identity based access). Enabling workspace MSI makes the authentication use the workspace MSI when previewing data in Azure Machine Learning studio. A SQL server user needs to be created for the service principal and workspace MSI (if applicable) and granted classic database permissions. More info can be found [here](/azure/azure-sql/database/authentication-aad-service-principal-tutorial#create-the-service-principal-user-in-azure-sql-database).\n\nContact your data admin to verify or add the correct permissions to the service principal or user identity.\n\nErrors also include:\n\n- ScriptExecution.DatabaseConnection.Authentication.AzureIdentityAccessTokenResolution.InvalidResource\n  - The server under the subscription and resource group couldn't be found. Check that the subscription ID and resource group defined in the datastore matches that of the server and update the values if needed.\n    > [!NOTE]\n    > Use the subscription ID and resource group of the server and not of the workspace. If the datastore is cross subscription or cross resource group server, these will be different.\n- ScriptExecution.DatabaseConnection.Authentication.AzureIdentityAccessTokenResolution.FirewallSettingsResolutionFailure\n  - The identity doesn't have permission to read firewall settings of the target server. Contact your data admin to the Reader role to the workspace MSI.\n\n## ScriptExecution.DatabaseQuery\n\n### ScriptExecution.DatabaseQuery.TimeoutExpired\n\nThe executed SQL query took too long and timed out. The timeout can be specified at time of data asset creation. If a new timeout is needed, a new asset must be created, or a new version of the current asset must be created. In Azure Machine Learning studio SQL preview, there will have a fixed query timeout, but the defined value will always be honored for jobs.\n\n## ScriptExecution.StreamAccess\n\n### ScriptExecution.StreamAccess.Authentication\n\nThe authentication failed while trying to connect to the storage account. The authentication method is stored inside the datastore and depending on the datastore type, can support account key, SAS token, service principal or no stored credential (identity based access). Enabling workspace MSI makes the authentication use the workspace MSI when previewing data in Azure Machine Learning studio.\n\nContact your data admin to verify or add the correct permissions to the service principal or user identity.\n\n> [!IMPORTANT]\n> If identity based access is used, the required RBAC role is Storage Blob Data Reader. If workspace MSI is used for Azure Machine Learning studio preview, the required RBAC roles are Storage Blob Data Reader and Reader.\n\nErrors also include:\n\n- ScriptExecution.StreamAccess.Authentication.AzureIdentityAccessTokenResolution.FirewallSettingsResolutionFailure\n  - The identity doesn't have permission to read firewall settings of the target storage account. Contact your data admin to the Reader role to the workspace MSI.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-troubleshoot-data-access-0.md"
                }
            },
            {
                "page_content": "Invoking a batch endpoint triggers an asynchronous batch inference job. Compute resources are automatically provisioned when the job starts, and automatically de-allocated as the job completes. So you only pay for compute when you use it.\n\nYou can [override compute resource settings](batch-inference/how-to-use-batch-endpoint.md#overwrite-deployment-configuration-per-each-job) (like instance count) and advanced settings (like mini batch size, error threshold, and so on) for each individual batch inference job to speed up execution and reduce cost.\n\n### Flexible data sources and storage\n\nYou can use the following options for input data when invoking a batch endpoint:\n\n- Cloud data: Either a path on Azure Machine Learning registered datastore, a reference to Azure Machine Learning registered V2 data asset, or a public URI. For more information, see [Data in Azure Machine Learning](concept-data.md).\n- Data stored locally: The data will be automatically uploaded to the Azure ML registered datastore and passed to the batch endpoint.\n\n> [!NOTE]\n> - If you're using existing V1 FileDatasets for batch endpoints, we recommend migrating them to V2 data assets. You can then refer to the V2 data assets directly when invoking batch endpoints. Currently, only data assets of type `uri_folder` or `uri_file` are supported. Batch endpoints created with GA CLIv2 (2.4.0 and newer) or GA REST API (2022-05-01 and newer) will not support V1 Datasets.\n> - You can also extract the datastores' URI or path from V1 FileDatasets. For this, you'll use the `az ml dataset show` command with the `--query` parameter and use that information for invoke.\n> - While batch endpoints created with earlier APIs will continue to support V1 FileDatasets, we'll be adding more support for V2 data assets in the latest API versions for better usability and flexibility. For more information on V2 data assets, see [Work with data using SDK v2](how-to-read-write-data-v2.md). For more information on the new V2 experience, see [What is v2](concept-v2.md).\n\nFor more information on supported input options, see [Accessing data from batch endpoints jobs](batch-inference/how-to-access-data-batch-endpoints-jobs.md).\n\nSpecify the storage output location to any datastore and path. By default, batch endpoints store their output to the workspace's default blob store, organized by the Job Name (a system-generated GUID).\n\n### Security\n\n- Authentication: Azure Active Directory Tokens\n- SSL: enabled by default for endpoint invocation\n- VNET support: Batch endpoints support ingress protection. A batch endpoint with ingress protection will accept scoring requests only from hosts inside a virtual network but not from the public internet. A batch endpoint that is created in a private-link enabled workspace will have ingress protection. To create a private-link enabled workspace, see [Create a secure workspace](tutorial-create-secure-workspace.md).\n\n> [!NOTE]\n> Creating batch endpoints in a private-link enabled workspace is only supported in the following versions.\n> - CLI - version 2.15.1 or higher.\n> - REST API - version 2022-05-01 or higher.\n> - SDK V2 - version 0.1.0b3 or higher.\n\n## Next steps\n\n- [How to deploy online endpoints with the Azure CLI and Python SDK](how-to-deploy-online-endpoints.md)\n- [How to deploy batch endpoints with the Azure CLI and Python SDK](batch-inference/how-to-use-batch-endpoint.md)\n- [How to use online endpoints with the studio](how-to-use-managed-online-endpoint-studio.md)\n- [Deploy models with REST](how-to-deploy-with-rest.md)\n- [How to monitor managed online endpoints](how-to-monitor-online-endpoints.md)\n- [How to view managed online endpoint costs](how-to-view-online-endpoints-costs.md)\n- [Manage and increase quotas for resources with Azure Machine Learning](how-to-manage-quotas.md#azure-machine-learning-managed-online-endpoints)\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-endpoints-187.md"
                }
            }
        ]
    },
    {
        "query": "How can I get a list of running compute instances and how long they have been running with the v2 CLI?",
        "result": "You can use the `az ml computetarget list` command with the `--query` parameter to get a list of running compute instances and their properties, including the `creationTime` and `state`. Here is an example command:\n\n```\naz ml computetarget list --query \"[?state=='Running'].{Name:name, CreationTime:creationTime, State:state}\"\n``` \n\nThis command will return a list of running compute instances with the name, creation time, and state properties. You can modify the `--query` parameter to get other properties as well.",
        "context": [
            {
                "page_content": "> The compute instance has 120GB OS disk. If you run out of disk space and get into an unusable state, please clear at least 5 GB disk space on OS disk (mounted on /) through the compute instance terminal by removing files/folders and then do `sudo reboot`. Temporary disk will be freed after restart; you do not need to clear space on temp disk manually. To access the terminal go to compute list page or compute instance details page and click on **Terminal** link. You can check available disk space by running `df -h` on the terminal. Clear at least 5 GB space before doing `sudo reboot`. Please do not stop or restart the compute instance through the Studio until 5 GB disk space has been cleared. Auto shutdowns, including scheduled start or stop as well as idle shutdowns(preview), will not work if the CI disk is full.\n\n## Next steps\n\n* [Quickstart: Create workspace resources you need to get started with Azure Machine Learning](quickstart-create-resources.md).\n* [Tutorial: Train your first ML model](tutorial-1st-experiment-sdk-train.md) shows how to use a compute instance with an integrated notebook.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-compute-instance-125.md"
                }
            },
            {
                "page_content": "\n# How to use parallel job in pipeline (V2)\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\nParallel job lets users accelerate their job execution by distributing repeated tasks on powerful multi-nodes compute clusters. For example, take the scenario where you're running an object detection model on large set of images. With Azure ML Parallel job, you can easily distribute your images to run custom code in parallel on a specific compute cluster. Parallelization could significantly reduce the time cost. Also by using Azure ML parallel job you can simplify and automate your process to make it more efficient.\n\n## Prerequisite\n\nAzure ML parallel job can only be used as one of steps in a pipeline job. Thus, it's important to be familiar with using pipelines. To learn more about Azure ML pipelines, see the following articles.\n\n- Understand what is a [Azure Machine Learning pipeline](concept-ml-pipelines.md)\n- Understand how to use Azure ML pipeline with [CLI v2](how-to-create-component-pipelines-cli.md) and [SDK v2](how-to-create-component-pipeline-python.md).\n\n## Why are parallel jobs needed?\n\nIn the real world, ML engineers always have scale requirements on their training or inferencing tasks. For example, when a data scientist provides a single script to train a sales prediction model, ML engineers need to apply this training task to each individual store. During this scale out process, some challenges are:\n\n- Delay pressure caused by long execution time.\n- Manual intervention to handle unexpected issues to keep the task proceeding.\n\nThe core value of Azure ML parallel job is to split a single serial task into mini-batches and dispatch those mini-batches to multiple computes to execute in parallel. By using parallel jobs, we can:\n\n - Significantly reduce end-to-end execution time.\n - Use Azure ML parallel job's automatic error handling settings.\n\nYou should consider using Azure ML Parallel job if:\n\n - You plan to train many models on top of your partitioned data.\n - You want to accelerate your large scale batch inferencing task.\n\n## Prepare for parallel job\n\nUnlike other types of jobs, a parallel job requires preparation. Follow the next sections to prepare for creating your parallel job.\n\n### Declare the inputs to be distributed and partition setting\n\nParallel job requires only one **major input data** to be split and processed with parallel. The major input data can be either tabular data or a set of files. Different input types can have a different partition method.\n\nThe following table illustrates the relation between input data and partition setting:\n\n| Data format | AML input type | AML input mode | Partition method |\n|: ---------- |: ------------- |: ------------- |: --------------- |\n| File list | `mltable` or<br>`uri_folder` | ro_mount or<br>download | By size (number of files) |\n| Tabular data | `mltable` | direct | By size (estimated physical size) |\n\nYou can declare your major input data with `input_data` attribute in parallel job YAML or Python SDK. And you can bind it with one of your defined `inputs` of your parallel job by using `${{inputs.<input name>}}`. Then to define the partition method for your major input.\n\nFor example, you could set numbers to `mini_batch_size` to partition your data **by size**.\n\n- When using file list input, this value defines the number of files for each mini-batch.\n- When using tabular input, this value defines the estimated physical size for each mini-batch.\n\n# [Azure CLI](#tab/cliv2)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\ntype: pipeline\n\ndisplay_name: iris-batch-prediction-using-parallel\ndescription: The hello world pipeline job with inline parallel job\ntags:\n  tag: tagvalue\n  owner: sdkteam\n\nsettings:\n  default_compute: azureml:cpu-cluster\n\njobs:\n  batch_prediction:\n    type: parallel\n    compute: azureml:cpu-cluster\n    inputs:\n      input_data: \n        type: mltable\n        path: ./neural-iris-mltable\n        mode: direct\n      score_model: \n        type: uri_folder\n        path: ./iris-model\n        mode: download\n    outputs:\n      job_output_file:\n        type: uri_file\n        mode: rw_mount\n\n    input_data: ${{inputs.input_data}}\n    mini_batch_size: \"10kb\"\n    resources:\n        instance_count: 2\n    max_concurrency_per_instance: 2\n\n    logging_level: \"DEBUG\"\n    mini_batch_error_threshold: 5\n    retry_settings:\n      max_retries: 2\n      timeout: 60\n\n    task:\n      type: run_function\n      code: \"./script\"\n      entry_script: iris_prediction.py\n      environment:\n        name: \"prs-env\"\n        version: 1\n        image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n        conda_file: ./environment/environment_parallel.yml\n      program_arguments: >-\n        --model ${{inputs.score_model}}\n        --error_threshold 5\n        --allowed_failed_percent 30\n        --task_overhead_timeout 1200\n        --progress_update_timeout 600\n        --first_task_creation_timeout 600\n        --copy_logs_to_parent True\n        --resource_monitor_interva 20\n      append_row_to: ${{outputs.job_output_file}}\n\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-use-parallel-job-in-pipeline-0.md"
                }
            },
            {
                "page_content": "These same snippets are available when you open your notebook in VS Code. For a complete list of available snippets, see [Azure Machine Learning VS Code Snippets](https://github.com/Azure/azureml-snippets/blob/main/snippets/snippets.md).\n\nYou can browse and search the list of snippets by using the notebook toolbar to open the snippet panel.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/open-snippet-panel.png\" alt-text=\"Open snippet panel tool in the notebook toolbar\":::\n\nFrom the snippets panel, you can also submit a request to add new snippets.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/propose-new-snippet.png\" alt-text=\"Snippet panel allows you to propose a new snippet\":::\n-->\n## Share a notebook\n\nYour notebooks are stored in your workspace's storage account, and can be shared with others, depending on their [access level](how-to-assign-roles.md) to your workspace.  They can open and edit the notebook as long as they have the appropriate access. For example, a Contributor can edit the notebook, while a Reader could only view it.\n\nOther users of your workspace can find your notebook in the **Notebooks**, **User files** section of Azure ML studio. By default, your notebooks are in a folder with your username, and others can access them there.\n\nYou can also copy the URL from your browser when you open a notebook, then send to others.  As long as they have appropriate access to your workspace, they can open the notebook.\n\nSince you don't share compute instances, other users who run your notebook will do so on their own compute instance.  \n\n## Collaborate with notebook comments (preview)\n\nUse a notebook comment to collaborate with others who have access to your notebook.\n\nToggle the comments pane on and off with the **Notebook comments** tool at the top of the notebook.  If your screen isn't wide enough, find this tool by first selecting the **...** at the end of the set of tools.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/notebook-comments-tool.png\" alt-text=\"Screenshot of notebook comments tool in the top toolbar.\":::  \n\nWhether the comments pane is visible or not, you can add a comment into any code cell:\n\n1. Select some text in the code cell.  You can only comment on text in a code cell.\n1. Use the **New comment thread** tool to create your comment.\n    :::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/comment-from-code.png\" alt-text=\"Screenshot of add a comment to a code cell tool.\":::\n1. If the comments pane was previously hidden, it will now open.  \n1. Type your comment and post it with the tool or use **Ctrl+Enter**.\n1. Once a comment is posted, select **...** in the top right to:\n    * Edit the comment\n    * Resolve the thread\n    * Delete the thread\n\nText that has been commented will appear with a purple highlight in the code. When you select a comment in the comments pane, your notebook will scroll to the cell that contains the highlighted text.\n\n> [!NOTE]\n> Comments are saved into the code cell's metadata.\n\n## Clean your notebook (preview)\n\nOver the course of creating a notebook, you typically end up with cells you used for data exploration or debugging. The *gather* feature will help you produce a clean notebook without these extraneous cells.\n\n1. Run all of your notebook cells.\n1. Select the cell containing the code you wish the new notebook to run. For example, the code that submits an experiment, or perhaps the code that registers a model.\n1. Select the **Gather** icon that appears on the cell toolbar.\n    :::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/gather.png\" alt-text=\"Screenshot: select the Gather icon\":::\n1. Enter the name for your new \"gathered\" notebook.  \n\nThe new notebook contains only code cells, with all cells required to produce the same results as the cell you selected for gathering.\n\n## Save and checkpoint a notebook\n\nAzure\u00a0Machine\u00a0Learning\u00a0creates\u00a0a\u00a0checkpoint\u00a0file\u00a0when\u00a0you\u00a0create\u00a0an\u00a0*ipynb*\u00a0file.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-run-jupyter-notebooks-58.md"
                }
            }
        ]
    },
    {
        "query": "how can I create a GPU compute cluster using the new CLI v2?",
        "result": "To create a GPU compute cluster using the new CLI v2, you can use the `az ml computetarget create` command. First, make sure you have the Azure CLI installed and the Machine Learning extension for Azure CLI.\n\nHere's an example command to create a new GPU compute cluster with a Standard_NC6 family virtual machine and \"Dedicated\" pricing tier:\n\n```\naz ml computetarget create --name gpu-cluster --type AmlCompute --min-instances 0 --max-instances 4 --vm-size Standard_NC6 --idle-seconds-before-scaledown 120 --admin-username azureuser --admin-user-password Password@1234 --priority Dedicated\n```\n\nReplace the `--name` argument of \"gpu-cluster\" with your desired name for the compute cluster, and adjust the `--vm-size` argument to your desired virtual machine size.\n\nYou'll also need to replace the `--admin-username` and `--admin-user-password` arguments with valid values for a new administrator user that will be created on the virtual machines in the cluster.",
        "context": [
            {
                "page_content": "\nIf you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead.\n\n```python\n# Handle to the workspace\n# from azure.ai.ml import MLClient\n\n# Authentication package\n# from azure.identity import InteractiveBrowserCredential\n# credential = InteractiveBrowserCredential()\n```\n\nNext, get a handle to the workspace by providing your Subscription ID, Resource Group name, and workspace name. To find these parameters:\n\n1. Look for your workspace name in the upper-right corner of the Azure Machine Learning studio toolbar.\n2. Select your workspace name to show your Resource Group and Subscription ID.\n3. Copy the values for Resource Group and Subscription ID into the code.\n\n```python\n# Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=\"<SUBSCRIPTION_ID>\",\n    resource_group_name=\"<RESOURCE_GROUP>\",\n    workspace_name=\"<AML_WORKSPACE_NAME>\",\n)\n```\n\nThe result of running this script is a workspace handle that you'll use to manage other resources and jobs.\n\n> [!NOTE]\n> - Creating `MLClient` will not connect the client to the workspace. The client initialization is lazy and will wait for the first time it needs to make a call. In this article, this will happen during compute creation.\n\n### Create a compute resource to run the job\n\nAzureML needs a compute resource to run a job. This resource can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n\nIn the following example script, we provision a Linux [`compute cluster`](./how-to-create-attach-compute-cluster.md?tabs=python). You can see the [`Azure Machine Learning pricing`](https://azure.microsoft.com/pricing/details/machine-learning/) page for the full list of VM sizes and prices. Since we need a GPU cluster for this example, let's pick a *STANDARD_NC6* model and create an AzureML compute.\n\n```python\nfrom azure.ai.ml.entities import AmlCompute\n\ngpu_compute_target = \"gpu-cluster\"\n\ntry:\n    # let's see if the compute target already exists\n    gpu_cluster = ml_client.compute.get(gpu_compute_target)\n    print(\n        f\"You already have a cluster named {gpu_compute_target}, we'll reuse it as is.\"\n    )\n\nexcept Exception:\n    print(\"Creating a new gpu compute target...\")\n\n    # Let's create the Azure ML compute object with the intended parameters\n    gpu_cluster = AmlCompute(\n        # Name assigned to the compute cluster\n        name=\"gpu-cluster\",\n        # Azure ML Compute is the on-demand VM service\n        type=\"amlcompute\",\n        # VM Family\n        size=\"STANDARD_NC6\",\n        # Minimum running nodes when there is no job running\n        min_instances=0,\n        # Nodes in cluster\n        max_instances=4,\n        # How many seconds will the node running after the job termination\n        idle_time_before_scale_down=180,\n        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n        tier=\"Dedicated\",\n    )\n\n    # Now, we pass the object to MLClient's create_or_update method\n    gpu_cluster = ml_client.begin_create_or_update(gpu_cluster).result()\n\nprint(\n    f\"AMLCompute with name {gpu_cluster.name} is created, the compute size is {gpu_cluster.size}\"\n)\n```\n\n### Create a job environment\n\nTo run an AzureML job, you'll need an environment. An AzureML [environment](concept-environments.md) encapsulates the dependencies (such as software runtime and libraries) needed to run your machine learning training script on your compute resource. This environment is similar to a Python environment on your local machine.\n\nAzureML allows you to either use a curated (or ready-made) environment\u2014useful for common training and inference scenarios\u2014or create a custom environment using a Docker image or a Conda configuration. \n\nIn this article, you'll reuse the curated AzureML environment `AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu`. You'll use the latest version of this environment using the `@latest` directive.\n\n```python\ncurated_env_name = \"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\"\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-train-tensorflow-56.md"
                }
            },
            {
                "page_content": "\nIf you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead.\n\n```python\n# Handle to the workspace\n# from azure.ai.ml import MLClient\n\n# Authentication package\n# from azure.identity import InteractiveBrowserCredential\n# credential = InteractiveBrowserCredential()\n```\n\nNext, get a handle to the workspace by providing your Subscription ID, Resource Group name, and workspace name. To find these parameters:\n\n1. Look for your workspace name in the upper-right corner of the Azure Machine Learning studio toolbar.\n2. Select your workspace name to show your Resource Group and Subscription ID.\n3. Copy the values for Resource Group and Subscription ID into the code.\n\n```python\n# Get a handle to the workspace\nml_client = MLClient(\n    credential=credential,\n    subscription_id=\"<SUBSCRIPTION_ID>\",\n    resource_group_name=\"<RESOURCE_GROUP>\",\n    workspace_name=\"<AML_WORKSPACE_NAME>\",\n)\n```\n\nThe result of running this script is a workspace handle that you'll use to manage other resources and jobs.\n\n> [!NOTE]\n> - Creating `MLClient` will not connect the client to the workspace. The client initialization is lazy and will wait for the first time it needs to make a call. In this article, this will happen during compute creation.\n\n### Create a compute resource to run the job\n\nAzureML needs a compute resource to run a job. This resource can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n\nIn the following example script, we provision a Linux [`compute cluster`](./how-to-create-attach-compute-cluster.md?tabs=python). You can see the [`Azure Machine Learning pricing`](https://azure.microsoft.com/pricing/details/machine-learning/) page for the full list of VM sizes and prices. Since we need a GPU cluster for this example, let's pick a *STANDARD_NC6* model and create an AzureML compute.\n\n```python\nfrom azure.ai.ml.entities import AmlCompute\n\ngpu_compute_taget = \"gpu-cluster\"\n\ntry:\n    # let's see if the compute target already exists\n    gpu_cluster = ml_client.compute.get(gpu_compute_taget)\n    print(\n        f\"You already have a cluster named {gpu_compute_taget}, we'll reuse it as is.\"\n    )\n\nexcept Exception:\n    print(\"Creating a new gpu compute target...\")\n\n    # Let's create the Azure ML compute object with the intended parameters\n    gpu_cluster = AmlCompute(\n        # Name assigned to the compute cluster\n        name=\"gpu-cluster\",\n        # Azure ML Compute is the on-demand VM service\n        type=\"amlcompute\",\n        # VM Family\n        size=\"STANDARD_NC6\",\n        # Minimum running nodes when there is no job running\n        min_instances=0,\n        # Nodes in cluster\n        max_instances=4,\n        # How many seconds will the node running after the job termination\n        idle_time_before_scale_down=180,\n        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n        tier=\"Dedicated\",\n    )\n\n    # Now, we pass the object to MLClient's create_or_update method\n    gpu_cluster = ml_client.begin_create_or_update(gpu_cluster).result()\n\nprint(\n    f\"AMLCompute with name {gpu_cluster.name} is created, the compute size is {gpu_cluster.size}\"\n)\n```\n\n### Create a job environment\n\nTo run an AzureML job, you'll need an environment. An AzureML [environment](concept-environments.md) encapsulates the dependencies (such as software runtime and libraries) needed to run your machine learning training script on your compute resource. This environment is similar to a Python environment on your local machine.\n\nAzureML allows you to either use a curated (or ready-made) environment or create a custom environment using a Docker image or a Conda configuration. In this article, you'll reuse the curated AzureML environment `AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu`. You'll use the latest version of this environment using the `@latest` directive.\n\n```python\ncurated_env_name = \"AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu@latest\"\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-train-pytorch-52.md"
                }
            },
            {
                "page_content": "For more information on workspaces, see [how to manage resources in VS Code](how-to-manage-resources-vscode.md).\n\n## Create a GPU cluster for training\n\nA compute target is the computing resource or environment where you run training jobs. For more information, see the [Azure Machine Learning compute targets documentation](./concept-compute-target.md).\n\n1. In the Azure Machine Learning view, expand your workspace node.\n1. Right-click the **Compute clusters** node inside your workspace's **Compute** node and select **Create Compute**\n\n    > [!div class=\"mx-imgBorder\"]\n    > ![Create training compute cluster](./media/tutorial-train-deploy-image-classification-model-vscode/create-compute.png)\n\n1. A specification file appears. Configure the specification file with the following options.\n\n    ```yml\n    $schema: https://azuremlschemas.azureedge.net/latest/compute.schema.json\n    name: gpu-cluster\n    type: amlcompute\n    size: Standard_NC12\n    \n    min_instances: 0\n    max_instances: 3\n    idle_time_before_scale_down: 120\n    ```\n\n    The specification file creates a GPU cluster called `gpu-cluster` with at most 3 Standard_NC12 VM nodes that automatically scales down to 0 nodes after 120 seconds of inactivity.\n\n    For more information on VM sizes, see [sizes for Linux virtual machines in Azure](../virtual-machines/sizes.md).\n\n1. Right-click the specification file and select **Azure ML: Execute YAML**.\n\nAfter a few minutes, the new compute target appears in the *Compute > Compute clusters* node of your workspace.\n\n## <a name=\"train-the-model\"></a> Train image classification model\n\nDuring the training process, a TensorFlow model is trained by processing the training data and learning patterns embedded within it for each of the respective digits being classified.\n\nLike workspaces and compute targets, training jobs are defined using resource templates. For this sample, the specification is defined in the *job.yml* file which looks like the following:\n\n```yml\n$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\ncode: src\ncommand: >\n    python train.py\nenvironment: azureml:AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu:48\ncompute: azureml:gpu-cluster\nexperiment_name: tensorflow-mnist-example\ndescription: Train a basic neural network with TensorFlow on the MNIST dataset.\n```\n\nThis specification file submits a training job called `tensorflow-mnist-example` to the recently created `gpu-cluster` computer target that runs the code in the *train.py* Python script. The environment used is one of the curated environments provided by Azure Machine Learning which contains TensorFlow and other software dependencies required to run the training script. For more information on curated environments, see [Azure Machine Learning curated environments](resource-curated-environments.md).\n\nTo submit the training job:\n\n1. Open the *job.yml* file.\n1. Right-click the file in the text editor and select **Azure ML: Execute YAML**.\n\nAt this point, a request is sent to Azure to run your experiment on the selected compute target in your workspace. This process takes several minutes. The amount of time to run the training job is impacted by several factors like the compute type and training data size. To track the progress of your experiment, right-click the current run node and select **View Job in Azure portal**.\n\nWhen the dialog requesting to open an external website appears, select **Open**.\n\n> [!div class=\"mx-imgBorder\"]\n> ![Track experiment progress](./media/tutorial-train-deploy-image-classification-model-vscode/track-experiment-progress.png)\n\nWhen the model is done training, the status label next to the run node updates to \"Completed\".\n\n## Next steps\n\nIn this tutorial, you learn the following tasks:\n\n> [!div class=\"checklist\"]\n> * Understand the code\n> * Create a workspace\n> * Create a GPU cluster for training\n> * Train a model\n\nFor next steps, see:\n\n* [Create and manage Azure Machine Learning resources using Visual Studio Code](how-to-set-up-vs-code-remote.md).\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/tutorial-train-deploy-image-classification-model-vscode-62.md"
                }
            }
        ]
    }
]