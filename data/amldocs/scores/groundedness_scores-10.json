[
    {
        "question": "can you give me an example of a yaml file to train a model with the CLI v2?",
        "reply": "Certainly! Here's an example YAML file that can be used to define an Azure ML pipeline for training a machine learning model:\n\n```yaml\n# pipeline.yml\n\nname: my-pipeline\ndescription: Example pipeline to train a machine learning model\n\n# Define environment(s) for this pipeline (optional)\nenvironments:\n  my-env:\n    docker:\n      enabled: true\n      base_image: mcr.microsoft.com/azureml/base:latest\n    python:\n      packages:\n        - foo\n        - bar==1.0.0\n\n# Define compute target(s) to run this pipeline\ncomputes:\n  my-compute: # The name of the compute resource you want to execute your code/resource on\n    vm_size: standard_d2_v2 # The Azure VM size to use for this compute resource\n    min_nodes: 0 # Optional. Minimum number of nodes for the compute target. If not provided, the minimum is 0\n    max_nodes: 4 # Optional. Max number of nodes for the compute target. If not provided, the maximum is 4\n    idle_seconds_before_scaledown: 300 # Optional. Number of seconds idle before scaling down compute resource. Default is 300 (5 min)\n    remote_login_port_publicaccess: Enabled # Optional. Enable or disable SSH or Remote Desktop access to compute instance.\n\n# Define a single step in the pipeline\nsteps:\n- name: training\n  arguments:\n    script: my_training_script.py\n    inputs:\n      data: /path/to/training/data\n    outputs:\n      model: /path/to/persisted/model\n  run_specs:\n    compute: my-compute\n    environment: my-env\n  is_exit_step: false # Optional. Indicates whether this is the last step in the pipeline. Default is false.\n\n# Define the pipeline\npipeline: \n  endpoint: /subscriptions/{subscription-id}/resourceGroups/{resource-group-name}/providers/Microsoft.MachineLearningServices/workspaces/{workspace-name}/endpoints/{pipeline-end-point-name}\n```\n\nThis YAML file defines a pipeline with a single step for training a machine learning model. The pipeline will execute on a compute target called `my-compute`. The step will execute a Python script called `my_training_script.py` that expects training data to be inputted from `/path/to/training/data`, and will output a trained model to `/path/to/persisted/model`. Finally, the pipeline itself is defined and points to the end point location. \n\nFor more information on creating and running machine learning pipelines using components with the Azure Machine Learning CLI v2, refer to the [official documentation](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-machine-learning-pipelines-cli).",
        "ungrounded_facts": [],
        "rating_out_of_10": 10
    },
    {
        "question": "how can I run a job under the user's identity using CLI v2? Please provide a concrete example of a yaml file.",
        "reply": "To run a batch deployment job under the user's identity using CLI v2, you can create a YAML file similar to the following example:\n\n```\n$schema: https://azuremlschemas.azureedge.net/latest/job-1.0.0.yaml\nname: sample-job\ncompute:\n  target: \"local\"\ntype: automl\ntask: image_classification\ntraining_data:\n  source: \n    type: azure_blob_mount\n    container_name: my_container\n    account_name: my_account\n  use_training_data: true\n  target_column_name: ImageFolder\n  ignore_column_identifiers: []\nprimary_metric: accuracy\nallowed_models: []\nfeaturization: {}\nmodel_explainability: false\nmodel_interaction: false\nexit_score_retries: 1\nallowed_exit_scores: []\n```\n\nThen, you can run the job with the following command:\n\n```\naz ml job create --file myjob.yaml\n```\n\nPlease note that the `--file` argument must include the relative or absolute path to your YAML file.",
        "ungrounded_facts": [],
        "rating_out_of_10": 10
    },
    {
        "question": "how can I use my csv file in a job using the v2 cli?",
        "reply": "You can use a YAML file to specify the job that you want to execute. You can pass the CSV file as an input to the job so that you can use it in your script. Here is an example YAML file where we use an `InputDirectory` named `input` to pass a CSV file to the job as input:\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/CommandJob.schema.json\n\ncode: src\ncommand: python my_script.py --input-file ${{inputs.input}}\ninputs:\n  input:\n    type: InputDirectory\n    path: ./data\nenvironment: azureml:AzureML-Minimal@latest\ncompute: local\n```\n\nIn this YAML file, `src` is the code directory, `my_script.py` is the script you want to execute, and `./data` is the directory containing your CSV file. You can execute this job using the following command:\n\n```azurecli\naz ml job create --file job.yml\n```\n\nThis command submits the job to the default environment and compute `(compute=local)`. If you want to submit the job to a remote compute (e.g. a cluster), you can modify the `compute` field in the YAML file accordingly.",
        "ungrounded_facts": [],
        "rating_out_of_10": 10
    },
    {
        "question": "how can I register a model from a job using the v2 cli?",
        "reply": "To register a model from a job using the v2 CLI, you can use the following command: \n```\naz ml model register --experiment-name <your-experiment-name> --run-id <your-run-id> --model-name <your-model-name> --model-path <your-model-path>\n```\nReplace `<your-experiment-name>` with the name of the experiment where the model was trained, `<your-run-id>` with the ID of the job run that produced the model, `<your-model-name>` with the name you want to give the registered model, and `<your-model-path>` with the path to the model file within the job run files (for example, `outputs/model.pkl`).\nNote that the `az ml` CLI command requires authentication through Azure Active Directory (AAD). If you haven't already, you will need to install and configure the [Azure CLI v2.0](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) and then sign in to your Azure account by running `az login`.",
        "ungrounded_facts": [],
        "rating_out_of_10": 10
    },
    {
        "question": "I'm trying to access the files/artifacts located in the code tab under an AzureML job. How can I download the code of a job with the v2 CLI?",
        "reply": "You can download the files/artifacts located in the code tab under an AzureML job with the v2 CLI by running the following command:\n\n```azurecli\naz ml job download -n <job-name> --type sdk\n```\n\nReplace `<job-name>` with the name of the job you want to download. The `--type` parameter specifies the type of artifact you want to download, and can be set to `sdk` for Python SDK code, `other` for other generic artifacts, or `all` for all artifacts. The downloaded artifacts will be located in the `outputs` folder of the current working directory.",
        "ungrounded_facts": [],
        "rating_out_of_10": 0
    },
    {
        "question": "how can I cancel a run using the new v2 cli?",
        "reply": "To cancel a run using the new v2 CLI, use the command `az ml run cancel` followed by the run ID. For example, to cancel a run with the ID `abc123`, use the command `az ml run cancel --run-id abc123`. You can also cancel multiple runs at once by providing a list of run IDs.",
        "ungrounded_facts": [],
        "rating_out_of_10": 10
    },
    {
        "query": "can you give me an example of a CLI v2 command to register a model?",
        "result": "Sure! Here's an example Azure CLI (v2) command to register a TensorFlow model:\n\n```azurecli\naz ml model create --model-file 'model.pb' --model-name 'tf-model' --model-framework 'TensorFlow' --model-framework-version '2.3' --model-description 'My first TF model' --marketing-name 'TF Model' --build-id 'build-001'\n```\n\nThis command registers a TensorFlow model named `tf-model` with the file `model.pb`. The model has a description of \"My first TF model\", a marketing name of \"TF Model\", and a build ID of \"build-001\". The `--model-framework` and `--model-framework-version` parameters describe the version of TensorFlow used to build the model. \n\nYou can adjust the parameter values depending on the framework you used to build the model.",
        "context": [
            {
                "page_content": "\n# Image processing with batch deployments\n\n[!INCLUDE [ml v2](../../includes/machine-learning-dev-v2.md)]\n\nBatch Endpoints can be used for processing tabular data, but also any other file type like images. Those deployments are supported in both MLflow and custom models. In this tutorial, we will learn how to deploy a model that classifies images according to the ImageNet taxonomy.\n\n## About this sample\n\nThe model we are going to work with was built using TensorFlow along with the RestNet architecture ([Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)). A sample of this model can be downloaded from `https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip`. The model has the following constrains that are important to keep in mind for deployment:\n\n* It works with images of size 244x244 (tensors of `(224, 224, 3)`).\n* It requires inputs to be scaled to the range `[0,1]`.\n\nThe information in this article is based on code samples contained in the [azureml-examples](https://github.com/azure/azureml-examples) repository. To run the commands locally without having to copy/paste YAML and other files, clone the repo, and then change directories to the `cli/endpoints/batch` if you are using the Azure CLI or `sdk/endpoints/batch` if you are using our SDK for Python.\n\n```azurecli\ngit clone https://github.com/Azure/azureml-examples --depth 1\ncd azureml-examples/cli/endpoints/batch\n```\n\n### Follow along in Jupyter Notebooks\n\nYou can follow along this sample in a Jupyter Notebook. In the cloned repository, open the notebook: [imagenet-classifier-batch.ipynb](https://github.com/Azure/azureml-examples/blob/main/sdk/python/endpoints/batch/imagenet-classifier-batch.ipynb).\n\n## Prerequisites\n\n[!INCLUDE [basic cli prereqs](../../includes/machine-learning-cli-prereqs.md)]\n\n* You must have a batch endpoint already created. This example assumes the endpoint is named `imagenet-classifier-batch`. If you don't have one, follow the instructions at [Use batch endpoints for batch scoring](how-to-use-batch-endpoint.md).\n* You must have a compute created where to deploy the deployment. This example assumes the name of the compute is `cpu-cluster`. If you don't, follow the instructions at [Create compute](how-to-use-batch-endpoint.md#create-compute).\n\n## Image classification with batch deployments\n\nIn this example, we are going to learn how to deploy a deep learning model that can classify a given image according to the [taxonomy of ImageNet](https://image-net.org/). \n\n### Registering the model\n\nBatch Endpoint can only deploy registered models so we need to register it. You can skip this step if the model you are trying to deploy is already registered.\n\n1. Downloading a copy of the model:\n\n    # [Azure CLI](#tab/cli)\n    \n    ```azurecli\n    wget https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip\n    mkdir -p imagenet-classifier\n    unzip model.zip -d imagenet-classifier\n    ```\n    \n    # [Python](#tab/sdk)\n\n    ```python\n    import os\n    import urllib.request\n    from zipfile import ZipFile\n    \n    response = urllib.request.urlretrieve('https://azuremlexampledata.blob.core.windows.net/data/imagenet/model.zip', 'model.zip')\n    \n    os.mkdirs(\"imagenet-classifier\", exits_ok=True)\n    with ZipFile(response[0], 'r') as zip:\n      model_path = zip.extractall(path=\"imagenet-classifier\")\n    ```\n    \n2. Register the model:\n   \n    # [Azure CLI](#tab/cli)\n\n    ```azurecli\n    MODEL_NAME='imagenet-classifier'\n    az ml model create --name $MODEL_NAME --type \"custom_model\" --path \"imagenet-classifier/model\"\n    ```\n\n    # [Python](#tab/sdk)\n\n    ```python\n    model_name = 'imagenet-classifier'\n    model = ml_client.models.create_or_update(\n        Model(name=model_name, path=model_path, type=AssetTypes.CUSTOM_MODEL)\n    )\n    ```\n\n### Creating a scoring script\n\nWe need to create a scoring script that can read the images provided by the batch deployment and return the scores of the model. The following script:\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-image-processing-batch-0.md"
                }
            },
            {
                "page_content": "The Bandit early termination policy is also used. This policy terminates poor performing trials; that is, those trials that are not within 20% slack of the best performing trial, which significantly saves compute resources.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\nsweep:\n  sampling_algorithm: random\n  early_termination:\n    type: bandit\n    evaluation_interval: 2\n    slack_factor: 0.2\n    delay_evaluation: 6\n```\n\n```yaml\nsearch_space:\n  - model_name:\n      type: choice\n      values: [yolov5]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.01\n    model_size:\n      type: choice\n      values: [small, medium]\n\n  - model_name:\n      type: choice\n      values: [fasterrcnn_resnet50_fpn]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.001\n    optimizer:\n      type: choice\n      values: [sgd, adam, adamw]\n    min_size:\n      type: choice\n      values: [600, 800]\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=sweep-settings)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=search-space-settings)]\n\n\nOnce the search space and sweep settings are defined, you can then submit the job to train an image model using your training dataset.\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nTo submit your AutoML job, you run the following CLI v2 command with the path to your .yml file, workspace name, resource group and subscription ID.\n\n```azurecli\naz ml job create --file ./hello-automl-job-basic.yml --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]\n```\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\nWhen you've configured your AutoML Job to the desired settings, you can submit the job.\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=submit-run)]\n\n\nWhen doing a hyperparameter sweep, it can be useful to visualize the different trials that were tried using the HyperDrive UI. You can navigate to this UI by going to the 'Child jobs' tab in the UI of the main automl_image_job from above, which is the HyperDrive parent job. Then you can go into the 'Child jobs' tab of this one.\n\nAlternatively, here below you can see directly the HyperDrive parent job and navigate to its 'Child jobs' tab:\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n```python\nhd_job = ml_client.jobs.get(returned_job.name + '_HD')\nhd_job\n```\n\n\n## Register and deploy model\n\nOnce the job completes, you can register the model that was created from the best trial (configuration that resulted in the best primary metric). You can either register the model after downloading or by specifying the azureml path with corresponding jobid.  \n\n### Get the best trial\n\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n```yaml\nCLI example not available, please use Python SDK.\n```\n\n\n# [Python SDK](#tab/python)\n[!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=best_run)] \n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/tutorial-auto-train-image-models-387.md"
                }
            },
            {
                "page_content": "\n# CLI (v2) core YAML syntax\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nEvery Azure Machine Learning entity has a schematized YAML representation. You can create a new entity from a YAML configuration file with a `.yml` or `.yaml` extension.\n\nThis article provides an overview of core syntax concepts you will encounter while configuring these YAML files.\n\n\n\n## Referencing an Azure ML entity\n\nAzure ML provides a reference syntax (consisting of a shorthand and longhand format) for referencing an existing Azure ML entity when configuring a YAML file. For example, you can reference an existing registered environment in your workspace to use as the environment for a job.\n\n### Referencing an Azure ML asset\n\nThere are two options for referencing an Azure ML asset (environments, models, data, and components):\n* Reference an explicit version of an asset:\n  * Shorthand syntax: `azureml:<asset_name>:<asset_version>`\n  * Longhand syntax, which includes the Azure Resource Manager (ARM) resource ID of the asset:\n  ```\n  azureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/environments/<environment-name>/versions/<environment-version>\n  ```\n* Reference the latest version of an asset:\n\n  In some scenarios you may want to reference the latest version of an asset without having to explicitly look up and specify the actual version string itself. The latest    version is defined as the latest (also known as most recently) created version of an asset under a given name. \n\n  You can reference the latest version using the following syntax: `azureml:<asset_name>@latest`. Azure ML will resolve the reference to an explicit asset version in the workspace.\n\n### Reference an Azure ML resource\n\nTo reference an Azure ML resource (such as compute), you can use either of the following syntaxes:\n* Shorthand syntax: `azureml:<resource_name>`\n* Longhand syntax, which includes the ARM resource ID of the resource:\n```\nazureml:/subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-name>/computes/<compute-name>\n```\n\n## Azure ML data reference URI\n\nAzure ML offers a convenience data reference URI format to point to data in an Azure storage service. This can be used for scenarios where you need to specify a cloud storage location in your YAML file, such as creating an Azure ML model from file(s) in storage, or pointing to data to pass as input to a job.\n\nTo use this data URI format, the storage service you want to reference must first be registered as a datastore in your workspace. Azure ML will handle the data access using the credentials you provided during datastore creation.\n\nThe format consists of a datastore in the current workspace and the path on the datastore to the file or folder you want to point to:\n\n```\nazureml://datastores/<datastore-name>/paths/<path-on-datastore>/\n```\n\nFor example:\n\n* `azureml://datastores/workspaceblobstore/paths/example-data/`\n* `azureml://datastores/workspaceblobstore/paths/example-data/iris.csv`\n\nIn addition to the Azure ML data reference URI, Azure ML also supports the following direct storage URI protocols: `https`, `wasbs`, `abfss`, and `adl`, as well as public `http` and `https` URIs.\n\n## Expression syntax for configuring Azure ML jobs and components\n\nv2 job and component YAML files allow for the use of expressions to bind to contexts for different scenarios. The essential use case is using an expression for a value that might not be known at the time of authoring the configuration, but must be resolved at runtime.\n\nUse the following syntax to tell Azure ML to evaluate an expression rather than treat it as a string:\n\n`${{ <expression> }}`\n\nThe supported scenarios are covered below.\n\n### Parameterizing the `command` with the `inputs` and `outputs` contexts of a job\n\nYou can specify literal values, URI paths, and registered Azure ML data assets as inputs to a job. The `command` can then be parameterized with references to those input(s) using the `${{inputs.<input_name>}}` syntax. References to literal inputs will get resolved to the literal value at runtime, while references to data inputs will get resolved to the download path or mount path (depending on the `mode` specified).\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-yaml-core-syntax-0.md"
                }
            }
        ],
        "rating_out_of_10": 0,
        "error": "Error parsing result json: Expecting ',' delimiter: line 3 column 456 (char 544)"
    },
    {
        "question": "how can I create a datastore using the new CLI v2?",
        "reply": "You can create a datastore using the new CLI v2 by running the following command:\n```azurecli\naz ml datastore create -n <datastore_name> -c <datastore_container_or_share> -g <resource_group> -w <workspace_name>\n```\nReplace `<datastore_name>` with the name for your new datastore, `<datastore_container_or_share>` with the name of the Azure Blob Container or the Azure File Share used for the datastore, `<resource_group>` with the name of your Azure resource group, and `<workspace_name>` with the name of your Azure Machine Learning workspace. Once the command is executed, a new datastore with the specified attributes will be created.",
        "ungrounded_facts": [
            "az ml datastore create -n <datastore_name> -c <datastore_container_or_share> -g <resource_group> -w <workspace_name>"
        ],
        "rating_out_of_10": 0
    },
    {
        "query": "How can I get a list of running compute instances and how long they have been running with the v2 CLI?",
        "result": "You can use the `az ml computetarget list` command with the `--query` parameter to get a list of running compute instances and their properties, including the `creationTime` and `state`. Here is an example command:\n\n```\naz ml computetarget list --query \"[?state=='Running'].{Name:name, CreationTime:creationTime, State:state}\"\n``` \n\nThis command will return a list of running compute instances with the name, creation time, and state properties. You can modify the `--query` parameter to get other properties as well.",
        "context": [
            {
                "page_content": "> The compute instance has 120GB OS disk. If you run out of disk space and get into an unusable state, please clear at least 5 GB disk space on OS disk (mounted on /) through the compute instance terminal by removing files/folders and then do `sudo reboot`. Temporary disk will be freed after restart; you do not need to clear space on temp disk manually. To access the terminal go to compute list page or compute instance details page and click on **Terminal** link. You can check available disk space by running `df -h` on the terminal. Clear at least 5 GB space before doing `sudo reboot`. Please do not stop or restart the compute instance through the Studio until 5 GB disk space has been cleared. Auto shutdowns, including scheduled start or stop as well as idle shutdowns(preview), will not work if the CI disk is full.\n\n## Next steps\n\n* [Quickstart: Create workspace resources you need to get started with Azure Machine Learning](quickstart-create-resources.md).\n* [Tutorial: Train your first ML model](tutorial-1st-experiment-sdk-train.md) shows how to use a compute instance with an integrated notebook.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/concept-compute-instance-125.md"
                }
            },
            {
                "page_content": "\n# How to use parallel job in pipeline (V2)\n\n[!INCLUDE [dev v2](../../includes/machine-learning-dev-v2.md)]\n\nParallel job lets users accelerate their job execution by distributing repeated tasks on powerful multi-nodes compute clusters. For example, take the scenario where you're running an object detection model on large set of images. With Azure ML Parallel job, you can easily distribute your images to run custom code in parallel on a specific compute cluster. Parallelization could significantly reduce the time cost. Also by using Azure ML parallel job you can simplify and automate your process to make it more efficient.\n\n## Prerequisite\n\nAzure ML parallel job can only be used as one of steps in a pipeline job. Thus, it's important to be familiar with using pipelines. To learn more about Azure ML pipelines, see the following articles.\n\n- Understand what is a [Azure Machine Learning pipeline](concept-ml-pipelines.md)\n- Understand how to use Azure ML pipeline with [CLI v2](how-to-create-component-pipelines-cli.md) and [SDK v2](how-to-create-component-pipeline-python.md).\n\n## Why are parallel jobs needed?\n\nIn the real world, ML engineers always have scale requirements on their training or inferencing tasks. For example, when a data scientist provides a single script to train a sales prediction model, ML engineers need to apply this training task to each individual store. During this scale out process, some challenges are:\n\n- Delay pressure caused by long execution time.\n- Manual intervention to handle unexpected issues to keep the task proceeding.\n\nThe core value of Azure ML parallel job is to split a single serial task into mini-batches and dispatch those mini-batches to multiple computes to execute in parallel. By using parallel jobs, we can:\n\n - Significantly reduce end-to-end execution time.\n - Use Azure ML parallel job's automatic error handling settings.\n\nYou should consider using Azure ML Parallel job if:\n\n - You plan to train many models on top of your partitioned data.\n - You want to accelerate your large scale batch inferencing task.\n\n## Prepare for parallel job\n\nUnlike other types of jobs, a parallel job requires preparation. Follow the next sections to prepare for creating your parallel job.\n\n### Declare the inputs to be distributed and partition setting\n\nParallel job requires only one **major input data** to be split and processed with parallel. The major input data can be either tabular data or a set of files. Different input types can have a different partition method.\n\nThe following table illustrates the relation between input data and partition setting:\n\n| Data format | AML input type | AML input mode | Partition method |\n|: ---------- |: ------------- |: ------------- |: --------------- |\n| File list | `mltable` or<br>`uri_folder` | ro_mount or<br>download | By size (number of files) |\n| Tabular data | `mltable` | direct | By size (estimated physical size) |\n\nYou can declare your major input data with `input_data` attribute in parallel job YAML or Python SDK. And you can bind it with one of your defined `inputs` of your parallel job by using `${{inputs.<input name>}}`. Then to define the partition method for your major input.\n\nFor example, you could set numbers to `mini_batch_size` to partition your data **by size**.\n\n- When using file list input, this value defines the number of files for each mini-batch.\n- When using tabular input, this value defines the estimated physical size for each mini-batch.\n\n# [Azure CLI](#tab/cliv2)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\n$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json\ntype: pipeline\n\ndisplay_name: iris-batch-prediction-using-parallel\ndescription: The hello world pipeline job with inline parallel job\ntags:\n  tag: tagvalue\n  owner: sdkteam\n\nsettings:\n  default_compute: azureml:cpu-cluster\n\njobs:\n  batch_prediction:\n    type: parallel\n    compute: azureml:cpu-cluster\n    inputs:\n      input_data: \n        type: mltable\n        path: ./neural-iris-mltable\n        mode: direct\n      score_model: \n        type: uri_folder\n        path: ./iris-model\n        mode: download\n    outputs:\n      job_output_file:\n        type: uri_file\n        mode: rw_mount\n\n    input_data: ${{inputs.input_data}}\n    mini_batch_size: \"10kb\"\n    resources:\n        instance_count: 2\n    max_concurrency_per_instance: 2\n\n    logging_level: \"DEBUG\"\n    mini_batch_error_threshold: 5\n    retry_settings:\n      max_retries: 2\n      timeout: 60\n\n    task:\n      type: run_function\n      code: \"./script\"\n      entry_script: iris_prediction.py\n      environment:\n        name: \"prs-env\"\n        version: 1\n        image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n        conda_file: ./environment/environment_parallel.yml\n      program_arguments: >-\n        --model ${{inputs.score_model}}\n        --error_threshold 5\n        --allowed_failed_percent 30\n        --task_overhead_timeout 1200\n        --progress_update_timeout 600\n        --first_task_creation_timeout 600\n        --copy_logs_to_parent True\n        --resource_monitor_interva 20\n      append_row_to: ${{outputs.job_output_file}}\n\n```\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-use-parallel-job-in-pipeline-0.md"
                }
            },
            {
                "page_content": "These same snippets are available when you open your notebook in VS Code. For a complete list of available snippets, see [Azure Machine Learning VS Code Snippets](https://github.com/Azure/azureml-snippets/blob/main/snippets/snippets.md).\n\nYou can browse and search the list of snippets by using the notebook toolbar to open the snippet panel.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/open-snippet-panel.png\" alt-text=\"Open snippet panel tool in the notebook toolbar\":::\n\nFrom the snippets panel, you can also submit a request to add new snippets.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/propose-new-snippet.png\" alt-text=\"Snippet panel allows you to propose a new snippet\":::\n-->\n## Share a notebook\n\nYour notebooks are stored in your workspace's storage account, and can be shared with others, depending on their [access level](how-to-assign-roles.md) to your workspace.  They can open and edit the notebook as long as they have the appropriate access. For example, a Contributor can edit the notebook, while a Reader could only view it.\n\nOther users of your workspace can find your notebook in the **Notebooks**, **User files** section of Azure ML studio. By default, your notebooks are in a folder with your username, and others can access them there.\n\nYou can also copy the URL from your browser when you open a notebook, then send to others.  As long as they have appropriate access to your workspace, they can open the notebook.\n\nSince you don't share compute instances, other users who run your notebook will do so on their own compute instance.  \n\n## Collaborate with notebook comments (preview)\n\nUse a notebook comment to collaborate with others who have access to your notebook.\n\nToggle the comments pane on and off with the **Notebook comments** tool at the top of the notebook.  If your screen isn't wide enough, find this tool by first selecting the **...** at the end of the set of tools.\n\n:::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/notebook-comments-tool.png\" alt-text=\"Screenshot of notebook comments tool in the top toolbar.\":::  \n\nWhether the comments pane is visible or not, you can add a comment into any code cell:\n\n1. Select some text in the code cell.  You can only comment on text in a code cell.\n1. Use the **New comment thread** tool to create your comment.\n    :::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/comment-from-code.png\" alt-text=\"Screenshot of add a comment to a code cell tool.\":::\n1. If the comments pane was previously hidden, it will now open.  \n1. Type your comment and post it with the tool or use **Ctrl+Enter**.\n1. Once a comment is posted, select **...** in the top right to:\n    * Edit the comment\n    * Resolve the thread\n    * Delete the thread\n\nText that has been commented will appear with a purple highlight in the code. When you select a comment in the comments pane, your notebook will scroll to the cell that contains the highlighted text.\n\n> [!NOTE]\n> Comments are saved into the code cell's metadata.\n\n## Clean your notebook (preview)\n\nOver the course of creating a notebook, you typically end up with cells you used for data exploration or debugging. The *gather* feature will help you produce a clean notebook without these extraneous cells.\n\n1. Run all of your notebook cells.\n1. Select the cell containing the code you wish the new notebook to run. For example, the code that submits an experiment, or perhaps the code that registers a model.\n1. Select the **Gather** icon that appears on the cell toolbar.\n    :::image type=\"content\" source=\"media/how-to-run-jupyter-notebooks/gather.png\" alt-text=\"Screenshot: select the Gather icon\":::\n1. Enter the name for your new \"gathered\" notebook.  \n\nThe new notebook contains only code cells, with all cells required to produce the same results as the cell you selected for gathering.\n\n## Save and checkpoint a notebook\n\nAzure\u00a0Machine\u00a0Learning\u00a0creates\u00a0a\u00a0checkpoint\u00a0file\u00a0when\u00a0you\u00a0create\u00a0an\u00a0*ipynb*\u00a0file.\n",
                "metadata": {
                    "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-run-jupyter-notebooks-58.md"
                }
            }
        ],
        "rating_out_of_10": 10,
        "error": "Error parsing result json: Invalid \\escape: line 3 column 282 (char 405)"
    },
    {
        "question": "how can I create a GPU compute cluster using the new CLI v2?",
        "reply": "To create a GPU compute cluster using the new CLI v2, you can use the `az ml computetarget create` command. First, make sure you have the Azure CLI installed and the Machine Learning extension for Azure CLI.\n\nHere's an example command to create a new GPU compute cluster with a Standard_NC6 family virtual machine and \"Dedicated\" pricing tier:\n\n```\naz ml computetarget create --name gpu-cluster --type AmlCompute --min-instances 0 --max-instances 4 --vm-size Standard_NC6 --idle-seconds-before-scaledown 120 --admin-username azureuser --admin-user-password Password@1234 --priority Dedicated\n```\n\nReplace the `--name` argument of \"gpu-cluster\" with your desired name for the compute cluster, and adjust the `--vm-size` argument to your desired virtual machine size.\n\nYou'll also need to replace the `--admin-username` and `--admin-user-password` arguments with valid values for a new administrator user that will be created on the virtual machines in the cluster.",
        "ungrounded_facts": [
            "usage of the az ml computetarget create command"
        ],
        "rating_out_of_10": 7
    }
]