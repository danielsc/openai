{
    "query": "Code Samples to create an MLTable and use it in a sweep job  using AzureML SDK V2?",
    "result": "To create an MLTable and use it in a sweep job using AzureML SDK V2, you can follow the steps below:\n\n1. Import necessary libraries:\n\n```python\nfrom azureml.core import Workspace, Datastore, Dataset, Experiment, Environment\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core.dataset import InMemoryDataset, transform\nfrom azureml.api.schema.dataTypes import DataTypes\nfrom azureml.api.schema.sampleDefinition import SampleDefinition\nfrom azureml.train.automl.utilities import get_primary_metric_name, get_primary_metric_goal\n```\n\n2. Create an Azure ML workspace:\n\n```python\nsubscription_id = '<SUBSCRIPTION_ID>'\nresource_group = '<RESOURCE_GROUP>'\nworkspace_name = '<WORKSPACE_NAME>'\nworkspace_region = 'eastus'\n\nws = Workspace.create(name=workspace_name,\n                      subscription_id=subscription_id,\n                      resource_group=resource_group,\n                      location=workspace_region, \n                      exist_ok=True)\n\nws.write_config()\n```\n\n3. Create a datastore and upload data:\n\n```python\n# create an InMemoryDataset object from tabular data\nimport pandas as pd\nimport io\nimport requests\n\nurl = \"<URL_TO_JSON_FILE>\"\ndf = pd.read_json(io.StringIO(requests.get(url).content.decode('utf-8')))\n\nds = ws.get_default_datastore()\ndf.to_csv(\"sample_data.csv\", index=False)\n\nds.upload_files(files=[\"./sample_data.csv\"],\n                target_path=\"sample_data\",\n                overwrite=True)\n```\n\n4. Create an MLTable and register it:\n\n```python\nfrom azureml.core import MLTable\nfrom azureml.data import DataType\n\n# create an MLTable object from the InMemoryDataset\nml_table = MLTable.from_dataset(ds, 'sample_data', infer_column_types=True)\n\n# define the schema of the MLTable\n# column names and types should correspond to the column names and types of your data\nml_table.schema = {\n  \"columns\" : [\n    {\"name\": \"id\", \"type\": DataType.int64},\n    {\"name\": \"feature1\", \"type\": DataType.double},\n    {\"name\": \"feature2\", \"type\": DataType.string},\n    {\"name\": \"label\", \"type\": DataType.int64}\n  ]\n}\n\n# register the MLTable as an asset\nml_table.register(workspace = ws,\n                  name = \"sample_data_mltable\",\n                  description = \"Sample MLTable asset\")\n```\n\nNote: You can use `ml_table.to_csv()` function to convert your MLTable data into CSV format.\n\n5. Create compute target:\n\n```python\n# create a compute target\ncompute_name = 'cpu-cluster'\n\ntry:\n    cpu_cluster = ComputeTarget(workspace=ws, name=compute_name)\n    print(\"Found existing compute target\")\nexcept ComputeTargetException:\n    print(\"Creating compute target...\")\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n                                                           min_nodes=0,\n                                                           max_nodes=4)\n    cpu_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n\ncpu_cluster.wait_for_completion(show_output=True)\n```\n\n6. Define model configuration and create an experiment:\n\n```python\n# define the model configuration\nautoml_config = AutoMLConfig(task='regression',\n                             training_data=ml_table,\n                             label_column_name='label',\n                             iteration_timeout_minutes=10,\n                             iterations=10,\n                             n_cross_validations=5,\n                             primary_metric='r2_score')\n\n# create an experiment\nexperiment_name = 'regression-in-mltable'\n\nexperiment = Experiment(workspace = ws, name = experiment_name)\n```\n\n7. Define HyperDrive config and submit the job:\n\n```python\nfrom azureml.train.hyperdrive import uniform, choice\nfrom azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\nfrom azureml.train.hyperdrive.parameter_expressions import randint\n\nparam_sampling = {\n    \"max_depth\": randint(1, 15),\n    \"learning_rate\": uniform(0.01, 0.2),\n    \"subsample\": uniform(0.5, 1),\n    \"gamma\": uniform(0, 1),\n    \"colsample_bytree\": uniform(0.5, 1),\n    \"min_child_weight\": choice(1, 3, 5, 7)\n}\n\nhyperdrive_config = HyperDriveConfig(\n    estimator=estimator,\n    hyperparameter_sampling=param_sampling,\n    policy=None,\n    primary_metric_name='r2_score',\n    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n    max_total_runs=4,\n    max_concurrent_runs=4\n)\n\nhyperdrive_run = experiment.submit(config = hyperdrive_config, tags = {'data': 'MLTable'})\n```\n\nThis is a sample code to create an MLTable and use it in a sweep job with AzureML SDK V2. You can customize it as per your own data and requirements.",
    "context": [
        {
            "page_content": "\nUsing the above helper functions, for any given image, you can run the following code to display the bounding boxes.\n\n```python\nimage_file = \"./odFridgeObjects/images/31.jpg\"\njsonl_file = \"./odFridgeObjects/train_annotations.jsonl\"\n\nplot_ground_truth_boxes_jsonl(image_file, jsonl_file)\n```\n\n## Upload data and create MLTable\nIn order to use the data for training, upload data to default Blob Storage of your Azure ML Workspace and register it as an asset. The benefits of registering data are:\n- Easy to share with other members of the team\n- Versioning of the metadata (location, description, etc.)\n- Lineage tracking\n\n# [Azure CLI](#tab/cli)\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nCreate a .yml file with the following configuration.\n\n```yml\n$schema: https://azuremlschemas.azureedge.net/latest/data.schema.json\nname: fridge-items-images-object-detection\ndescription: Fridge-items images Object detection\npath: ./data/odFridgeObjects\ntype: uri_folder\n```\n\nTo upload the images as a data asset, you run the following CLI v2 command with the path to your .yml file, workspace name, resource group and subscription ID.\n\n```azurecli\naz ml data create -f [PATH_TO_YML_FILE] --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=upload-data)]\n\n\nNext step is to create `MLTable` from your data in jsonl format as shown below. MLtable package your data into a consumable object for training.\n\n```yaml\npaths:\n  - file: ./train_annotations.jsonl\ntransformations:\n  - read_json_lines:\n        encoding: utf8\n        invalid_lines: error\n        include_path_column: false\n  - convert_column_types:\n      - columns: image_url\n        column_type: stream_info\n```\n\n# [Azure CLI](#tab/cli)\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nThe following configuration creates training and validation data from the MLTable.\n\n```yaml\ntarget_column_name: label\ntraining_data:\n  path: data/training-mltable-folder\n  type: mltable\nvalidation_data:\n  path: data/validation-mltable-folder\n  type: mltable\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n\nYou can create data inputs from training and validation MLTable with the following code:\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=data-load)]\n\n\n## Configure your object detection experiment\n\nTo configure automated ML jobs for image-related tasks, create a task specific AutoML job.\n\n# [Azure CLI](#tab/cli)\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\ntask: image_object_detection\nprimary_metric: mean_average_precision\n```\n\n# [Python SDK](#tab/python)\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=image-object-detection-configuration)]\n\n\n### Automatic hyperparameter sweeping for image tasks (AutoMode)\n\n> [!IMPORTANT]\n> This feature is currently in public preview. This preview version is provided without a service-level agreement. Certain features might not be supported or might have constrained capabilities. For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/).\n\nIn your AutoML job, you can perform an automatic hyperparameter sweep in order to find the optimal model (we call this functionality AutoMode). You only specify the number of trials; the hyperparameter search space, sampling method and early termination policy are not needed. The system will automatically determine the region of the hyperparameter space to sweep based on the number of trials. A value between 10 and 20 will likely work well on many datasets.\n",
            "metadata": {
                "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/tutorial-auto-train-image-models-210.md"
            }
        },
        {
            "page_content": "\n# [Python SDK](#tab/python)\n\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\nYou can create data inputs from training and validation MLTable from your local directory or cloud storage with the following code:\n\n[!Notebook-python[] (~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=data-load)]\n\nTraining data is a required parameter and is passed in using the `training_data` parameter of the task specific `automl` type function. You can optionally specify another MLTable as a validation data with the `validation_data` parameter. If no validation data is specified, 20% of your training data will be used for validation by default, unless you pass `validation_data_size` argument with a different value.\n\nTarget column name is a required parameter and used as target for supervised ML task. It's passed in using the `target_column_name` parameter of the task specific `automl` function. For example,\n\n```python\nfrom azure.ai.ml import automl\nimage_object_detection_job = automl.image_object_detection(\n    training_data=my_training_data_input,\n    validation_data=my_validation_data_input,\n    target_column_name=\"label\"\n)\n```\n\n## Compute to run experiment\n\nProvide a [compute target](concept-azure-machine-learning-architecture.md#compute-targets) for automated ML to conduct model training. Automated ML models for computer vision tasks require GPU SKUs and support NC and ND families. We recommend the NCsv3-series (with v100 GPUs) for faster training. A compute target with a multi-GPU VM SKU leverages multiple GPUs to also speed up training. Additionally, when you set up a compute target with multiple nodes you can conduct faster model training through parallelism when tuning hyperparameters for your model.\n\n> [!NOTE]\n> If you are using a [compute instance](concept-compute-instance.md) as your compute target, please make sure that multiple AutoML jobs are not run at the same time. Also, please make sure that `max_concurrent_trials` is set to 1 in your [job limits](#job-limits).\n\nThe compute target is passed in using the `compute` parameter. For example:\n\n# [Azure CLI](#tab/cli)\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\n```yaml\ncompute: azureml:gpu-cluster\n```\n\n# [Python SDK](#tab/python)\n\n [!INCLUDE [sdk v2](../../includes/machine-learning-sdk-v2.md)]\n\n```python\nfrom azure.ai.ml import automl\n\ncompute_name = \"gpu-cluster\"\nimage_object_detection_job = automl.image_object_detection(\n    compute=compute_name,\n)\n```\n\n## Configure experiments\n\nFor computer vision tasks, you can launch either [individual trials](#individual-trials), [manual sweeps](#manually-sweeping-model-hyperparameters) or [automatic sweeps](#automatically-sweeping-model-hyperparameters-automode). We recommend starting with an automatic sweep to get a first baseline model. Then, you can try out individual trials with certain models and hyperparameter configurations. Finally, with manual sweeps you can explore multiple hyperparameter values near the more promising models and hyperparameter configurations. This three step workflow (automatic sweep, individual trials, manual sweeps) avoids searching the entirety of the hyperparameter space, which grows exponentially in the number of hyperparameters.\n\nAutomatic sweeps can yield competitive results for many datasets. Additionally, they do not require advanced knowledge of model architectures, they take into account hyperparameter correlations and they work seamlessly across different hardware setups. All these reasons make them a strong option for the early stage of your experimentation process.\n\n### Primary metric\n\nAn AutoML training job uses a primary metric for model optimization and hyperparameter tuning. The primary metric depends on the task type as shown below; other primary metric values are currently not supported. \n\n* [Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) for image classification\n",
            "metadata": {
                "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/how-to-auto-train-image-models-207.md"
            }
        },
        {
            "page_content": "\n# CLI (v2) Automated ML image object detection job YAML schema\n\n[!INCLUDE [cli v2](../../includes/machine-learning-cli-v2.md)]\n\nThe source JSON schema can be found at https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLImageObjectDetectionJob.schema.json.\n\n\n\n[!INCLUDE [schema note](../../includes/machine-learning-preview-old-json-schema-note.md)]\n\n## YAML syntax\n\nFor information on all the keys in Yaml syntax, see [Yaml syntax](./reference-automl-images-cli-classification.md#yaml-syntax) of image classification task. Here we only describe the keys that have different values as compared to what's specified for image classification task.\n\n| Key | Type | Description | Allowed values | Default value |\n| --- | ---- | ----------- | -------------- | ------------- |\n| `task` | const | **Required.** The type of AutoML task. | `image_object_detection` | `image_object_detection` |\n| `primary_metric` | string |  The metric that AutoML will optimize for model selection. |`mean_average_precision` | `mean_average_precision` |\n| `training_parameters` | object | Dictionary containing training parameters for the job. Provide an object that has keys as listed in following sections. <br> - [Model Specific Hyperparameters](./reference-automl-images-hyperparameters.md#model-specific-hyperparameters) for yolov5 (if you're using yolov5 for object detection) <br> - [Model agnostic hyperparameters](./reference-automl-images-hyperparameters.md#model-agnostic-hyperparameters) <br> - [Object detection and instance segmentation task specific hyperparameters](./reference-automl-images-hyperparameters.md#object-detection-and-instance-segmentation-task-specific-hyperparameters). <br> <br> For an example, see [Supported model architectures](./how-to-auto-train-image-models.md?tabs=cli#supported-model-architectures) section.| | |\n\n## Remarks\n\nThe `az ml job` command can be used for managing Azure Machine Learning jobs.\n\n## Examples\n\nExamples are available in the [examples GitHub repository](https://github.com/Azure/azureml-examples/tree/main/cli/jobs). Examples relevant to image object detection job are shown below.\n\n## YAML: AutoML image object detection job\n\n```yaml\n$schema: https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json\ntype: automl\n\n# <experiment_name>\nexperiment_name: dpv2-cli-automl-image-object-detection-experiment\n# </experiment_name>\ndescription: An Image Object Detection job using fridge items dataset\n\n# <compute_settings>\ncompute: azureml:gpu-cluster\n# </compute_settings>\n\n# <task_settings>\ntask: image_object_detection\nlog_verbosity: debug\nprimary_metric: mean_average_precision\n# </task_settings>\n\n# <mltable_settings>\ntarget_column_name: label\ntraining_data:\n  # Update the path, if prepare_data.py is using data_path other than \"./data\"\n  path: data/training-mltable-folder\n  type: mltable\nvalidation_data:\n  # Update the path, if prepare_data.py is using data_path other than \"./data\"\n  path: data/validation-mltable-folder\n  type: mltable\n# </mltable_settings>\n\n# <limit_settings>\nlimits:\n  timeout_minutes: 60\n  max_trials: 10\n  max_concurrent_trials: 2\n# </limit_settings>\n\n# <fixed_settings>\ntraining_parameters:\n  early_stopping: True\n  evaluation_frequency: 1\n# </fixed_settings>\n\n# <sweep_settings>\nsweep:\n  sampling_algorithm: random\n  early_termination:\n    type: bandit\n    evaluation_interval: 2\n    slack_factor: 0.2\n    delay_evaluation: 6\n# </sweep_settings>\n\n# <search_space_settings>\nsearch_space:\n  - model_name:\n      type: choice\n      values: [yolov5]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.01\n    model_size:\n      type: choice\n      values: ['small', 'medium']\n  - model_name:\n      type: choice\n      values: [fasterrcnn_resnet50_fpn]\n    learning_rate:\n      type: uniform\n      min_value: 0.0001\n      max_value: 0.001\n    optimizer:\n      type: choice\n      values: ['sgd', 'adam', 'adamw']\n    min_size:\n      type: choice\n      values: [600, 800]\n# </search_space_settings>\n\n```\n",
            "metadata": {
                "sourcefile": "UI/2023-04-06_191207_UTC/simple-4000-100/reference-automl-images-cli-object-detection-0.md"
            }
        }
    ]
}