
# Question

How do I deploy a model in AzureML using CLI V2 and Managed Inferencing ?

# Response A

To deploy a model in AzureML using CLI V2 and Managed Inferencing, you can follow these steps:

1. Create or configure a secure Kubernetes inferencing environment.
2. Deploy AzureML extension.
3. Attach the Kubernetes cluster to the workspace.
4. Use CLI v2 to deploy the model to a Kubernetes online endpoint. You can find examples on the AzureML GitHub repository.

# Response B

To deploy a model in AzureML using CLI V2 and Managed Inferencing, you can follow these steps:

1. Create or configure a secure Kubernetes inferencing environment. 
2. Deploy the AzureML extension.
3. Attach the Kubernetes cluster to the workspace.
4. Use the AzureML CLI V2 to deploy the model to a Kubernetes online endpoint. You can find examples of how to do this in the AzureML examples repository on GitHub.

Here are some links to get you started:

- [Secure Kubernetes inferencing environment](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-secure-kubernetes-inferencing-environment)
- [Deploy AzureML extension](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-kubernetes-extension)
- [Attach Kubernetes cluster to workspace](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-attach-kubernetes-anywhere)
- [AzureML CLI V2 examples for Kubernetes online endpoint deployment](https://github.com/Azure/azureml-examples/tree/main/cli/endpoints/online/kubernetes)

# Label

Preferred response: 
