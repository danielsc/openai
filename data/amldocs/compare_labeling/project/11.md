
# Question

How can I create a sweep job using AzureML SDK V2 ?

# Response A

To create a sweep job using AzureML SDK V2, you can use the `sweep` method of a command job. First, define a command job that takes hyperparameters as inputs. Then, call the `sweep` method on the command job to sweep over the hyperparameters based on the search space and terminate policy you defined. Finally, set the limits for the sweep and submit the job. Here is an example code snippet:

```python
from azure.ai.ml import command, Input
from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy

command_job = command(
    code="./src",
    command="python main.py --iris-csv ${{inputs.iris_csv}} --learning-rate ${{inputs.learning_rate}} --boosting ${{inputs.boosting}}",
    environment="AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest",
    inputs={
        "iris_csv": Input(
            type="uri_file",
            path="https://azuremlexamples.blob.core.windows.net/datasets/iris.csv",
        ),
        "learning_rate": Uniform(min_value=0.01, max_value=0.9),
        "boosting": Choice(values=["gbdt", "dart"]),
    },
    compute="cpu-cluster",
)

sweep_job = command_job.sweep(
    compute="cpu-cluster", 
    sampling_algorithm="random",
    primary_metric="test-multi_logloss",
    goal="Minimize",
)

sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=10, timeout=7200)
sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)

returned_sweep_job = ml_client.create_or_update(sweep_job)
```

# Response B

To create a sweep job using AzureML SDK V2, you can use the `azure.ai.ml.sweep` module. Here's an example:

```python
from azure.ai.ml import MLClient
from azure.ai.ml import command, Input
from azure.ai.ml.sweep import Choice, Uniform, MedianStoppingPolicy
from azure.identity import DefaultAzureCredential

# Create your command
command_job_for_sweep = command(
    code="./src",
    command="python main.py --iris-csv ${{inputs.iris_csv}} --learning-rate ${{inputs.learning_rate}} --boosting ${{inputs.boosting}}",
    environment="AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu@latest",
    inputs={
        "iris_csv": Input(
            type="uri_file",
            path="https://azuremlexamples.blob.core.windows.net/datasets/iris.csv",
        ),
        #define the search space for your hyperparameters
        "learning_rate": Uniform(min_value=0.01, max_value=0.9),
        "boosting": Choice(values=["gbdt", "dart"]),
    },
    compute="cpu-cluster",
)

# Call sweep() on your command job to sweep over your parameter expressions
sweep_job = command_job_for_sweep.sweep(
    compute="cpu-cluster", 
    sampling_algorithm="random",
    primary_metric="test-multi_logloss",
    goal="Minimize",
)

# Define the limits for this sweep
sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=10, timeout=7200)

# Set early stopping on this one
sweep_job.early_termination = MedianStoppingPolicy(delay_evaluation=5, evaluation_interval=2)

# Specify your experiment details
sweep_job.display_name = "lightgbm-iris-sweep-example"
sweep_job.experiment_name = "lightgbm-iris-sweep-example"
sweep_job.description = "Run a hyperparameter sweep job for LightGBM on Iris dataset."

# submit the sweep
returned_sweep_job = ml_client.create_or_update(sweep_job)

# get a URL for the status of the job
returned_sweep_job.services["Studio"].endpoint

# Download best trial model output
ml_client.jobs.download(returned_sweep_job.name, output_name="model")
```

In this example, we create a command job using the `command()` function, which takes the command to run, the environment to run it in, and the inputs to the command. We then call the `sweep()` method on the command job to create a sweep job, which we can then submit using the `create_or_update()` method of the `MLClient` object. We can also set limits on the sweep job, such as the maximum number of trials and the maximum amount of time to run. Finally, we can download the best trial model output using the `download()` method of the `MLClient` object.

# Label

Preferred response: 
