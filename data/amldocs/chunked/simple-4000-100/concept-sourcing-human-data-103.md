:::row-end:::

-----

:::row:::
    :::column span="":::
        **Qualify external suppliers carefully.**     
    :::column-end:::

    :::column span="":::
        - Data collections with unqualified suppliers may result in low quality data, poor data management, unprofessional practices, and potentially harmful outcomes for data contributors and data collectors (including violations of human rights).
        - Annotation or labeling work (e.g., audio transcription, image tagging) with unqualified suppliers may result in low quality or biased datasets, insecure data management, unprofessional practices, and potentially harmful outcomes for data contributors (including violations of human rights).
    :::column-end:::

:::row-end:::

-----

:::row:::
    :::column span="":::
        **Communicate expectations clearly in the Statement of Work (SOW) (contracts or agreements) with suppliers.**
    :::column-end:::

    :::column span="":::
        - A contract which lacks requirements for responsible data collection work may result in low-quality or poorly collected data.     
    :::column-end:::

:::row-end:::

-----

:::row:::
    :::column span="":::
        **Qualify geographies carefully.** 
    :::column-end:::

    :::column span="":::
        - When applicable, collecting data in areas of high geopolitical risk and/or unfamiliar geographies may result in unusable or low-quality data and may impact the safety of involved parties.
    :::column-end:::

:::row-end:::

-----

:::row:::
    :::column span="":::
        **Be a good steward of your datasets.**
    :::column-end:::

    :::column span="":::
        - Improper data management and poor documentation can result in data misuse.
    :::column-end:::

:::row-end:::

-----


>[!NOTE]
>This article focuses on recommendations for human data, including personal data and sensitive data such as biometric data, health data, racial or ethnic data, data collected manually from the general public or company employees, as well as metadata relating to human characteristics, such as age, ancestry, and gender identity, that may be created via annotation or labeling. 

[Download the full recommendations here](https://bit.ly/3FK8m8A)



## Best practices for collecting age, ancestry, and gender identity

In order for AI systems to work well for everyone, the datasets used for training and evaluation should reflect the diversity of people who will use or be affected by those systems. In many cases, age, ancestry, and gender identity can help approximate the range of factors that might affect how well a product performs for a variety of people; however, collecting this information requires special consideration.

If you do collect this data, always let data contributors self-identify (choose their own responses) instead of having data collectors make assumptions, which might be incorrect. Also include a “prefer not to answer” option for each question. These practices will show respect for the data contributors and yield more balanced and higher-quality data. 
 
These best practices have been developed based on three years of research with intended stakeholders and collaboration with many teams at Microsoft: [fairness and inclusiveness working groups](https://www.microsoft.com/ai/our-approach?activetab=pivot1:primaryr5), [Global Diversity & Inclusion](https://www.microsoft.com/diversity/default.aspx), [Global Readiness](https://www.microsoft.com/security/blog/2014/09/29/microsoft-global-readiness-diverse-cultures-multiple-languages-one-world/), [Office of Responsible AI](https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6), and others.   

To enable people to self-identify, consider using the following survey questions. 

### Age

**How old are you?**

*Select your age range*

[*Include appropriate age ranges as defined by project purpose, geographical region, and guidance from domain experts*]

- \# to # 
- \# to # 
- \# to # 
- Prefer not to answer


### Ancestry
